<!DOCTYPE html>

<html class="writer-html5" data-content_root="../../" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>dgl.convert — DGL 2.0.0 documentation</title>
<link href="../../_static/pygments.css?v=80d5e7a1" rel="stylesheet" type="text/css"/>
<link href="../../_static/css/theme.css?v=19f00094" rel="stylesheet" type="text/css"/>
<link href="../../_static/graphviz.css?v=fd3f3429" rel="stylesheet" type="text/css"/>
<link href="../../_static/copybutton.css?v=76b2166b" rel="stylesheet" type="text/css"/>
<link href="../../_static/sg_gallery.css?v=d2d258e8" rel="stylesheet" type="text/css"/>
<link href="../../_static/sg_gallery-binder.css?v=f4aeca0c" rel="stylesheet" type="text/css"/>
<link href="../../_static/sg_gallery-dataframe.css?v=2082cf3c" rel="stylesheet" type="text/css"/>
<link href="../../_static/sg_gallery-rendered-html.css?v=1277b6f3" rel="stylesheet" type="text/css"/>
<link href="../../_static/css/custom.css?v=0bf289b5" rel="stylesheet" type="text/css"/>
<!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
<script src="../../_static/jquery.js?v=5d32c60e"></script>
<script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
<script src="../../_static/documentation_options.js?v=51b770b3"></script>
<script src="../../_static/doctools.js?v=9a2dae69"></script>
<script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
<script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
<script src="../../_static/copybutton.js?v=ccdb6887"></script>
<script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
<script src="../../_static/js/theme.js"></script>
<link href="../../genindex.html" rel="index" title="Index"/>
<link href="../../search.html" rel="search" title="Search"/>
</head>
<body class="wy-body-for-nav">
<div class="wy-grid-for-nav">
<nav class="wy-nav-side" data-toggle="wy-nav-shift">
<div class="wy-side-scroll">
<div class="wy-side-nav-search">
<a class="icon icon-home" href="../../index.html">
            DGL
          </a>
<div class="version">
                2.0.0
              </div>
<div role="search">
<form action="../../search.html" class="wy-form" id="rtd-search-form" method="get">
<input aria-label="Search docs" name="q" placeholder="Search docs" type="text"/>
<input name="check_keywords" type="hidden" value="yes"/>
<input name="area" type="hidden" value="default"/>
</form>
</div>
</div><div aria-label="Navigation menu" class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation">
<p class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../install/index.html">Install and Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/blitz/index.html">A Blitz Introduction to DGL</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Materials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../stochastic_training/index.html">🆕 Stochastic Training of GNNs with GraphBolt</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../guide/index.html">User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../guide_cn/index.html">用户指南【包含过时信息】</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../guide_ko/index.html">사용자 가이드[시대에 뒤쳐진]</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/sparse/index.html">Tutorials: dgl.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/cpu/index.html">Training on CPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/multi/index.html">Training on Multiple GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/dist/index.html">Distributed training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/models/index.html">Paper Study with DGL</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.html">dgl</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.data.html">dgl.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.dataloading.html">dgl.dataloading</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.DGLGraph.html">dgl.DGLGraph</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.distributed.html">dgl.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.function.html">dgl.function</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.geometry.html">dgl.geometry</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.graphbolt.html">🆕 dgl.graphbolt</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/nn-pytorch.html">dgl.nn (PyTorch)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/nn-tensorflow.html">dgl.nn (TensorFlow)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/nn-mxnet.html">dgl.nn (MXNet)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/nn.functional.html">dgl.nn.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.ops.html">dgl.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.optim.html">dgl.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.sampling.html">dgl.sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.sparse_v0.html">dgl.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.multiprocessing.html">dgl.multiprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/transforms.html">dgl.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/udf.html">User-defined Functions</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../contribute.html">Contribute to DGL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../developer/ffi.html">DGL Foreign Function Interface (FFI)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../performance.html">Performance Benchmarks</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Misc</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../faq.html">Frequently Asked Questions (FAQ)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../env_var.html">Environment Variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../resources.html">Resources</a></li>
</ul>
</div>
</div>
</nav>
<section class="wy-nav-content-wrap" data-toggle="wy-nav-shift"><nav aria-label="Mobile navigation menu" class="wy-nav-top">
<i class="fa fa-bars" data-toggle="wy-nav-top"></i>
<a href="../../index.html">DGL</a>
</nav>
<div class="wy-nav-content">
<div class="rst-content">
<div aria-label="Page navigation" role="navigation">
<ul class="wy-breadcrumbs">
<li><a aria-label="Home" class="icon icon-home" href="../../index.html"></a></li>
<li class="breadcrumb-item"><a href="../index.html">Module code</a></li>
<li class="breadcrumb-item active">dgl.convert</li>
<li class="wy-breadcrumbs-aside">
</li>
</ul>
<hr/>
</div>
<div class="document" itemscope="itemscope" itemtype="http://schema.org/Article" role="main">
<div itemprop="articleBody">
<h1>Source code for dgl.convert</h1><div class="highlight"><pre>
<span></span><span class="sd">"""Module for converting graph from/to other object."""</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>
<span class="kn">from</span> <span class="nn">collections.abc</span> <span class="kn">import</span> <span class="n">Mapping</span>

<span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="nn">nx</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy.sparse</span> <span class="kn">import</span> <span class="n">spmatrix</span>

<span class="kn">from</span> <span class="nn">.</span> <span class="kn">import</span> <span class="n">backend</span> <span class="k">as</span> <span class="n">F</span><span class="p">,</span> <span class="n">graph_index</span><span class="p">,</span> <span class="n">heterograph_index</span><span class="p">,</span> <span class="n">utils</span>
<span class="kn">from</span> <span class="nn">.base</span> <span class="kn">import</span> <span class="n">DGLError</span><span class="p">,</span> <span class="n">EID</span><span class="p">,</span> <span class="n">ETYPE</span><span class="p">,</span> <span class="n">NID</span><span class="p">,</span> <span class="n">NTYPE</span>
<span class="kn">from</span> <span class="nn">.heterograph</span> <span class="kn">import</span> <span class="n">combine_frames</span><span class="p">,</span> <span class="n">DGLBlock</span><span class="p">,</span> <span class="n">DGLGraph</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">"graph"</span><span class="p">,</span>
    <span class="s2">"hetero_from_shared_memory"</span><span class="p">,</span>
    <span class="s2">"heterograph"</span><span class="p">,</span>
    <span class="s2">"create_block"</span><span class="p">,</span>
    <span class="s2">"block_to_graph"</span><span class="p">,</span>
    <span class="s2">"to_heterogeneous"</span><span class="p">,</span>
    <span class="s2">"to_homogeneous"</span><span class="p">,</span>
    <span class="s2">"from_scipy"</span><span class="p">,</span>
    <span class="s2">"bipartite_from_scipy"</span><span class="p">,</span>
    <span class="s2">"from_networkx"</span><span class="p">,</span>
    <span class="s2">"bipartite_from_networkx"</span><span class="p">,</span>
    <span class="s2">"to_networkx"</span><span class="p">,</span>
    <span class="s2">"from_cugraph"</span><span class="p">,</span>
    <span class="s2">"to_cugraph"</span><span class="p">,</span>
<span class="p">]</span>


<div class="viewcode-block" id="graph">
<a class="viewcode-back" href="../../generated/dgl.graph.html#dgl.graph">[docs]</a>
<span class="k">def</span> <span class="nf">graph</span><span class="p">(</span>
    <span class="n">data</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">num_nodes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">idtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">row_sorted</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">col_sorted</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">"""Create a graph and return.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : graph data</span>
<span class="sd">        The data for constructing a graph, which takes the form of :math:`(U, V)`.</span>
<span class="sd">        :math:`(U[i], V[i])` forms the edge with ID :math:`i` in the graph.</span>
<span class="sd">        The allowed data formats are:</span>

<span class="sd">        - ``(Tensor, Tensor)``: Each tensor must be a 1D tensor containing node IDs.</span>
<span class="sd">          DGL calls this format "tuple of node-tensors". The tensors should have the same</span>
<span class="sd">          data type of int32/int64 and device context (see below the descriptions of</span>
<span class="sd">          :attr:`idtype` and :attr:`device`).</span>
<span class="sd">        - ``('coo', (Tensor, Tensor))``: Same as ``(Tensor, Tensor)``.</span>
<span class="sd">        - ``('csr', (Tensor, Tensor, Tensor))``: The three tensors form the CSR representation</span>
<span class="sd">          of the graph's adjacency matrix.  The first one is the row index pointer.  The</span>
<span class="sd">          second one is the column indices.  The third one is the edge IDs, which can be empty</span>
<span class="sd">          to represent consecutive integer IDs starting from 0.</span>
<span class="sd">        - ``('csc', (Tensor, Tensor, Tensor))``: The three tensors form the CSC representation</span>
<span class="sd">          of the graph's adjacency matrix.  The first one is the column index pointer.  The</span>
<span class="sd">          second one is the row indices.  The third one is the edge IDs, which can be empty</span>
<span class="sd">          to represent consecutive integer IDs starting from 0.</span>

<span class="sd">        The tensors can be replaced with any iterable of integers (e.g. list, tuple,</span>
<span class="sd">        numpy.ndarray).</span>
<span class="sd">    num_nodes : int, optional</span>
<span class="sd">        The number of nodes in the graph. If not given, this will be the largest node ID</span>
<span class="sd">        plus 1 from the :attr:`data` argument. If given and the value is no greater than</span>
<span class="sd">        the largest node ID from the :attr:`data` argument, DGL will raise an error.</span>
<span class="sd">    idtype : int32 or int64, optional</span>
<span class="sd">        The data type for storing the structure-related graph information such as node and</span>
<span class="sd">        edge IDs. It should be a framework-specific data type object (e.g., ``torch.int32``).</span>
<span class="sd">        If ``None`` (default), DGL infers the ID type from the :attr:`data` argument.</span>
<span class="sd">        See "Notes" for more details.</span>
<span class="sd">    device : device context, optional</span>
<span class="sd">        The device of the returned graph, which should be a framework-specific device object</span>
<span class="sd">        (e.g., ``torch.device``). If ``None`` (default), DGL uses the device of the tensors of</span>
<span class="sd">        the :attr:`data` argument. If :attr:`data` is not a tuple of node-tensors, the</span>
<span class="sd">        returned graph is on CPU.  If the specified :attr:`device` differs from that of the</span>
<span class="sd">        provided tensors, it casts the given tensors to the specified device first.</span>
<span class="sd">    row_sorted : bool, optional</span>
<span class="sd">        Whether or not the rows of the COO are in ascending order.</span>
<span class="sd">    col_sorted : bool, optional</span>
<span class="sd">        Whether or not the columns of the COO are in ascending order within</span>
<span class="sd">        each row. This only has an effect when ``row_sorted`` is True.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    DGLGraph</span>
<span class="sd">        The created graph.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    1. If the :attr:`idtype` argument is not given then:</span>

<span class="sd">       - in the case of the tuple of node-tensor format, DGL uses the</span>
<span class="sd">         data type of the given ID tensors.</span>
<span class="sd">       - in the case of the tuple of sequence format, DGL uses int64.</span>

<span class="sd">       Once the graph has been created, you can change the data type by using</span>
<span class="sd">       :func:`dgl.DGLGraph.long` or :func:`dgl.DGLGraph.int`.</span>

<span class="sd">       If the specified :attr:`idtype` argument differs from the data type of the provided</span>
<span class="sd">       tensors, it casts the given tensors to the specified data type first.</span>
<span class="sd">    2. The most efficient construction approach is to provide a tuple of node tensors without</span>
<span class="sd">       specifying :attr:`idtype` and :attr:`device`. This is because the returned graph shares</span>
<span class="sd">       the storage with the input node-tensors in this case.</span>
<span class="sd">    3. DGL internally maintains multiple copies of the graph structure in different</span>
<span class="sd">       `sparse formats &lt;https://en.wikipedia.org/wiki/Sparse_matrix&gt;`_ and chooses the most</span>
<span class="sd">       efficient one depending on the computation invoked. If memory usage becomes an issue</span>
<span class="sd">       in the case of large graphs, use :func:`dgl.DGLGraph.formats` to restrict the allowed</span>
<span class="sd">       formats.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    The following example uses PyTorch backend.</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>

<span class="sd">    Create a small three-edge graph.</span>

<span class="sd">    &gt;&gt;&gt; # Source nodes for edges (2, 1), (3, 2), (4, 3)</span>
<span class="sd">    &gt;&gt;&gt; src_ids = torch.tensor([2, 3, 4])</span>
<span class="sd">    &gt;&gt;&gt; # Destination nodes for edges (2, 1), (3, 2), (4, 3)</span>
<span class="sd">    &gt;&gt;&gt; dst_ids = torch.tensor([1, 2, 3])</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.graph((src_ids, dst_ids))</span>

<span class="sd">    Explicitly specify the number of nodes in the graph.</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.graph((src_ids, dst_ids), num_nodes=100)</span>

<span class="sd">    Create a graph on the first GPU with data type int32.</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.graph((src_ids, dst_ids), idtype=torch.int32, device='cuda:0')</span>

<span class="sd">    Creating a graph with CSR representation:</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.graph(('csr', ([0, 0, 0, 1, 2, 3], [1, 2, 3], [])))</span>

<span class="sd">    Create the same graph with CSR representation and edge IDs.</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.graph(('csr', ([0, 0, 0, 1, 2, 3], [1, 2, 3], [0, 1, 2])))</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    from_scipy</span>
<span class="sd">    from_networkx</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">spmatrix</span><span class="p">):</span>
        <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
            <span class="s2">"dgl.graph no longer supports graph construction from a SciPy "</span>
            <span class="s2">"sparse matrix, use dgl.from_scipy instead."</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">nx</span><span class="o">.</span><span class="n">Graph</span><span class="p">):</span>
        <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
            <span class="s2">"dgl.graph no longer supports graph construction from a NetworkX "</span>
            <span class="s2">"graph, use dgl.from_networkx instead."</span>
        <span class="p">)</span>

    <span class="p">(</span><span class="n">sparse_fmt</span><span class="p">,</span> <span class="n">arrays</span><span class="p">),</span> <span class="n">urange</span><span class="p">,</span> <span class="n">vrange</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">graphdata2tensors</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">idtype</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">num_nodes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># override the number of nodes</span>
        <span class="k">if</span> <span class="n">num_nodes</span> <span class="o">&lt;</span> <span class="nb">max</span><span class="p">(</span><span class="n">urange</span><span class="p">,</span> <span class="n">vrange</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                <span class="s2">"The num_nodes argument must be larger than the max ID in the data,"</span>
                <span class="s2">" but got </span><span class="si">{}</span><span class="s2"> and </span><span class="si">{}</span><span class="s2">."</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">num_nodes</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="n">urange</span><span class="p">,</span> <span class="n">vrange</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="n">urange</span><span class="p">,</span> <span class="n">vrange</span> <span class="o">=</span> <span class="n">num_nodes</span><span class="p">,</span> <span class="n">num_nodes</span>

    <span class="n">g</span> <span class="o">=</span> <span class="n">create_from_edges</span><span class="p">(</span>
        <span class="n">sparse_fmt</span><span class="p">,</span>
        <span class="n">arrays</span><span class="p">,</span>
        <span class="s2">"_N"</span><span class="p">,</span>
        <span class="s2">"_E"</span><span class="p">,</span>
        <span class="s2">"_N"</span><span class="p">,</span>
        <span class="n">urange</span><span class="p">,</span>
        <span class="n">vrange</span><span class="p">,</span>
        <span class="n">row_sorted</span><span class="o">=</span><span class="n">row_sorted</span><span class="p">,</span>
        <span class="n">col_sorted</span><span class="o">=</span><span class="n">col_sorted</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">g</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span></div>



<span class="k">def</span> <span class="nf">hetero_from_shared_memory</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Create a heterograph from shared memory with the given name.</span>

<span class="sd">    The newly created graph will have the same node types and edge types as the original graph.</span>
<span class="sd">    But it does not have node features or edges features.</span>

<span class="sd">    Paramaters</span>
<span class="sd">    ----------</span>
<span class="sd">    name : str</span>
<span class="sd">        The name of the share memory</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    HeteroGraph (in shared memory)</span>
<span class="sd">    """</span>
    <span class="n">g</span><span class="p">,</span> <span class="n">ntypes</span><span class="p">,</span> <span class="n">etypes</span> <span class="o">=</span> <span class="n">heterograph_index</span><span class="o">.</span><span class="n">create_heterograph_from_shared_memory</span><span class="p">(</span>
        <span class="n">name</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">DGLGraph</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">ntypes</span><span class="p">,</span> <span class="n">etypes</span><span class="p">)</span>


<div class="viewcode-block" id="heterograph">
<a class="viewcode-back" href="../../generated/dgl.heterograph.html#dgl.heterograph">[docs]</a>
<span class="k">def</span> <span class="nf">heterograph</span><span class="p">(</span><span class="n">data_dict</span><span class="p">,</span> <span class="n">num_nodes_dict</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">idtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Create a heterogeneous graph and return.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data_dict : graph data</span>
<span class="sd">        The dictionary data for constructing a heterogeneous graph. The keys are in the form of</span>
<span class="sd">        string triplets (src_type, edge_type, dst_type), specifying the source node,</span>
<span class="sd">        edge, and destination node types. The values are graph data in the form of</span>
<span class="sd">        :math:`(U, V)`, where :math:`(U[i], V[i])` forms the edge with ID :math:`i`.</span>
<span class="sd">        The allowed graph data formats are:</span>

<span class="sd">        - ``(Tensor, Tensor)``: Each tensor must be a 1D tensor containing node IDs. DGL calls</span>
<span class="sd">          this format "tuple of node-tensors". The tensors should have the same data type,</span>
<span class="sd">          which must be either int32 or int64. They should also have the same device context</span>
<span class="sd">          (see below the descriptions of :attr:`idtype` and :attr:`device`).</span>
<span class="sd">        - ``('coo', (Tensor, Tensor))``: Same as ``(Tensor, Tensor)``.</span>
<span class="sd">        - ``('csr', (Tensor, Tensor, Tensor))``: The three tensors form the CSR representation</span>
<span class="sd">          of the graph's adjacency matrix.  The first one is the row index pointer.  The</span>
<span class="sd">          second one is the column indices.  The third one is the edge IDs, which can be empty</span>
<span class="sd">          (i.e. with 0 elements) to represent consecutive integer IDs starting from 0.</span>
<span class="sd">        - ``('csc', (Tensor, Tensor, Tensor))``: The three tensors form the CSC representation</span>
<span class="sd">          of the graph's adjacency matrix.  The first one is the column index pointer.  The</span>
<span class="sd">          second one is the row indices.  The third one is the edge IDs, which can be empty</span>
<span class="sd">          to represent consecutive integer IDs starting from 0.</span>

<span class="sd">        The tensors can be replaced with any iterable of integers (e.g. list, tuple,</span>
<span class="sd">        numpy.ndarray).</span>
<span class="sd">    num_nodes_dict : dict[str, int], optional</span>
<span class="sd">        The number of nodes for some node types, which is a dictionary mapping a node type</span>
<span class="sd">        :math:`T` to the number of :math:`T`-typed nodes. If not given for a node type</span>
<span class="sd">        :math:`T`, DGL finds the largest ID appearing in *every* graph data whose source</span>
<span class="sd">        or destination node type is :math:`T`, and sets the number of nodes to be that ID</span>
<span class="sd">        plus one. If given and the value is no greater than the largest ID for some node type,</span>
<span class="sd">        DGL will raise an error. By default, DGL infers the number of nodes for all node types.</span>
<span class="sd">    idtype : int32 or int64, optional</span>
<span class="sd">        The data type for storing the structure-related graph information such as node and</span>
<span class="sd">        edge IDs. It should be a framework-specific data type object (e.g., ``torch.int32``).</span>
<span class="sd">        If ``None`` (default), DGL infers the ID type from the :attr:`data_dict` argument.</span>
<span class="sd">    device : device context, optional</span>
<span class="sd">        The device of the returned graph, which should be a framework-specific device object</span>
<span class="sd">        (e.g., ``torch.device``). If ``None`` (default), DGL uses the device of the tensors of</span>
<span class="sd">        the :attr:`data` argument. If :attr:`data` is not a tuple of node-tensors, the</span>
<span class="sd">        returned graph is on CPU.  If the specified :attr:`device` differs from that of the</span>
<span class="sd">        provided tensors, it casts the given tensors to the specified device first.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    DGLGraph</span>
<span class="sd">        The created graph.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    1. If the :attr:`idtype` argument is not given then:</span>

<span class="sd">       - in the case of the tuple of node-tensor format, DGL uses</span>
<span class="sd">         the data type of the given ID tensors.</span>
<span class="sd">       - in the case of the tuple of sequence format, DGL uses int64.</span>

<span class="sd">       Once the graph has been created, you can change the data type by using</span>
<span class="sd">       :func:`dgl.DGLGraph.long` or :func:`dgl.DGLGraph.int`.</span>

<span class="sd">       If the specified :attr:`idtype` argument differs from the data type of the provided</span>
<span class="sd">       tensors, it casts the given tensors to the specified data type first.</span>
<span class="sd">    2. The most efficient construction approach is to provide a tuple of node tensors without</span>
<span class="sd">       specifying :attr:`idtype` and :attr:`device`. This is because the returned graph shares</span>
<span class="sd">       the storage with the input node-tensors in this case.</span>
<span class="sd">    3. DGL internally maintains multiple copies of the graph structure in different sparse</span>
<span class="sd">       formats and chooses the most efficient one depending on the computation invoked.</span>
<span class="sd">       If memory usage becomes an issue in the case of large graphs, use</span>
<span class="sd">       :func:`dgl.DGLGraph.formats` to restrict the allowed formats.</span>
<span class="sd">    4. DGL internally decides a deterministic order for the same set of node types and canonical</span>
<span class="sd">       edge types, which does not necessarily follow the order in :attr:`data_dict`.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    The following example uses PyTorch backend.</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>

<span class="sd">    Create a heterograph with three canonical edge types.</span>

<span class="sd">    &gt;&gt;&gt; data_dict = {</span>
<span class="sd">    ...     ('user', 'follows', 'user'): (torch.tensor([0, 1]), torch.tensor([1, 2])),</span>
<span class="sd">    ...     ('user', 'follows', 'topic'): (torch.tensor([1, 1]), torch.tensor([1, 2])),</span>
<span class="sd">    ...     ('user', 'plays', 'game'): (torch.tensor([0, 3]), torch.tensor([3, 4]))</span>
<span class="sd">    ... }</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.heterograph(data_dict)</span>
<span class="sd">    &gt;&gt;&gt; g</span>
<span class="sd">    Graph(num_nodes={'game': 5, 'topic': 3, 'user': 4},</span>
<span class="sd">          num_edges={('user', 'follows', 'user'): 2, ('user', 'follows', 'topic'): 2,</span>
<span class="sd">                     ('user', 'plays', 'game'): 2},</span>
<span class="sd">          metagraph=[('user', 'user', 'follows'), ('user', 'topic', 'follows'),</span>
<span class="sd">                     ('user', 'game', 'plays')])</span>

<span class="sd">    Explicitly specify the number of nodes for each node type in the graph.</span>

<span class="sd">    &gt;&gt;&gt; num_nodes_dict = {'user': 4, 'topic': 4, 'game': 6}</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.heterograph(data_dict, num_nodes_dict=num_nodes_dict)</span>

<span class="sd">    Create a graph on the first GPU with data type int32.</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.heterograph(data_dict, idtype=torch.int32, device='cuda:0')</span>
<span class="sd">    """</span>
    <span class="c1"># Convert all data to node tensors first</span>
    <span class="n">node_tensor_dict</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">need_infer</span> <span class="o">=</span> <span class="n">num_nodes_dict</span> <span class="ow">is</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">num_nodes_dict</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">num_nodes_dict</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">sty</span><span class="p">,</span> <span class="n">ety</span><span class="p">,</span> <span class="n">dty</span><span class="p">),</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">data_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">spmatrix</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                <span class="s2">"dgl.heterograph no longer supports graph construction from a SciPy "</span>
                <span class="s2">"sparse matrix, use dgl.from_scipy instead."</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">nx</span><span class="o">.</span><span class="n">Graph</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                <span class="s2">"dgl.heterograph no longer supports graph construction from a NetworkX "</span>
                <span class="s2">"graph, use dgl.from_networkx instead."</span>
            <span class="p">)</span>
        <span class="n">is_bipartite</span> <span class="o">=</span> <span class="n">sty</span> <span class="o">!=</span> <span class="n">dty</span>
        <span class="p">(</span><span class="n">sparse_fmt</span><span class="p">,</span> <span class="n">arrays</span><span class="p">),</span> <span class="n">urange</span><span class="p">,</span> <span class="n">vrange</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">graphdata2tensors</span><span class="p">(</span>
            <span class="n">data</span><span class="p">,</span> <span class="n">idtype</span><span class="p">,</span> <span class="n">bipartite</span><span class="o">=</span><span class="n">is_bipartite</span>
        <span class="p">)</span>
        <span class="n">node_tensor_dict</span><span class="p">[(</span><span class="n">sty</span><span class="p">,</span> <span class="n">ety</span><span class="p">,</span> <span class="n">dty</span><span class="p">)]</span> <span class="o">=</span> <span class="p">(</span><span class="n">sparse_fmt</span><span class="p">,</span> <span class="n">arrays</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">need_infer</span><span class="p">:</span>
            <span class="n">num_nodes_dict</span><span class="p">[</span><span class="n">sty</span><span class="p">]</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">num_nodes_dict</span><span class="p">[</span><span class="n">sty</span><span class="p">],</span> <span class="n">urange</span><span class="p">)</span>
            <span class="n">num_nodes_dict</span><span class="p">[</span><span class="n">dty</span><span class="p">]</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">num_nodes_dict</span><span class="p">[</span><span class="n">dty</span><span class="p">],</span> <span class="n">vrange</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># sanity check</span>
            <span class="k">if</span> <span class="n">num_nodes_dict</span><span class="p">[</span><span class="n">sty</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">urange</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                    <span class="s2">"The given number of nodes of node type </span><span class="si">{}</span><span class="s2"> must be larger than"</span>
                    <span class="s2">" the max ID in the data, but got </span><span class="si">{}</span><span class="s2"> and </span><span class="si">{}</span><span class="s2">."</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                        <span class="n">sty</span><span class="p">,</span> <span class="n">num_nodes_dict</span><span class="p">[</span><span class="n">sty</span><span class="p">],</span> <span class="n">urange</span> <span class="o">-</span> <span class="mi">1</span>
                    <span class="p">)</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">num_nodes_dict</span><span class="p">[</span><span class="n">dty</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">vrange</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                    <span class="s2">"The given number of nodes of node type </span><span class="si">{}</span><span class="s2"> must be larger than"</span>
                    <span class="s2">" the max ID in the data, but got </span><span class="si">{}</span><span class="s2"> and </span><span class="si">{}</span><span class="s2">."</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                        <span class="n">dty</span><span class="p">,</span> <span class="n">num_nodes_dict</span><span class="p">[</span><span class="n">dty</span><span class="p">],</span> <span class="n">vrange</span> <span class="o">-</span> <span class="mi">1</span>
                    <span class="p">)</span>
                <span class="p">)</span>
    <span class="c1"># Create the graph</span>
    <span class="p">(</span>
        <span class="n">metagraph</span><span class="p">,</span>
        <span class="n">ntypes</span><span class="p">,</span>
        <span class="n">etypes</span><span class="p">,</span>
        <span class="n">relations</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">=</span> <span class="n">heterograph_index</span><span class="o">.</span><span class="n">create_metagraph_index</span><span class="p">(</span>
        <span class="n">num_nodes_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="n">node_tensor_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
    <span class="p">)</span>
    <span class="n">num_nodes_per_type</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">toindex</span><span class="p">(</span>
        <span class="p">[</span><span class="n">num_nodes_dict</span><span class="p">[</span><span class="n">ntype</span><span class="p">]</span> <span class="k">for</span> <span class="n">ntype</span> <span class="ow">in</span> <span class="n">ntypes</span><span class="p">],</span> <span class="s2">"int64"</span>
    <span class="p">)</span>
    <span class="n">rel_graphs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">srctype</span><span class="p">,</span> <span class="n">etype</span><span class="p">,</span> <span class="n">dsttype</span> <span class="ow">in</span> <span class="n">relations</span><span class="p">:</span>
        <span class="n">sparse_fmt</span><span class="p">,</span> <span class="n">arrays</span> <span class="o">=</span> <span class="n">node_tensor_dict</span><span class="p">[(</span><span class="n">srctype</span><span class="p">,</span> <span class="n">etype</span><span class="p">,</span> <span class="n">dsttype</span><span class="p">)]</span>
        <span class="n">g</span> <span class="o">=</span> <span class="n">create_from_edges</span><span class="p">(</span>
            <span class="n">sparse_fmt</span><span class="p">,</span>
            <span class="n">arrays</span><span class="p">,</span>
            <span class="n">srctype</span><span class="p">,</span>
            <span class="n">etype</span><span class="p">,</span>
            <span class="n">dsttype</span><span class="p">,</span>
            <span class="n">num_nodes_dict</span><span class="p">[</span><span class="n">srctype</span><span class="p">],</span>
            <span class="n">num_nodes_dict</span><span class="p">[</span><span class="n">dsttype</span><span class="p">],</span>
        <span class="p">)</span>
        <span class="n">rel_graphs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>

    <span class="c1"># create graph index</span>
    <span class="n">hgidx</span> <span class="o">=</span> <span class="n">heterograph_index</span><span class="o">.</span><span class="n">create_heterograph_from_relations</span><span class="p">(</span>
        <span class="n">metagraph</span><span class="p">,</span> <span class="p">[</span><span class="n">rgrh</span><span class="o">.</span><span class="n">_graph</span> <span class="k">for</span> <span class="n">rgrh</span> <span class="ow">in</span> <span class="n">rel_graphs</span><span class="p">],</span> <span class="n">num_nodes_per_type</span>
    <span class="p">)</span>
    <span class="n">retg</span> <span class="o">=</span> <span class="n">DGLGraph</span><span class="p">(</span><span class="n">hgidx</span><span class="p">,</span> <span class="n">ntypes</span><span class="p">,</span> <span class="n">etypes</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">retg</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span></div>



<div class="viewcode-block" id="create_block">
<a class="viewcode-back" href="../../generated/dgl.create_block.html#dgl.create_block">[docs]</a>
<span class="k">def</span> <span class="nf">create_block</span><span class="p">(</span>
    <span class="n">data_dict</span><span class="p">,</span> <span class="n">num_src_nodes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_dst_nodes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">idtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">"""Create a message flow graph (MFG) as a :class:`DGLBlock` object.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data_dict : graph data</span>
<span class="sd">        The dictionary data for constructing a MFG. The keys are in the form of</span>
<span class="sd">        string triplets (src_type, edge_type, dst_type), specifying the source node type,</span>
<span class="sd">        edge type, and destination node type. The values are graph data in the form of</span>
<span class="sd">        :math:`(U, V)`, where :math:`(U[i], V[i])` forms the edge with ID :math:`i`.</span>
<span class="sd">        The allowed graph data formats are:</span>

<span class="sd">        - ``(Tensor, Tensor)``: Each tensor must be a 1D tensor containing node IDs. DGL calls</span>
<span class="sd">          this format "tuple of node-tensors". The tensors should have the same data type,</span>
<span class="sd">          which must be either int32 or int64. They should also have the same device context</span>
<span class="sd">          (see below the descriptions of :attr:`idtype` and :attr:`device`).</span>
<span class="sd">        - ``('coo', (Tensor, Tensor))``: Same as ``(Tensor, Tensor)``.</span>
<span class="sd">        - ``('csr', (Tensor, Tensor, Tensor))``: The three tensors form the CSR representation</span>
<span class="sd">          of the graph's adjacency matrix.  The first one is the row index pointer.  The</span>
<span class="sd">          second one is the column indices.  The third one is the edge IDs, which can be empty</span>
<span class="sd">          to represent consecutive integer IDs starting from 0.</span>
<span class="sd">        - ``('csc', (Tensor, Tensor, Tensor))``: The three tensors form the CSC representation</span>
<span class="sd">          of the graph's adjacency matrix.  The first one is the column index pointer.  The</span>
<span class="sd">          second one is the row indices.  The third one is the edge IDs, which can be empty</span>
<span class="sd">          to represent consecutive integer IDs starting from 0.</span>

<span class="sd">        The tensors can be replaced with any iterable of integers (e.g. list, tuple,</span>
<span class="sd">        numpy.ndarray).</span>

<span class="sd">        If you would like to create a MFG with a single source node type, a single destination</span>
<span class="sd">        node type, and a single edge type, then you can pass in the graph data directly</span>
<span class="sd">        without wrapping it as a dictionary.</span>
<span class="sd">    num_src_nodes : dict[str, int] or int, optional</span>
<span class="sd">        The number of nodes for each source node type, which is a dictionary mapping a node type</span>
<span class="sd">        :math:`T` to the number of :math:`T`-typed source nodes.</span>

<span class="sd">        If not given for a node type :math:`T`, DGL finds the largest ID appearing in *every*</span>
<span class="sd">        graph data whose source node type is :math:`T`, and sets the number of nodes to</span>
<span class="sd">        be that ID plus one. If given and the value is no greater than the largest ID for some</span>
<span class="sd">        source node type, DGL will raise an error. By default, DGL infers the number of nodes for</span>
<span class="sd">        all source node types.</span>

<span class="sd">        If you would like to create a MFG with a single source node type, a single destination</span>
<span class="sd">        node type, and a single edge type, then you can pass in an integer to directly</span>
<span class="sd">        represent the number of source nodes.</span>
<span class="sd">    num_dst_nodes : dict[str, int] or int, optional</span>
<span class="sd">        The number of nodes for each destination node type, which is a dictionary mapping a node</span>
<span class="sd">        type :math:`T` to the number of :math:`T`-typed destination nodes.</span>

<span class="sd">        If not given for a node type :math:`T`, DGL finds the largest ID appearing in *every*</span>
<span class="sd">        graph data whose destination node type is :math:`T`, and sets the number of nodes to</span>
<span class="sd">        be that ID plus one. If given and the value is no greater than the largest ID for some</span>
<span class="sd">        destination node type, DGL will raise an error. By default, DGL infers the number of nodes</span>
<span class="sd">        for all destination node types.</span>

<span class="sd">        If you would like to create a MFG with a single destination node type, a single</span>
<span class="sd">        destination node type, and a single edge type, then you can pass in an integer to directly</span>
<span class="sd">        represent the number of destination nodes.</span>
<span class="sd">    idtype : int32 or int64, optional</span>
<span class="sd">        The data type for storing the structure-related graph information such as node and</span>
<span class="sd">        edge IDs. It should be a framework-specific data type object (e.g., ``torch.int32``).</span>
<span class="sd">        If ``None`` (default), DGL infers the ID type from the :attr:`data_dict` argument.</span>
<span class="sd">    device : device context, optional</span>
<span class="sd">        The device of the returned graph, which should be a framework-specific device object</span>
<span class="sd">        (e.g., ``torch.device``). If ``None`` (default), DGL uses the device of the tensors of</span>
<span class="sd">        the :attr:`data` argument. If :attr:`data` is not a tuple of node-tensors, the</span>
<span class="sd">        returned graph is on CPU.  If the specified :attr:`device` differs from that of the</span>
<span class="sd">        provided tensors, it casts the given tensors to the specified device first.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    DGLBlock</span>
<span class="sd">        The created MFG.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    1. If the :attr:`idtype` argument is not given then:</span>

<span class="sd">       - in the case of the tuple of node-tensor format, DGL uses</span>
<span class="sd">         the data type of the given ID tensors.</span>
<span class="sd">       - in the case of the tuple of sequence format, DGL uses int64.</span>

<span class="sd">       Once the graph has been created, you can change the data type by using</span>
<span class="sd">       :func:`dgl.DGLGraph.long` or :func:`dgl.DGLGraph.int`.</span>

<span class="sd">       If the specified :attr:`idtype` argument differs from the data type of the provided</span>
<span class="sd">       tensors, it casts the given tensors to the specified data type first.</span>
<span class="sd">    2. The most efficient construction approach is to provide a tuple of node tensors without</span>
<span class="sd">       specifying :attr:`idtype` and :attr:`device`. This is because the returned graph shares</span>
<span class="sd">       the storage with the input node-tensors in this case.</span>
<span class="sd">    3. DGL internally maintains multiple copies of the graph structure in different sparse</span>
<span class="sd">       formats and chooses the most efficient one depending on the computation invoked.</span>
<span class="sd">       If memory usage becomes an issue in the case of large graphs, use</span>
<span class="sd">       :func:`dgl.DGLGraph.formats` to restrict the allowed formats.</span>
<span class="sd">    4. DGL internally decides a deterministic order for the same set of node types and canonical</span>
<span class="sd">       edge types, which does not necessarily follow the order in :attr:`data_dict`.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    The following example uses PyTorch backend.</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; block = dgl.create_block(([0, 1, 2], [1, 2, 3]), num_src_nodes=3, num_dst_nodes=4)</span>
<span class="sd">    &gt;&gt;&gt; block</span>
<span class="sd">    Block(num_src_nodes=3, num_dst_nodes=4, num_edges=3)</span>

<span class="sd">    &gt;&gt;&gt; block = dgl.create_block({</span>
<span class="sd">    ...     ('A', 'AB', 'B'): ([1, 2, 3], [2, 1, 0]),</span>
<span class="sd">    ...     ('B', 'BA', 'A'): ([2, 1], [2, 3])},</span>
<span class="sd">    ...     num_src_nodes={'A': 6, 'B': 5},</span>
<span class="sd">    ...     num_dst_nodes={'A': 4, 'B': 3})</span>
<span class="sd">    &gt;&gt;&gt; block</span>
<span class="sd">    Block(num_src_nodes={'A': 6, 'B': 5},</span>
<span class="sd">          num_dst_nodes={'A': 4, 'B': 3},</span>
<span class="sd">          num_edges={('A', 'AB', 'B'): 3, ('B', 'BA', 'A'): 2},</span>
<span class="sd">          metagraph=[('A', 'B', 'AB'), ('B', 'A', 'BA')])</span>

<span class="sd">    See also</span>
<span class="sd">    --------</span>
<span class="sd">    to_block</span>
<span class="sd">    """</span>
    <span class="n">need_infer</span> <span class="o">=</span> <span class="n">num_src_nodes</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">num_dst_nodes</span> <span class="ow">is</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data_dict</span><span class="p">,</span> <span class="n">Mapping</span><span class="p">):</span>
        <span class="n">data_dict</span> <span class="o">=</span> <span class="p">{(</span><span class="s2">"_N"</span><span class="p">,</span> <span class="s2">"_E"</span><span class="p">,</span> <span class="s2">"_N"</span><span class="p">):</span> <span class="n">data_dict</span><span class="p">}</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">need_infer</span><span class="p">:</span>
            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
                <span class="n">num_src_nodes</span><span class="p">,</span> <span class="nb">int</span>
            <span class="p">),</span> <span class="s2">"num_src_nodes must be a pair of integers if data_dict is not a dict"</span>
            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
                <span class="n">num_dst_nodes</span><span class="p">,</span> <span class="nb">int</span>
            <span class="p">),</span> <span class="s2">"num_dst_nodes must be a pair of integers if data_dict is not a dict"</span>
            <span class="n">num_src_nodes</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"_N"</span><span class="p">:</span> <span class="n">num_src_nodes</span><span class="p">}</span>
            <span class="n">num_dst_nodes</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"_N"</span><span class="p">:</span> <span class="n">num_dst_nodes</span><span class="p">}</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">need_infer</span><span class="p">:</span>
            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
                <span class="n">num_src_nodes</span><span class="p">,</span> <span class="n">Mapping</span>
            <span class="p">),</span> <span class="s2">"num_src_nodes must be a dict if data_dict is a dict"</span>
            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
                <span class="n">num_dst_nodes</span><span class="p">,</span> <span class="n">Mapping</span>
            <span class="p">),</span> <span class="s2">"num_dst_nodes must be a dict if data_dict is a dict"</span>

    <span class="k">if</span> <span class="n">need_infer</span><span class="p">:</span>
        <span class="n">num_src_nodes</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
        <span class="n">num_dst_nodes</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

    <span class="c1"># Convert all data to node tensors first</span>
    <span class="n">node_tensor_dict</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">sty</span><span class="p">,</span> <span class="n">ety</span><span class="p">,</span> <span class="n">dty</span><span class="p">),</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">data_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="p">(</span><span class="n">sparse_fmt</span><span class="p">,</span> <span class="n">arrays</span><span class="p">),</span> <span class="n">urange</span><span class="p">,</span> <span class="n">vrange</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">graphdata2tensors</span><span class="p">(</span>
            <span class="n">data</span><span class="p">,</span> <span class="n">idtype</span><span class="p">,</span> <span class="n">bipartite</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>
        <span class="n">node_tensor_dict</span><span class="p">[(</span><span class="n">sty</span><span class="p">,</span> <span class="n">ety</span><span class="p">,</span> <span class="n">dty</span><span class="p">)]</span> <span class="o">=</span> <span class="p">(</span><span class="n">sparse_fmt</span><span class="p">,</span> <span class="n">arrays</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">need_infer</span><span class="p">:</span>
            <span class="n">num_src_nodes</span><span class="p">[</span><span class="n">sty</span><span class="p">]</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">num_src_nodes</span><span class="p">[</span><span class="n">sty</span><span class="p">],</span> <span class="n">urange</span><span class="p">)</span>
            <span class="n">num_dst_nodes</span><span class="p">[</span><span class="n">dty</span><span class="p">]</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">num_dst_nodes</span><span class="p">[</span><span class="n">dty</span><span class="p">],</span> <span class="n">vrange</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># sanity check</span>
            <span class="k">if</span> <span class="n">num_src_nodes</span><span class="p">[</span><span class="n">sty</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">urange</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                    <span class="s2">"The given number of nodes of source node type </span><span class="si">{}</span><span class="s2"> must be larger"</span>
                    <span class="s2">" than the max ID in the data, but got </span><span class="si">{}</span><span class="s2"> and </span><span class="si">{}</span><span class="s2">."</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                        <span class="n">sty</span><span class="p">,</span> <span class="n">num_src_nodes</span><span class="p">[</span><span class="n">sty</span><span class="p">],</span> <span class="n">urange</span> <span class="o">-</span> <span class="mi">1</span>
                    <span class="p">)</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">num_dst_nodes</span><span class="p">[</span><span class="n">dty</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">vrange</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                    <span class="s2">"The given number of nodes of destination node type </span><span class="si">{}</span><span class="s2"> must be"</span>
                    <span class="s2">" larger than the max ID in the data, but got </span><span class="si">{}</span><span class="s2"> and </span><span class="si">{}</span><span class="s2">."</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                        <span class="n">dty</span><span class="p">,</span> <span class="n">num_dst_nodes</span><span class="p">[</span><span class="n">dty</span><span class="p">],</span> <span class="n">vrange</span> <span class="o">-</span> <span class="mi">1</span>
                    <span class="p">)</span>
                <span class="p">)</span>
    <span class="c1"># Create the graph</span>

    <span class="c1"># Sort the ntypes and relation tuples to have a deterministic order for the same set</span>
    <span class="c1"># of type names.</span>
    <span class="n">srctypes</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">num_src_nodes</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
    <span class="n">dsttypes</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">num_dst_nodes</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
    <span class="n">relations</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">node_tensor_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>

    <span class="n">num_nodes_per_type</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">toindex</span><span class="p">(</span>
        <span class="p">[</span><span class="n">num_src_nodes</span><span class="p">[</span><span class="n">ntype</span><span class="p">]</span> <span class="k">for</span> <span class="n">ntype</span> <span class="ow">in</span> <span class="n">srctypes</span><span class="p">]</span>
        <span class="o">+</span> <span class="p">[</span><span class="n">num_dst_nodes</span><span class="p">[</span><span class="n">ntype</span><span class="p">]</span> <span class="k">for</span> <span class="n">ntype</span> <span class="ow">in</span> <span class="n">dsttypes</span><span class="p">],</span>
        <span class="s2">"int64"</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">srctype_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">ntype</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ntype</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">srctypes</span><span class="p">)}</span>
    <span class="n">dsttype_dict</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">ntype</span><span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">srctypes</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ntype</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dsttypes</span><span class="p">)</span>
    <span class="p">}</span>

    <span class="n">meta_edges_src</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">meta_edges_dst</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">etypes</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">rel_graphs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">srctype</span><span class="p">,</span> <span class="n">etype</span><span class="p">,</span> <span class="n">dsttype</span> <span class="ow">in</span> <span class="n">relations</span><span class="p">:</span>
        <span class="n">meta_edges_src</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">srctype_dict</span><span class="p">[</span><span class="n">srctype</span><span class="p">])</span>
        <span class="n">meta_edges_dst</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dsttype_dict</span><span class="p">[</span><span class="n">dsttype</span><span class="p">])</span>
        <span class="n">etypes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">etype</span><span class="p">)</span>
        <span class="n">sparse_fmt</span><span class="p">,</span> <span class="n">arrays</span> <span class="o">=</span> <span class="n">node_tensor_dict</span><span class="p">[(</span><span class="n">srctype</span><span class="p">,</span> <span class="n">etype</span><span class="p">,</span> <span class="n">dsttype</span><span class="p">)]</span>
        <span class="n">g</span> <span class="o">=</span> <span class="n">create_from_edges</span><span class="p">(</span>
            <span class="n">sparse_fmt</span><span class="p">,</span>
            <span class="n">arrays</span><span class="p">,</span>
            <span class="s2">"SRC/"</span> <span class="o">+</span> <span class="n">srctype</span><span class="p">,</span>
            <span class="n">etype</span><span class="p">,</span>
            <span class="s2">"DST/"</span> <span class="o">+</span> <span class="n">dsttype</span><span class="p">,</span>
            <span class="n">num_src_nodes</span><span class="p">[</span><span class="n">srctype</span><span class="p">],</span>
            <span class="n">num_dst_nodes</span><span class="p">[</span><span class="n">dsttype</span><span class="p">],</span>
        <span class="p">)</span>
        <span class="n">rel_graphs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>

    <span class="c1"># metagraph is DGLGraph, currently still using int64 as index dtype</span>
    <span class="n">metagraph</span> <span class="o">=</span> <span class="n">graph_index</span><span class="o">.</span><span class="n">from_coo</span><span class="p">(</span>
        <span class="nb">len</span><span class="p">(</span><span class="n">srctypes</span><span class="p">)</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">dsttypes</span><span class="p">),</span> <span class="n">meta_edges_src</span><span class="p">,</span> <span class="n">meta_edges_dst</span><span class="p">,</span> <span class="kc">True</span>
    <span class="p">)</span>
    <span class="c1"># create graph index</span>
    <span class="n">hgidx</span> <span class="o">=</span> <span class="n">heterograph_index</span><span class="o">.</span><span class="n">create_heterograph_from_relations</span><span class="p">(</span>
        <span class="n">metagraph</span><span class="p">,</span> <span class="p">[</span><span class="n">rgrh</span><span class="o">.</span><span class="n">_graph</span> <span class="k">for</span> <span class="n">rgrh</span> <span class="ow">in</span> <span class="n">rel_graphs</span><span class="p">],</span> <span class="n">num_nodes_per_type</span>
    <span class="p">)</span>
    <span class="n">retg</span> <span class="o">=</span> <span class="n">DGLBlock</span><span class="p">(</span><span class="n">hgidx</span><span class="p">,</span> <span class="p">(</span><span class="n">srctypes</span><span class="p">,</span> <span class="n">dsttypes</span><span class="p">),</span> <span class="n">etypes</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">retg</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span></div>



<div class="viewcode-block" id="block_to_graph">
<a class="viewcode-back" href="../../generated/dgl.block_to_graph.html#dgl.block_to_graph">[docs]</a>
<span class="k">def</span> <span class="nf">block_to_graph</span><span class="p">(</span><span class="n">block</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Convert a message flow graph (MFG) as a :class:`DGLBlock` object to a :class:`DGLGraph`.</span>

<span class="sd">    DGL will rename all the source node types by suffixing with ``_src``, and</span>
<span class="sd">    all the destination node types by suffixing with ``_dst``.</span>

<span class="sd">    Features on the returned graph will be preserved.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    block : DGLBlock</span>
<span class="sd">        The MFG.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    DGLGraph</span>
<span class="sd">        The graph.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; block = dgl.create_block({</span>
<span class="sd">    ...     ('A', 'AB', 'B'): ([1, 2, 3], [2, 1, 0]),</span>
<span class="sd">    ...     ('B', 'BA', 'A'): ([2, 1], [2, 3])})</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.block_to_graph(block)</span>
<span class="sd">    &gt;&gt;&gt; g</span>
<span class="sd">    Graph(num_nodes={'A_src': 4, 'B_src': 3, 'A_dst': 4, 'B_dst': 3},</span>
<span class="sd">          num_edges={('A_src', 'AB', 'B_dst'): 3, ('B_src', 'BA', 'A_dst'): 2},</span>
<span class="sd">          metagraph=[('A_src', 'B_dst', 'AB'), ('B_src', 'A_dst', 'BA')])</span>
<span class="sd">    """</span>
    <span class="n">new_types</span> <span class="o">=</span> <span class="p">[</span><span class="n">ntype</span> <span class="o">+</span> <span class="s2">"_src"</span> <span class="k">for</span> <span class="n">ntype</span> <span class="ow">in</span> <span class="n">block</span><span class="o">.</span><span class="n">srctypes</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span>
        <span class="n">ntype</span> <span class="o">+</span> <span class="s2">"_dst"</span> <span class="k">for</span> <span class="n">ntype</span> <span class="ow">in</span> <span class="n">block</span><span class="o">.</span><span class="n">dsttypes</span>
    <span class="p">]</span>
    <span class="n">retg</span> <span class="o">=</span> <span class="n">DGLGraph</span><span class="p">(</span><span class="n">block</span><span class="o">.</span><span class="n">_graph</span><span class="p">,</span> <span class="n">new_types</span><span class="p">,</span> <span class="n">block</span><span class="o">.</span><span class="n">etypes</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">srctype</span> <span class="ow">in</span> <span class="n">block</span><span class="o">.</span><span class="n">srctypes</span><span class="p">:</span>
        <span class="n">retg</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">srctype</span> <span class="o">+</span> <span class="s2">"_src"</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">block</span><span class="o">.</span><span class="n">srcnodes</span><span class="p">[</span><span class="n">srctype</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">dsttype</span> <span class="ow">in</span> <span class="n">block</span><span class="o">.</span><span class="n">dsttypes</span><span class="p">:</span>
        <span class="n">retg</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">dsttype</span> <span class="o">+</span> <span class="s2">"_dst"</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">block</span><span class="o">.</span><span class="n">dstnodes</span><span class="p">[</span><span class="n">dsttype</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">srctype</span><span class="p">,</span> <span class="n">etype</span><span class="p">,</span> <span class="n">dsttype</span> <span class="ow">in</span> <span class="n">block</span><span class="o">.</span><span class="n">canonical_etypes</span><span class="p">:</span>
        <span class="n">retg</span><span class="o">.</span><span class="n">edges</span><span class="p">[</span><span class="n">srctype</span> <span class="o">+</span> <span class="s2">"_src"</span><span class="p">,</span> <span class="n">etype</span><span class="p">,</span> <span class="n">dsttype</span> <span class="o">+</span> <span class="s2">"_dst"</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
            <span class="n">block</span><span class="o">.</span><span class="n">edges</span><span class="p">[</span><span class="n">srctype</span><span class="p">,</span> <span class="n">etype</span><span class="p">,</span> <span class="n">dsttype</span><span class="p">]</span><span class="o">.</span><span class="n">data</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">retg</span></div>



<div class="viewcode-block" id="to_heterogeneous">
<a class="viewcode-back" href="../../generated/dgl.to_heterogeneous.html#dgl.to_heterogeneous">[docs]</a>
<span class="k">def</span> <span class="nf">to_heterogeneous</span><span class="p">(</span>
    <span class="n">G</span><span class="p">,</span> <span class="n">ntypes</span><span class="p">,</span> <span class="n">etypes</span><span class="p">,</span> <span class="n">ntype_field</span><span class="o">=</span><span class="n">NTYPE</span><span class="p">,</span> <span class="n">etype_field</span><span class="o">=</span><span class="n">ETYPE</span><span class="p">,</span> <span class="n">metagraph</span><span class="o">=</span><span class="kc">None</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">"""Convert a homogeneous graph to a heterogeneous graph and return.</span>

<span class="sd">    The input graph should have only one type of nodes and edges. Each node and edge</span>
<span class="sd">    stores an integer feature as its type ID</span>
<span class="sd">    (specified by :attr:`ntype_field` and :attr:`etype_field`).</span>
<span class="sd">    DGL uses it to retrieve the type names stored in the given</span>
<span class="sd">    :attr:`ntypes` and :attr:`etypes` arguments.</span>

<span class="sd">    The function will automatically distinguish edge types that have the same given</span>
<span class="sd">    type IDs but different src and dst type IDs. For example, it allows both edges A and B</span>
<span class="sd">    to have the same type ID 0, but one has (0, 1) and the other as (2, 3) as the</span>
<span class="sd">    (src, dst) type IDs. In this case, the function will "split" edge type 0 into two types:</span>
<span class="sd">    (0, ty_A, 1) and (2, ty_B, 3). In another word, these two edges share the same edge</span>
<span class="sd">    type name, but can be distinguished by an edge type triplet.</span>

<span class="sd">    The function stores the node and edge IDs in the input graph using the ``dgl.NID``</span>
<span class="sd">    and ``dgl.EID`` names in the ``ndata`` and ``edata`` of the resulting graph.</span>
<span class="sd">    It also copies any node/edge features from :attr:`G` to the returned heterogeneous</span>
<span class="sd">    graph, except for reserved fields for storing type IDs (``dgl.NTYPE`` and ``dgl.ETYPE``)</span>
<span class="sd">    and node/edge IDs (``dgl.NID`` and ``dgl.EID``).</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    G : DGLGraph</span>
<span class="sd">        The homogeneous graph.</span>
<span class="sd">    ntypes : list[str]</span>
<span class="sd">        The node type names.</span>
<span class="sd">    etypes : list[str]</span>
<span class="sd">        The edge type names.</span>
<span class="sd">    ntype_field : str, optional</span>
<span class="sd">        The feature field used to store node type. (Default: ``dgl.NTYPE``)</span>
<span class="sd">    etype_field : str, optional</span>
<span class="sd">        The feature field used to store edge type. (Default: ``dgl.ETYPE``)</span>
<span class="sd">    metagraph : networkx MultiDiGraph, optional</span>
<span class="sd">        Metagraph of the returned heterograph.</span>
<span class="sd">        If provided, DGL assumes that G can indeed be described with the given metagraph.</span>
<span class="sd">        If None, DGL will infer the metagraph from the given inputs, which could be</span>
<span class="sd">        costly for large graphs.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    DGLGraph</span>
<span class="sd">        A heterogeneous graph.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    * The returned node and edge types may not necessarily be in the same order as</span>
<span class="sd">      ``ntypes`` and ``etypes``.</span>
<span class="sd">    * Calling :func:`~dgl.to_homogeneous` then calling :func:`~dgl.to_heterogeneous` again</span>
<span class="sd">      yields the same result.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    The following example uses PyTorch backend.</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>

<span class="sd">    &gt;&gt;&gt; hg = dgl.heterograph({</span>
<span class="sd">    ...     ('user', 'develops', 'activity'): (torch.tensor([0, 1]), torch.tensor([1, 2])),</span>
<span class="sd">    ...     ('developer', 'develops', 'game'): (torch.tensor([0, 1]), torch.tensor([0, 1]))</span>
<span class="sd">    ... })</span>
<span class="sd">    &gt;&gt;&gt; print(hg)</span>
<span class="sd">    Graph(num_nodes={'activity': 3, 'developer': 2, 'game': 2, 'user': 2},</span>
<span class="sd">          num_edges={('developer', 'develops', 'game'): 2, ('user', 'develops', 'activity'): 2},</span>
<span class="sd">          metagraph=[('developer', 'game', 'develops'), ('user', 'activity', 'develops')])</span>

<span class="sd">    We first convert the heterogeneous graph to a homogeneous graph.</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.to_homogeneous(hg)</span>
<span class="sd">    &gt;&gt;&gt; print(g)</span>
<span class="sd">    Graph(num_nodes=9, num_edges=4,</span>
<span class="sd">          ndata_schemes={'_TYPE': Scheme(shape=(), dtype=torch.int64),</span>
<span class="sd">                         '_ID': Scheme(shape=(), dtype=torch.int64)}</span>
<span class="sd">          edata_schemes={'_TYPE': Scheme(shape=(), dtype=torch.int64),</span>
<span class="sd">                         '_ID': Scheme(shape=(), dtype=torch.int64)})</span>
<span class="sd">    &gt;&gt;&gt; g.ndata</span>
<span class="sd">    {'_TYPE': tensor([0, 0, 0, 1, 1, 2, 2, 3, 3]), '_ID': tensor([0, 1, 2, 0, 1, 0, 1, 0, 1])}</span>
<span class="sd">    Nodes 0, 1, 2 for 'activity', 3, 4 for 'developer', 5, 6 for 'game', 7, 8 for 'user'</span>
<span class="sd">    &gt;&gt;&gt; g.edata</span>
<span class="sd">    {'_TYPE': tensor([0, 0, 1, 1]), '_ID': tensor([0, 1, 0, 1])}</span>
<span class="sd">    Edges 0, 1 for ('developer', 'develops', 'game'), 2, 3 for ('user', 'develops', 'activity')</span>

<span class="sd">    Now convert the homogeneous graph back to a heterogeneous graph.</span>

<span class="sd">    &gt;&gt;&gt; hg_2 = dgl.to_heterogeneous(g, hg.ntypes, hg.etypes)</span>
<span class="sd">    &gt;&gt;&gt; print(hg_2)</span>
<span class="sd">    Graph(num_nodes={'activity': 3, 'developer': 2, 'game': 2, 'user': 2},</span>
<span class="sd">          num_edges={('developer', 'develops', 'game'): 2, ('user', 'develops', 'activity'): 2},</span>
<span class="sd">          metagraph=[('developer', 'game', 'develops'), ('user', 'activity', 'develops')])</span>

<span class="sd">    Retrieve the original node/edge IDs.</span>

<span class="sd">    &gt;&gt;&gt; hg_2.ndata[dgl.NID]</span>
<span class="sd">    {'activity': tensor([0, 1, 2]),</span>
<span class="sd">     'developer': tensor([3, 4]),</span>
<span class="sd">     'game': tensor([5, 6]),</span>
<span class="sd">     'user': tensor([7, 8])}</span>
<span class="sd">    &gt;&gt;&gt; hg_2.edata[dgl.EID]</span>
<span class="sd">    {('developer', 'develops', 'game'): tensor([0, 1]),</span>
<span class="sd">     ('user', 'develops', 'activity'): tensor([2, 3])}</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    to_homogeneous</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="p">(</span>
        <span class="nb">hasattr</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="s2">"ntypes"</span><span class="p">)</span>
        <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">G</span><span class="o">.</span><span class="n">ntypes</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span>
        <span class="ow">or</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="s2">"etypes"</span><span class="p">)</span>
        <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">G</span><span class="o">.</span><span class="n">etypes</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span>
    <span class="p">):</span>
        <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
            <span class="s2">"The input graph should be homogeneous and have only one "</span>
            <span class="s2">" type of nodes and edges."</span>
        <span class="p">)</span>

    <span class="n">num_ntypes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ntypes</span><span class="p">)</span>
    <span class="n">idtype</span> <span class="o">=</span> <span class="n">G</span><span class="o">.</span><span class="n">idtype</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">G</span><span class="o">.</span><span class="n">device</span>

    <span class="n">ntype_ids</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(</span><span class="n">G</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="n">ntype_field</span><span class="p">])</span>
    <span class="n">etype_ids</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(</span><span class="n">G</span><span class="o">.</span><span class="n">edata</span><span class="p">[</span><span class="n">etype_field</span><span class="p">])</span>

    <span class="c1"># relabel nodes to per-type local IDs</span>
    <span class="n">ntype_count</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">ntype_ids</span><span class="p">,</span> <span class="n">minlength</span><span class="o">=</span><span class="n">num_ntypes</span><span class="p">)</span>
    <span class="n">ntype_offset</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">ntype_count</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">ntype_ids_sortidx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">ntype_ids</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s2">"stable"</span><span class="p">)</span>
    <span class="n">ntype_local_ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">ntype_ids</span><span class="p">)</span>
    <span class="n">node_groups</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_ntypes</span><span class="p">):</span>
        <span class="n">node_group</span> <span class="o">=</span> <span class="n">ntype_ids_sortidx</span><span class="p">[</span><span class="n">ntype_offset</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="p">:</span> <span class="n">ntype_offset</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]]</span>
        <span class="n">node_groups</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node_group</span><span class="p">)</span>
        <span class="n">ntype_local_ids</span><span class="p">[</span><span class="n">node_group</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">ntype_count</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

    <span class="n">src</span><span class="p">,</span> <span class="n">dst</span> <span class="o">=</span> <span class="n">G</span><span class="o">.</span><span class="n">all_edges</span><span class="p">(</span><span class="n">order</span><span class="o">=</span><span class="s2">"eid"</span><span class="p">)</span>
    <span class="n">src</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(</span><span class="n">src</span><span class="p">)</span>
    <span class="n">dst</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(</span><span class="n">dst</span><span class="p">)</span>
    <span class="n">src_local</span> <span class="o">=</span> <span class="n">ntype_local_ids</span><span class="p">[</span><span class="n">src</span><span class="p">]</span>
    <span class="n">dst_local</span> <span class="o">=</span> <span class="n">ntype_local_ids</span><span class="p">[</span><span class="n">dst</span><span class="p">]</span>
    <span class="c1"># a 2D tensor of shape (E, 3). Each row represents the (stid, etid, dtid) tuple.</span>
    <span class="n">edge_ctids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">ntype_ids</span><span class="p">[</span><span class="n">src</span><span class="p">],</span> <span class="n">etype_ids</span><span class="p">,</span> <span class="n">ntype_ids</span><span class="p">[</span><span class="n">dst</span><span class="p">]],</span> <span class="mi">1</span><span class="p">)</span>

    <span class="c1"># infer metagraph and canonical edge types</span>
    <span class="c1"># No matter which branch it takes, the code will generate a 2D tensor of shape (E_m, 3),</span>
    <span class="c1"># E_m is the set of all possible canonical edge tuples. Each row represents the</span>
    <span class="c1"># (stid, dtid, dtid) tuple. We then compute a 2D tensor of shape (E, E_m) using the</span>
    <span class="c1"># above ``edge_ctids`` matrix. Each element i,j indicates whether the edge i is of the</span>
    <span class="c1"># canonical edge type j. We can then group the edges of the same type together.</span>
    <span class="k">if</span> <span class="n">metagraph</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">canonical_etids</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">etype_remapped</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">make_invmap</span><span class="p">(</span>
            <span class="nb">list</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">_</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">edge_ctids</span><span class="p">),</span> <span class="kc">False</span>
        <span class="p">)</span>
        <span class="n">etype_mask</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">etype_remapped</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">canonical_etids</span><span class="p">))[:,</span> <span class="kc">None</span><span class="p">]</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">ntypes_invmap</span> <span class="o">=</span> <span class="p">{</span><span class="n">nt</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">nt</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">ntypes</span><span class="p">)}</span>
        <span class="n">etypes_invmap</span> <span class="o">=</span> <span class="p">{</span><span class="n">et</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">et</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">etypes</span><span class="p">)}</span>
        <span class="n">canonical_etids</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">srctype</span><span class="p">,</span> <span class="n">dsttype</span><span class="p">,</span> <span class="n">etype</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span>
            <span class="n">metagraph</span><span class="o">.</span><span class="n">edges</span><span class="p">(</span><span class="n">keys</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="n">srctype_id</span> <span class="o">=</span> <span class="n">ntypes_invmap</span><span class="p">[</span><span class="n">srctype</span><span class="p">]</span>
            <span class="n">etype_id</span> <span class="o">=</span> <span class="n">etypes_invmap</span><span class="p">[</span><span class="n">etype</span><span class="p">]</span>
            <span class="n">dsttype_id</span> <span class="o">=</span> <span class="n">ntypes_invmap</span><span class="p">[</span><span class="n">dsttype</span><span class="p">]</span>
            <span class="n">canonical_etids</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">srctype_id</span><span class="p">,</span> <span class="n">etype_id</span><span class="p">,</span> <span class="n">dsttype_id</span><span class="p">))</span>
        <span class="n">canonical_etids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">canonical_etids</span><span class="p">)</span>
        <span class="n">etype_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">edge_ctids</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span> <span class="o">==</span> <span class="n">canonical_etids</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">])</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">edge_groups</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">etype_mask</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">nonzero</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">canonical_etids</span><span class="p">))</span>
    <span class="p">]</span>

    <span class="n">data_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="n">canonical_etypes</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">stid</span><span class="p">,</span> <span class="n">etid</span><span class="p">,</span> <span class="n">dtid</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">canonical_etids</span><span class="p">):</span>
        <span class="n">src_of_etype</span> <span class="o">=</span> <span class="n">src_local</span><span class="p">[</span><span class="n">edge_groups</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>
        <span class="n">dst_of_etype</span> <span class="o">=</span> <span class="n">dst_local</span><span class="p">[</span><span class="n">edge_groups</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>
        <span class="n">canonical_etypes</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">ntypes</span><span class="p">[</span><span class="n">stid</span><span class="p">],</span> <span class="n">etypes</span><span class="p">[</span><span class="n">etid</span><span class="p">],</span> <span class="n">ntypes</span><span class="p">[</span><span class="n">dtid</span><span class="p">]))</span>
        <span class="n">data_dict</span><span class="p">[</span><span class="n">canonical_etypes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="p">(</span><span class="n">src_of_etype</span><span class="p">,</span> <span class="n">dst_of_etype</span><span class="p">)</span>
    <span class="n">hg</span> <span class="o">=</span> <span class="n">heterograph</span><span class="p">(</span>
        <span class="n">data_dict</span><span class="p">,</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">ntypes</span><span class="p">,</span> <span class="n">ntype_count</span><span class="p">)),</span> <span class="n">idtype</span><span class="o">=</span><span class="n">idtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span>
    <span class="p">)</span>

    <span class="n">ntype2ngrp</span> <span class="o">=</span> <span class="p">{</span><span class="n">ntype</span><span class="p">:</span> <span class="n">node_groups</span><span class="p">[</span><span class="n">ntid</span><span class="p">]</span> <span class="k">for</span> <span class="n">ntid</span><span class="p">,</span> <span class="n">ntype</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">ntypes</span><span class="p">)}</span>

    <span class="c1"># features</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">G</span><span class="o">.</span><span class="n">ndata</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="p">[</span><span class="n">ntype_field</span><span class="p">,</span> <span class="n">NID</span><span class="p">]:</span>
            <span class="k">continue</span>
        <span class="k">for</span> <span class="n">ntid</span><span class="p">,</span> <span class="n">ntype</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">hg</span><span class="o">.</span><span class="n">ntypes</span><span class="p">):</span>
            <span class="n">rows</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">copy_to</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">ntype2ngrp</span><span class="p">[</span><span class="n">ntype</span><span class="p">]),</span> <span class="n">F</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
            <span class="n">hg</span><span class="o">.</span><span class="n">_node_frames</span><span class="p">[</span><span class="n">ntid</span><span class="p">][</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">gather_row</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">rows</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">G</span><span class="o">.</span><span class="n">edata</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="p">[</span><span class="n">etype_field</span><span class="p">,</span> <span class="n">EID</span><span class="p">]:</span>
            <span class="k">continue</span>
        <span class="k">for</span> <span class="n">etid</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">hg</span><span class="o">.</span><span class="n">canonical_etypes</span><span class="p">)):</span>
            <span class="n">rows</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">copy_to</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">edge_groups</span><span class="p">[</span><span class="n">etid</span><span class="p">]),</span> <span class="n">F</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
            <span class="n">hg</span><span class="o">.</span><span class="n">_edge_frames</span><span class="p">[</span><span class="n">hg</span><span class="o">.</span><span class="n">get_etype_id</span><span class="p">(</span><span class="n">canonical_etypes</span><span class="p">[</span><span class="n">etid</span><span class="p">])][</span>
                <span class="n">key</span>
            <span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">gather_row</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">rows</span><span class="p">)</span>

    <span class="c1"># Record the original IDs of the nodes/edges</span>
    <span class="k">for</span> <span class="n">ntid</span><span class="p">,</span> <span class="n">ntype</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">hg</span><span class="o">.</span><span class="n">ntypes</span><span class="p">):</span>
        <span class="n">hg</span><span class="o">.</span><span class="n">_node_frames</span><span class="p">[</span><span class="n">ntid</span><span class="p">][</span><span class="n">NID</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">copy_to</span><span class="p">(</span>
            <span class="n">F</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">ntype2ngrp</span><span class="p">[</span><span class="n">ntype</span><span class="p">]),</span> <span class="n">device</span>
        <span class="p">)</span>
    <span class="k">for</span> <span class="n">etid</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">hg</span><span class="o">.</span><span class="n">canonical_etypes</span><span class="p">)):</span>
        <span class="n">hg</span><span class="o">.</span><span class="n">_edge_frames</span><span class="p">[</span><span class="n">hg</span><span class="o">.</span><span class="n">get_etype_id</span><span class="p">(</span><span class="n">canonical_etypes</span><span class="p">[</span><span class="n">etid</span><span class="p">])][</span>
            <span class="n">EID</span>
        <span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">copy_to</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">edge_groups</span><span class="p">[</span><span class="n">etid</span><span class="p">]),</span> <span class="n">device</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">hg</span></div>



<div class="viewcode-block" id="to_homogeneous">
<a class="viewcode-back" href="../../generated/dgl.to_homogeneous.html#dgl.to_homogeneous">[docs]</a>
<span class="k">def</span> <span class="nf">to_homogeneous</span><span class="p">(</span>
    <span class="n">G</span><span class="p">,</span> <span class="n">ndata</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">edata</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">store_type</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_count</span><span class="o">=</span><span class="kc">False</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">"""Convert a heterogeneous graph to a homogeneous graph and return.</span>

<span class="sd">    By default, the function stores the node and edge types of the input graph as</span>
<span class="sd">    the ``dgl.NTYPE`` and ``dgl.ETYPE`` features in the returned graph.</span>
<span class="sd">    Each feature is an integer representing the type id, determined by the</span>
<span class="sd">    :meth:`DGLGraph.get_ntype_id` and :meth:`DGLGraph.get_etype_id` methods.</span>
<span class="sd">    One can omit it by specifying ``store_type=False``.</span>

<span class="sd">    The result graph assigns nodes and edges of the same type with IDs in continuous range</span>
<span class="sd">    (i.e., nodes of the first type have IDs 0 ~ ``G.num_nodes(G.ntypes[0])``; nodes</span>
<span class="sd">    of the second type come after; so on and so forth). Therefore, a more memory-efficient</span>
<span class="sd">    format for type information is an integer list; the i^th corresponds to</span>
<span class="sd">    the number of nodes/edges of the i^th type. One can choose this format by</span>
<span class="sd">    specifying ``return_count=True``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    G : DGLGraph</span>
<span class="sd">        The heterogeneous graph.</span>
<span class="sd">    ndata : list[str], optional</span>
<span class="sd">        The node features to combine across all node types. For each feature ``feat`` in</span>
<span class="sd">        :attr:`ndata`, it concatenates ``G.nodes[T].data[feat]`` across all node types ``T``.</span>
<span class="sd">        As a result, the feature ``feat`` of all node types should have the same shape and</span>
<span class="sd">        data type. By default, the returned graph will not have any node features.</span>
<span class="sd">    edata : list[str], optional</span>
<span class="sd">        The edge features to combine across all edge types. For each feature ``feat`` in</span>
<span class="sd">        :attr:`edata`, it concatenates ``G.edges[T].data[feat]`` across all edge types ``T``.</span>
<span class="sd">        As a result, the feature ``feat`` of all edge types should have the same shape and</span>
<span class="sd">        data type. By default, the returned graph will not have any edge features.</span>
<span class="sd">    store_type : bool, optional</span>
<span class="sd">        If True, store type information as the ``dgl.NTYPE`` and ``dgl.ETYPE`` features</span>
<span class="sd">        in the returned graph.</span>
<span class="sd">    return_count : bool, optional</span>
<span class="sd">        If True, return type information as an integer list; the i^th element corresponds to</span>
<span class="sd">        the number of nodes/edges of the i^th type.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    DGLGraph</span>
<span class="sd">        A homogeneous graph.</span>
<span class="sd">    ntype_count : list[int], optional</span>
<span class="sd">        Number of nodes of each type. Return when ``return_count`` is True.</span>
<span class="sd">    etype_count : list[int], optional</span>
<span class="sd">        Number of edges of each type. Return when ``return_count`` is True.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>

<span class="sd">    * Calculating type information may introduce noticeable cost. Setting both ``store_type``</span>
<span class="sd">      and ``return_count`` to False can avoid such cost if type information is not needed.</span>
<span class="sd">      Otherwise, DGL recommends to use ``store_type=False`` and ``return_count=True`` due</span>
<span class="sd">      to its memory efficiency.</span>
<span class="sd">    * The ``ntype_count`` and ``etype_count`` lists can help speed up some operations.</span>
<span class="sd">      See :class:`~dgl.nn.pytorch.conv.RelGraphConv` for such an example.</span>
<span class="sd">    * Calling :func:`~dgl.to_homogeneous` then calling :func:`~dgl.to_heterogeneous` again</span>
<span class="sd">      yields the same result.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    The following example uses PyTorch backend.</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>

<span class="sd">    &gt;&gt;&gt; hg = dgl.heterograph({</span>
<span class="sd">    ...     ('user', 'follows', 'user'): ([0, 1], [1, 2]),</span>
<span class="sd">    ...     ('developer', 'develops', 'game'): ([0, 1], [0, 1])</span>
<span class="sd">    ...     })</span>
<span class="sd">    &gt;&gt;&gt; hg.nodes['user'].data['h'] = torch.ones(3, 1)</span>
<span class="sd">    &gt;&gt;&gt; hg.nodes['developer'].data['h'] = torch.zeros(2, 1)</span>
<span class="sd">    &gt;&gt;&gt; hg.nodes['game'].data['h'] = torch.ones(2, 1)</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.to_homogeneous(hg)</span>
<span class="sd">    &gt;&gt;&gt; # The first three nodes are for 'user', the next two are for 'developer',</span>
<span class="sd">    &gt;&gt;&gt; # and the last two are for 'game'</span>
<span class="sd">    &gt;&gt;&gt; g.ndata</span>
<span class="sd">    {'_TYPE': tensor([0, 0, 0, 1, 1, 2, 2]), '_ID': tensor([0, 1, 2, 0, 1, 0, 1])}</span>
<span class="sd">    &gt;&gt;&gt; # The first two edges are for 'follows', and the next two are for 'develops' edges.</span>
<span class="sd">    &gt;&gt;&gt; g.edata</span>
<span class="sd">    {'_TYPE': tensor([0, 0, 1, 1]), '_ID': tensor([0, 1, 0, 1])}</span>

<span class="sd">    Combine feature 'h' across all node types in the conversion.</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.to_homogeneous(hg, ndata=['h'])</span>
<span class="sd">    &gt;&gt;&gt; g.ndata['h']</span>
<span class="sd">    tensor([[1.], [1.], [1.], [0.], [0.], [1.], [1.]])</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    to_heterogeneous</span>
<span class="sd">    """</span>
    <span class="n">num_nodes_per_ntype</span> <span class="o">=</span> <span class="p">[</span><span class="n">G</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">(</span><span class="n">ntype</span><span class="p">)</span> <span class="k">for</span> <span class="n">ntype</span> <span class="ow">in</span> <span class="n">G</span><span class="o">.</span><span class="n">ntypes</span><span class="p">]</span>
    <span class="n">offset_per_ntype</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">num_nodes_per_ntype</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">srcs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">dsts</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">nids</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">eids</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">if</span> <span class="n">store_type</span><span class="p">:</span>
        <span class="n">ntype_ids</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">etype_ids</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">if</span> <span class="n">return_count</span><span class="p">:</span>
        <span class="n">ntype_count</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">etype_count</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">total_num_nodes</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">ntype_id</span><span class="p">,</span> <span class="n">ntype</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">G</span><span class="o">.</span><span class="n">ntypes</span><span class="p">):</span>
        <span class="n">num_nodes</span> <span class="o">=</span> <span class="n">G</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">(</span><span class="n">ntype</span><span class="p">)</span>
        <span class="n">total_num_nodes</span> <span class="o">+=</span> <span class="n">num_nodes</span>
        <span class="k">if</span> <span class="n">store_type</span><span class="p">:</span>
            <span class="c1"># Type ID is always in int64</span>
            <span class="n">ntype_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">full_1d</span><span class="p">(</span><span class="n">num_nodes</span><span class="p">,</span> <span class="n">ntype_id</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">G</span><span class="o">.</span><span class="n">device</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">return_count</span><span class="p">:</span>
            <span class="n">ntype_count</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">num_nodes</span><span class="p">)</span>
        <span class="n">nids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_nodes</span><span class="p">,</span> <span class="n">G</span><span class="o">.</span><span class="n">idtype</span><span class="p">,</span> <span class="n">G</span><span class="o">.</span><span class="n">device</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">etype_id</span><span class="p">,</span> <span class="n">etype</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">G</span><span class="o">.</span><span class="n">canonical_etypes</span><span class="p">):</span>
        <span class="n">srctype</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">dsttype</span> <span class="o">=</span> <span class="n">etype</span>
        <span class="n">src</span><span class="p">,</span> <span class="n">dst</span> <span class="o">=</span> <span class="n">G</span><span class="o">.</span><span class="n">all_edges</span><span class="p">(</span><span class="n">etype</span><span class="o">=</span><span class="n">etype</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">"eid"</span><span class="p">)</span>
        <span class="n">num_edges</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">src</span><span class="p">)</span>
        <span class="n">srcs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">src</span> <span class="o">+</span> <span class="nb">int</span><span class="p">(</span><span class="n">offset_per_ntype</span><span class="p">[</span><span class="n">G</span><span class="o">.</span><span class="n">get_ntype_id</span><span class="p">(</span><span class="n">srctype</span><span class="p">)]))</span>
        <span class="n">dsts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dst</span> <span class="o">+</span> <span class="nb">int</span><span class="p">(</span><span class="n">offset_per_ntype</span><span class="p">[</span><span class="n">G</span><span class="o">.</span><span class="n">get_ntype_id</span><span class="p">(</span><span class="n">dsttype</span><span class="p">)]))</span>
        <span class="k">if</span> <span class="n">store_type</span><span class="p">:</span>
            <span class="c1"># Type ID is always in int64</span>
            <span class="n">etype_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">full_1d</span><span class="p">(</span><span class="n">num_edges</span><span class="p">,</span> <span class="n">etype_id</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">G</span><span class="o">.</span><span class="n">device</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">return_count</span><span class="p">:</span>
            <span class="n">etype_count</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">num_edges</span><span class="p">)</span>
        <span class="n">eids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_edges</span><span class="p">,</span> <span class="n">G</span><span class="o">.</span><span class="n">idtype</span><span class="p">,</span> <span class="n">G</span><span class="o">.</span><span class="n">device</span><span class="p">))</span>

    <span class="n">retg</span> <span class="o">=</span> <span class="n">graph</span><span class="p">(</span>
        <span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">srcs</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">F</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">dsts</span><span class="p">,</span> <span class="mi">0</span><span class="p">)),</span>
        <span class="n">num_nodes</span><span class="o">=</span><span class="n">total_num_nodes</span><span class="p">,</span>
        <span class="n">idtype</span><span class="o">=</span><span class="n">G</span><span class="o">.</span><span class="n">idtype</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="n">G</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># copy features</span>
    <span class="k">if</span> <span class="n">ndata</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">ndata</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">if</span> <span class="n">edata</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">edata</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">comb_nf</span> <span class="o">=</span> <span class="n">combine_frames</span><span class="p">(</span>
        <span class="n">G</span><span class="o">.</span><span class="n">_node_frames</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">G</span><span class="o">.</span><span class="n">ntypes</span><span class="p">)),</span> <span class="n">col_names</span><span class="o">=</span><span class="n">ndata</span>
    <span class="p">)</span>
    <span class="n">comb_ef</span> <span class="o">=</span> <span class="n">combine_frames</span><span class="p">(</span>
        <span class="n">G</span><span class="o">.</span><span class="n">_edge_frames</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">G</span><span class="o">.</span><span class="n">etypes</span><span class="p">)),</span> <span class="n">col_names</span><span class="o">=</span><span class="n">edata</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">comb_nf</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">retg</span><span class="o">.</span><span class="n">ndata</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">comb_nf</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">comb_ef</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">retg</span><span class="o">.</span><span class="n">edata</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">comb_ef</span><span class="p">)</span>

    <span class="n">retg</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="n">NID</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">nids</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">retg</span><span class="o">.</span><span class="n">edata</span><span class="p">[</span><span class="n">EID</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">eids</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">store_type</span><span class="p">:</span>
        <span class="n">retg</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="n">NTYPE</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">ntype_ids</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">retg</span><span class="o">.</span><span class="n">edata</span><span class="p">[</span><span class="n">ETYPE</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">etype_ids</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">return_count</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">retg</span><span class="p">,</span> <span class="n">ntype_count</span><span class="p">,</span> <span class="n">etype_count</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">retg</span></div>



<div class="viewcode-block" id="from_scipy">
<a class="viewcode-back" href="../../generated/dgl.from_scipy.html#dgl.from_scipy">[docs]</a>
<span class="k">def</span> <span class="nf">from_scipy</span><span class="p">(</span><span class="n">sp_mat</span><span class="p">,</span> <span class="n">eweight_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">idtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Create a graph from a SciPy sparse matrix and return.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    sp_mat : scipy.sparse.spmatrix</span>
<span class="sd">        The graph adjacency matrix. Each nonzero entry ``sp_mat[i, j]`` represents an edge from</span>
<span class="sd">        node ``i`` to ``j``. The matrix must have square shape ``(N, N)``, where ``N`` is the</span>
<span class="sd">        number of nodes in the graph.</span>
<span class="sd">    eweight_name : str, optional</span>
<span class="sd">        The edata name for storing the nonzero values of :attr:`sp_mat`. If given, DGL will</span>
<span class="sd">        store the nonzero values of :attr:`sp_mat` in ``edata[eweight_name]`` of the returned</span>
<span class="sd">        graph.</span>
<span class="sd">    idtype : int32 or int64, optional</span>
<span class="sd">        The data type for storing the structure-related graph information such as node and</span>
<span class="sd">        edge IDs. It should be a framework-specific data type object (e.g., ``torch.int32``).</span>
<span class="sd">        By default, DGL uses int64.</span>
<span class="sd">    device : device context, optional</span>
<span class="sd">        The device of the resulting graph. It should be a framework-specific device object</span>
<span class="sd">        (e.g., ``torch.device``). By default, DGL stores the graph on CPU.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    DGLGraph</span>
<span class="sd">        The created graph.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    1. The function supports all kinds of SciPy sparse matrix classes (e.g.,</span>
<span class="sd">       :class:`scipy.sparse.csr.csr_matrix`). It converts the input matrix to the COOrdinate</span>
<span class="sd">       format using :func:`scipy.sparse.spmatrix.tocoo` before creates a :class:`DGLGraph`.</span>
<span class="sd">       Creating from a :class:`scipy.sparse.coo.coo_matrix` is hence the most efficient way.</span>
<span class="sd">    2. DGL internally maintains multiple copies of the graph structure in different sparse</span>
<span class="sd">       formats and chooses the most efficient one depending on the computation invoked.</span>
<span class="sd">       If memory usage becomes an issue in the case of large graphs, use</span>
<span class="sd">       :func:`dgl.DGLGraph.formats` to restrict the allowed formats.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    The following example uses PyTorch backend.</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; from scipy.sparse import coo_matrix</span>

<span class="sd">    Create a small three-edge graph.</span>

<span class="sd">    &gt;&gt;&gt; # Source nodes for edges (2, 1), (3, 2), (4, 3)</span>
<span class="sd">    &gt;&gt;&gt; src_ids = np.array([2, 3, 4])</span>
<span class="sd">    &gt;&gt;&gt; # Destination nodes for edges (2, 1), (3, 2), (4, 3)</span>
<span class="sd">    &gt;&gt;&gt; dst_ids = np.array([1, 2, 3])</span>
<span class="sd">    &gt;&gt;&gt; # Weight for edges (2, 1), (3, 2), (4, 3)</span>
<span class="sd">    &gt;&gt;&gt; eweight = np.array([0.2, 0.3, 0.5])</span>
<span class="sd">    &gt;&gt;&gt; sp_mat = coo_matrix((eweight, (src_ids, dst_ids)), shape=(5, 5))</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.from_scipy(sp_mat)</span>

<span class="sd">    Retrieve the edge weights.</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.from_scipy(sp_mat, eweight_name='w')</span>
<span class="sd">    &gt;&gt;&gt; g.edata['w']</span>
<span class="sd">    tensor([0.2000, 0.3000, 0.5000], dtype=torch.float64)</span>

<span class="sd">    Create a graph on the first GPU with data type int32.</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.from_scipy(sp_mat, idtype=torch.int32, device='cuda:0')</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    graph</span>
<span class="sd">    from_networkx</span>
<span class="sd">    """</span>
    <span class="c1"># Sanity check</span>
    <span class="n">num_rows</span> <span class="o">=</span> <span class="n">sp_mat</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">num_cols</span> <span class="o">=</span> <span class="n">sp_mat</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">num_rows</span> <span class="o">!=</span> <span class="n">num_cols</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
            <span class="s2">"Expect the number of rows to be the same as the number of columns for "</span>
            <span class="s2">"sp_mat, got </span><span class="si">{:d}</span><span class="s2"> and </span><span class="si">{:d}</span><span class="s2">."</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">num_rows</span><span class="p">,</span> <span class="n">num_cols</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="p">(</span><span class="n">sparse_fmt</span><span class="p">,</span> <span class="n">arrays</span><span class="p">),</span> <span class="n">urange</span><span class="p">,</span> <span class="n">vrange</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">graphdata2tensors</span><span class="p">(</span>
        <span class="n">sp_mat</span><span class="p">,</span> <span class="n">idtype</span>
    <span class="p">)</span>
    <span class="n">g</span> <span class="o">=</span> <span class="n">create_from_edges</span><span class="p">(</span><span class="n">sparse_fmt</span><span class="p">,</span> <span class="n">arrays</span><span class="p">,</span> <span class="s2">"_N"</span><span class="p">,</span> <span class="s2">"_E"</span><span class="p">,</span> <span class="s2">"_N"</span><span class="p">,</span> <span class="n">urange</span><span class="p">,</span> <span class="n">vrange</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">eweight_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">g</span><span class="o">.</span><span class="n">edata</span><span class="p">[</span><span class="n">eweight_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">sp_mat</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">g</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span></div>



<div class="viewcode-block" id="bipartite_from_scipy">
<a class="viewcode-back" href="../../generated/dgl.bipartite_from_scipy.html#dgl.bipartite_from_scipy">[docs]</a>
<span class="k">def</span> <span class="nf">bipartite_from_scipy</span><span class="p">(</span>
    <span class="n">sp_mat</span><span class="p">,</span> <span class="n">utype</span><span class="p">,</span> <span class="n">etype</span><span class="p">,</span> <span class="n">vtype</span><span class="p">,</span> <span class="n">eweight_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">idtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">"""Create a uni-directional bipartite graph from a SciPy sparse matrix and return.</span>

<span class="sd">    The created graph will have two types of nodes ``utype`` and ``vtype`` as well as one</span>
<span class="sd">    edge type ``etype`` whose edges are from ``utype`` to ``vtype``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    sp_mat : scipy.sparse.spmatrix</span>
<span class="sd">        The graph adjacency matrix. Each nonzero entry ``sp_mat[i, j]``</span>
<span class="sd">        represents an edge from node ``i`` of type :attr:`utype` to ``j`` of type :attr:`vtype`.</span>
<span class="sd">        Let the matrix shape be ``(N, M)``. There will be ``N`` nodes of type :attr:`utype`</span>
<span class="sd">        and ``M`` nodes of type ``vtype`` in the resulting graph.</span>
<span class="sd">    utype : str, optional</span>
<span class="sd">        The name of the source node type.</span>
<span class="sd">    etype : str, optional</span>
<span class="sd">        The name of the edge type.</span>
<span class="sd">    vtype : str, optional</span>
<span class="sd">        The name of the destination node type.</span>
<span class="sd">    eweight_name : str, optional</span>
<span class="sd">        The edata name for storing the nonzero values of :attr:`sp_mat`.</span>
<span class="sd">        If given, DGL will store the nonzero values of :attr:`sp_mat` in ``edata[eweight_name]``</span>
<span class="sd">        of the returned graph.</span>
<span class="sd">    idtype : int32 or int64, optional</span>
<span class="sd">        The data type for storing the structure-related graph information such as node and</span>
<span class="sd">        edge IDs. It should be a framework-specific data type object (e.g., ``torch.int32``).</span>
<span class="sd">        By default, DGL uses int64.</span>
<span class="sd">    device : device context, optional</span>
<span class="sd">        The device of the resulting graph. It should be a framework-specific device object</span>
<span class="sd">        (e.g., ``torch.device``). By default, DGL stores the graph on CPU.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    DGLGraph</span>
<span class="sd">        The created graph.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    1. The function supports all kinds of SciPy sparse matrix classes (e.g.,</span>
<span class="sd">       :class:`scipy.sparse.csr.csr_matrix`). It converts the input matrix to the COOrdinate</span>
<span class="sd">       format using :func:`scipy.sparse.spmatrix.tocoo` before creates a :class:`DGLGraph`.</span>
<span class="sd">       Creating from a :class:`scipy.sparse.coo.coo_matrix` is hence the most efficient way.</span>
<span class="sd">    2. DGL internally maintains multiple copies of the graph structure in different sparse</span>
<span class="sd">       formats and chooses the most efficient one depending on the computation invoked.</span>
<span class="sd">       If memory usage becomes an issue in the case of large graphs, use</span>
<span class="sd">       :func:`dgl.DGLGraph.formats` to restrict the allowed formats.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    The following example uses PyTorch backend.</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; from scipy.sparse import coo_matrix</span>

<span class="sd">    Create a small three-edge graph.</span>

<span class="sd">    &gt;&gt;&gt; # Source nodes for edges (2, 1), (3, 2), (4, 3)</span>
<span class="sd">    &gt;&gt;&gt; src_ids = np.array([2, 3, 4])</span>
<span class="sd">    &gt;&gt;&gt; # Destination nodes for edges (2, 1), (3, 2), (4, 3)</span>
<span class="sd">    &gt;&gt;&gt; dst_ids = np.array([1, 2, 3])</span>
<span class="sd">    &gt;&gt;&gt; # Weight for edges (2, 1), (3, 2), (4, 3)</span>
<span class="sd">    &gt;&gt;&gt; eweight = np.array([0.2, 0.3, 0.5])</span>
<span class="sd">    &gt;&gt;&gt; sp_mat = coo_matrix((eweight, (src_ids, dst_ids)))</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.bipartite_from_scipy(sp_mat, utype='_U', etype='_E', vtype='_V')</span>

<span class="sd">    Retrieve the edge weights.</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.bipartite_from_scipy(sp_mat, utype='_U', etype='_E', vtype='_V', eweight_name='w')</span>
<span class="sd">    &gt;&gt;&gt; g.edata['w']</span>
<span class="sd">    tensor([0.2000, 0.3000, 0.5000], dtype=torch.float64)</span>

<span class="sd">    Create a graph on the first GPU with data type int32.</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.bipartite_from_scipy(sp_mat, utype='_U', etype='_E', vtype='_V',</span>
<span class="sd">    ...                              idtype=torch.int32, device='cuda:0')</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    heterograph</span>
<span class="sd">    bipartite_from_networkx</span>
<span class="sd">    """</span>
    <span class="p">(</span><span class="n">sparse_fmt</span><span class="p">,</span> <span class="n">arrays</span><span class="p">),</span> <span class="n">urange</span><span class="p">,</span> <span class="n">vrange</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">graphdata2tensors</span><span class="p">(</span>
        <span class="n">sp_mat</span><span class="p">,</span> <span class="n">idtype</span><span class="p">,</span> <span class="n">bipartite</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>
    <span class="n">g</span> <span class="o">=</span> <span class="n">create_from_edges</span><span class="p">(</span>
        <span class="n">sparse_fmt</span><span class="p">,</span> <span class="n">arrays</span><span class="p">,</span> <span class="n">utype</span><span class="p">,</span> <span class="n">etype</span><span class="p">,</span> <span class="n">vtype</span><span class="p">,</span> <span class="n">urange</span><span class="p">,</span> <span class="n">vrange</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">eweight_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">g</span><span class="o">.</span><span class="n">edata</span><span class="p">[</span><span class="n">eweight_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">sp_mat</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">g</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span></div>



<span class="k">def</span> <span class="nf">_batcher</span><span class="p">(</span><span class="n">lst</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">F</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">lst</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">F</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">lst</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">lst</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">lst</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">lst</span><span class="p">)</span>


<div class="viewcode-block" id="from_networkx">
<a class="viewcode-back" href="../../generated/dgl.from_networkx.html#dgl.from_networkx">[docs]</a>
<span class="k">def</span> <span class="nf">from_networkx</span><span class="p">(</span>
    <span class="n">nx_graph</span><span class="p">,</span>
    <span class="n">node_attrs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">edge_attrs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">edge_id_attr_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">idtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">"""Create a graph from a NetworkX graph and return.</span>

<span class="sd">    .. note::</span>
<span class="sd">        Creating a DGLGraph from a NetworkX graph is not fast especially for large scales.</span>
<span class="sd">        It is recommended to first convert a NetworkX graph into a tuple of node-tensors</span>
<span class="sd">        and then construct a DGLGraph with :func:`dgl.graph`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    nx_graph : networkx.Graph</span>
<span class="sd">        The NetworkX graph holding the graph structure and the node/edge attributes.</span>
<span class="sd">        DGL will relabel the nodes using consecutive integers starting from zero if it is</span>
<span class="sd">        not the case. If the input graph is undirected, DGL converts it to a directed graph</span>
<span class="sd">        by :func:`networkx.Graph.to_directed`.</span>
<span class="sd">    node_attrs : list[str], optional</span>
<span class="sd">        The names of the node attributes to retrieve from the NetworkX graph. If given, DGL</span>
<span class="sd">        stores the retrieved node attributes in ``ndata`` of the returned graph using their</span>
<span class="sd">        original names. The attribute data must be convertible to Tensor type (e.g., scalar,</span>
<span class="sd">        numpy.ndarray, list, etc.).</span>
<span class="sd">    edge_attrs : list[str], optional</span>
<span class="sd">        The names of the edge attributes to retrieve from the NetworkX graph. If given, DGL</span>
<span class="sd">        stores the retrieved edge attributes in ``edata`` of the returned graph using their</span>
<span class="sd">        original names. The attribute data must be convertible to Tensor type (e.g., scalar,</span>
<span class="sd">        ``numpy.ndarray``, list, etc.). It must be None if :attr:`nx_graph` is undirected.</span>
<span class="sd">    edge_id_attr_name : str, optional</span>
<span class="sd">        The name of the edge attribute that stores the edge IDs. If given, DGL will assign edge</span>
<span class="sd">        IDs accordingly when creating the graph, so the attribute must be valid IDs, i.e.</span>
<span class="sd">        consecutive integers starting from zero. By default, the edge IDs of the returned graph</span>
<span class="sd">        can be arbitrary. It must be None if :attr:`nx_graph` is undirected.</span>
<span class="sd">    idtype : int32 or int64, optional</span>
<span class="sd">        The data type for storing the structure-related graph information such as node and</span>
<span class="sd">        edge IDs. It should be a framework-specific data type object (e.g., ``torch.int32``).</span>
<span class="sd">        By default, DGL uses int64.</span>
<span class="sd">    device : device context, optional</span>
<span class="sd">        The device of the resulting graph. It should be a framework-specific device object</span>
<span class="sd">        (e.g., ``torch.device``). By default, DGL stores the graph on CPU.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    DGLGraph</span>
<span class="sd">        The created graph.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    DGL internally maintains multiple copies of the graph structure in different sparse</span>
<span class="sd">    formats and chooses the most efficient one depending on the computation invoked.</span>
<span class="sd">    If memory usage becomes an issue in the case of large graphs, use</span>
<span class="sd">    :func:`dgl.DGLGraph.formats` to restrict the allowed formats.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    The following example uses PyTorch backend.</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import networkx as nx</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>

<span class="sd">    Create a 2-edge NetworkX graph.</span>

<span class="sd">    &gt;&gt;&gt; nx_g = nx.DiGraph()</span>
<span class="sd">    &gt;&gt;&gt; # Add 3 nodes and two features for them</span>
<span class="sd">    &gt;&gt;&gt; nx_g.add_nodes_from([0, 1, 2], feat1=np.zeros((3, 1)), feat2=np.ones((3, 1)))</span>
<span class="sd">    &gt;&gt;&gt; # Add 2 edges (1, 2) and (2, 1) with two features, one being edge IDs</span>
<span class="sd">    &gt;&gt;&gt; nx_g.add_edge(1, 2, weight=np.ones((1, 1)), eid=np.array([1]))</span>
<span class="sd">    &gt;&gt;&gt; nx_g.add_edge(2, 1, weight=np.ones((1, 1)), eid=np.array([0]))</span>

<span class="sd">    Convert it into a DGLGraph with structure only.</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.from_networkx(nx_g)</span>

<span class="sd">    Retrieve the node/edge features of the graph.</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.from_networkx(nx_g, node_attrs=['feat1', 'feat2'], edge_attrs=['weight'])</span>

<span class="sd">    Use a pre-specified ordering of the edges.</span>

<span class="sd">    &gt;&gt;&gt; g.edges()</span>
<span class="sd">    (tensor([1, 2]), tensor([2, 1]))</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.from_networkx(nx_g, edge_id_attr_name='eid')</span>
<span class="sd">    (tensor([2, 1]), tensor([1, 2]))</span>

<span class="sd">    Create a graph on the first GPU with data type int32.</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.from_networkx(nx_g, idtype=torch.int32, device='cuda:0')</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    graph</span>
<span class="sd">    from_scipy</span>
<span class="sd">    """</span>
    <span class="c1"># Sanity check</span>
    <span class="k">if</span> <span class="p">(</span>
        <span class="n">edge_id_attr_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="ow">and</span> <span class="n">edge_id_attr_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">nx_graph</span><span class="o">.</span><span class="n">edges</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="kc">True</span><span class="p">)))[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="p">):</span>
        <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
            <span class="s2">"Failed to find the pre-specified edge IDs in the edge features of "</span>
            <span class="s2">"the NetworkX graph with name </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">edge_id_attr_name</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">nx_graph</span><span class="o">.</span><span class="n">is_directed</span><span class="p">()</span> <span class="ow">and</span> <span class="ow">not</span> <span class="p">(</span>
        <span class="n">edge_id_attr_name</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">edge_attrs</span> <span class="ow">is</span> <span class="kc">None</span>
    <span class="p">):</span>
        <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
            <span class="s2">"Expect edge_id_attr_name and edge_attrs to be None when nx_graph is "</span>
            <span class="s2">"undirected, got </span><span class="si">{}</span><span class="s2"> and </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">edge_id_attr_name</span><span class="p">,</span> <span class="n">edge_attrs</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="c1"># Relabel nodes using consecutive integers starting from 0</span>
    <span class="n">nx_graph</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">convert_node_labels_to_integers</span><span class="p">(</span><span class="n">nx_graph</span><span class="p">,</span> <span class="n">ordering</span><span class="o">=</span><span class="s2">"sorted"</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">nx_graph</span><span class="o">.</span><span class="n">is_directed</span><span class="p">():</span>
        <span class="n">nx_graph</span> <span class="o">=</span> <span class="n">nx_graph</span><span class="o">.</span><span class="n">to_directed</span><span class="p">()</span>

    <span class="p">(</span><span class="n">sparse_fmt</span><span class="p">,</span> <span class="n">arrays</span><span class="p">),</span> <span class="n">urange</span><span class="p">,</span> <span class="n">vrange</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">graphdata2tensors</span><span class="p">(</span>
        <span class="n">nx_graph</span><span class="p">,</span> <span class="n">idtype</span><span class="p">,</span> <span class="n">edge_id_attr_name</span><span class="o">=</span><span class="n">edge_id_attr_name</span>
    <span class="p">)</span>

    <span class="n">g</span> <span class="o">=</span> <span class="n">create_from_edges</span><span class="p">(</span><span class="n">sparse_fmt</span><span class="p">,</span> <span class="n">arrays</span><span class="p">,</span> <span class="s2">"_N"</span><span class="p">,</span> <span class="s2">"_E"</span><span class="p">,</span> <span class="s2">"_N"</span><span class="p">,</span> <span class="n">urange</span><span class="p">,</span> <span class="n">vrange</span><span class="p">)</span>

    <span class="c1"># nx_graph.edges(data=True) returns src, dst, attr_dict</span>
    <span class="n">has_edge_id</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">nx_graph</span><span class="o">.</span><span class="n">number_of_edges</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">edge_id_attr_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="p">)</span>

    <span class="c1"># handle features</span>
    <span class="c1"># copy attributes</span>
    <span class="k">if</span> <span class="n">node_attrs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># mapping from feature name to a list of tensors to be concatenated</span>
        <span class="n">attr_dict</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">nid</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">()):</span>
            <span class="k">for</span> <span class="n">attr</span> <span class="ow">in</span> <span class="n">node_attrs</span><span class="p">:</span>
                <span class="n">attr_dict</span><span class="p">[</span><span class="n">attr</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nx_graph</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">nid</span><span class="p">][</span><span class="n">attr</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">attr</span> <span class="ow">in</span> <span class="n">node_attrs</span><span class="p">:</span>
            <span class="n">g</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="n">attr</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">copy_to</span><span class="p">(</span><span class="n">_batcher</span><span class="p">(</span><span class="n">attr_dict</span><span class="p">[</span><span class="n">attr</span><span class="p">]),</span> <span class="n">g</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">edge_attrs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># mapping from feature name to a list of tensors to be concatenated</span>
        <span class="n">attr_dict</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">g</span><span class="o">.</span><span class="n">num_edges</span><span class="p">())</span>
        <span class="c1"># each defaultdict value is initialized to be a list of None</span>
        <span class="c1"># None here serves as placeholder to be replaced by feature with</span>
        <span class="c1"># corresponding edge id</span>
        <span class="k">if</span> <span class="n">has_edge_id</span><span class="p">:</span>
            <span class="n">num_edges</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">num_edges</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">attrs</span> <span class="ow">in</span> <span class="n">nx_graph</span><span class="o">.</span><span class="n">edges</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">attrs</span><span class="p">[</span><span class="n">edge_id_attr_name</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">num_edges</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                        <span class="s2">"Expect the pre-specified edge ids to be"</span>
                        <span class="s2">" smaller than the number of edges --"</span>
                        <span class="s2">" </span><span class="si">{}</span><span class="s2">, got </span><span class="si">{}</span><span class="s2">."</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">num_edges</span><span class="p">,</span> <span class="n">attrs</span><span class="p">[</span><span class="s2">"id"</span><span class="p">])</span>
                    <span class="p">)</span>
                <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">edge_attrs</span><span class="p">:</span>
                    <span class="n">attr_dict</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="n">attrs</span><span class="p">[</span><span class="n">edge_id_attr_name</span><span class="p">]]</span> <span class="o">=</span> <span class="n">attrs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># XXX: assuming networkx iteration order is deterministic</span>
            <span class="c1">#      so the order is the same as graph_index.from_networkx</span>
            <span class="k">for</span> <span class="n">eid</span><span class="p">,</span> <span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">attrs</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">nx_graph</span><span class="o">.</span><span class="n">edges</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="kc">True</span><span class="p">)):</span>
                <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">edge_attrs</span><span class="p">:</span>
                    <span class="n">attr_dict</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="n">eid</span><span class="p">]</span> <span class="o">=</span> <span class="n">attrs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">attr</span> <span class="ow">in</span> <span class="n">edge_attrs</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">attr_dict</span><span class="p">[</span><span class="n">attr</span><span class="p">]:</span>
                <span class="k">if</span> <span class="n">val</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                        <span class="s2">"Not all edges have attribute </span><span class="si">{}</span><span class="s2">."</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">attr</span><span class="p">)</span>
                    <span class="p">)</span>
            <span class="n">g</span><span class="o">.</span><span class="n">edata</span><span class="p">[</span><span class="n">attr</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">copy_to</span><span class="p">(</span><span class="n">_batcher</span><span class="p">(</span><span class="n">attr_dict</span><span class="p">[</span><span class="n">attr</span><span class="p">]),</span> <span class="n">g</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">g</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span></div>



<div class="viewcode-block" id="bipartite_from_networkx">
<a class="viewcode-back" href="../../generated/dgl.bipartite_from_networkx.html#dgl.bipartite_from_networkx">[docs]</a>
<span class="k">def</span> <span class="nf">bipartite_from_networkx</span><span class="p">(</span>
    <span class="n">nx_graph</span><span class="p">,</span>
    <span class="n">utype</span><span class="p">,</span>
    <span class="n">etype</span><span class="p">,</span>
    <span class="n">vtype</span><span class="p">,</span>
    <span class="n">u_attrs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">e_attrs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">v_attrs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">edge_id_attr_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">idtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">"""Create a unidirectional bipartite graph from a NetworkX graph and return.</span>

<span class="sd">    The created graph will have two types of nodes ``utype`` and ``vtype`` as well as one</span>
<span class="sd">    edge type ``etype`` whose edges are from ``utype`` to ``vtype``.</span>

<span class="sd">    .. note::</span>
<span class="sd">        Creating a DGLGraph from a NetworkX graph is not fast especially for large scales.</span>
<span class="sd">        It is recommended to first convert a NetworkX graph into a tuple of node-tensors</span>
<span class="sd">        and then construct a DGLGraph with :func:`dgl.heterograph`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    nx_graph : networkx.DiGraph</span>
<span class="sd">        The NetworkX graph holding the graph structure and the node/edge attributes.</span>
<span class="sd">        DGL will relabel the nodes using consecutive integers starting from zero if it is</span>
<span class="sd">        not the case. The graph must follow `NetworkX's bipartite graph convention</span>
<span class="sd">        &lt;https://networkx.github.io/documentation/stable/reference/algorithms/bipartite.html&gt;`_,</span>
<span class="sd">        and furthermore the edges must be from nodes with attribute ``bipartite=0`` to nodes</span>
<span class="sd">        with attribute ``bipartite=1``.</span>
<span class="sd">    utype : str, optional</span>
<span class="sd">        The name of the source node type.</span>
<span class="sd">    etype : str, optional</span>
<span class="sd">        The name of the edge type.</span>
<span class="sd">    vtype : str, optional</span>
<span class="sd">        The name of the destination node type.</span>
<span class="sd">    u_attrs : list[str], optional</span>
<span class="sd">        The names of the node attributes for node type :attr:`utype` to retrieve from the</span>
<span class="sd">        NetworkX graph. If given, DGL stores the retrieved node attributes in</span>
<span class="sd">        ``nodes[utype].data`` of the returned graph using their original names. The attribute</span>
<span class="sd">        data must be convertible to Tensor type (e.g., scalar, ``numpy.ndarray``, list, etc.).</span>
<span class="sd">    e_attrs : list[str], optional</span>
<span class="sd">        The names of the edge attributes to retrieve from the NetworkX graph. If given, DGL</span>
<span class="sd">        stores the retrieved edge attributes in ``edata`` of the returned graph using their</span>
<span class="sd">        original names. The attribute data must be convertible to Tensor type (e.g., scalar,</span>
<span class="sd">        numpy.ndarray, list, etc.).</span>
<span class="sd">    v_attrs : list[str], optional</span>
<span class="sd">        The names of the node attributes for node type :attr:`vtype` to retrieve from the</span>
<span class="sd">        NetworkX graph.  If given, DGL stores the retrieved node attributes in</span>
<span class="sd">        ``nodes[vtype].data`` of the returned graph using their original names. The attribute</span>
<span class="sd">        data must be convertible to Tensor type (e.g., scalar, numpy.array, list, etc.).</span>
<span class="sd">    edge_id_attr_name : str, optional</span>
<span class="sd">        The name of the edge attribute that stores the edge IDs. If given, DGL will assign edge</span>
<span class="sd">        IDs accordingly when creating the graph, so the attribute must be valid IDs, i.e.</span>
<span class="sd">        consecutive integers starting from zero. By default, the edge IDs of the returned graph</span>
<span class="sd">        can be arbitrary.</span>
<span class="sd">    idtype : int32 or int64, optional</span>
<span class="sd">        The data type for storing the structure-related graph information such as node and</span>
<span class="sd">        edge IDs. It should be a framework-specific data type object (e.g., torch.int32).</span>
<span class="sd">        By default, DGL uses int64.</span>
<span class="sd">    device : device context, optional</span>
<span class="sd">        The device of the resulting graph. It should be a framework-specific device object</span>
<span class="sd">        (e.g., torch.device). By default, DGL stores the graph on CPU.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    DGLGraph</span>
<span class="sd">        The created graph.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    The following example uses PyTorch backend.</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import networkx as nx</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>

<span class="sd">    Create a 2-edge unidirectional bipartite graph.</span>

<span class="sd">    &gt;&gt;&gt; nx_g = nx.DiGraph()</span>
<span class="sd">    &gt;&gt;&gt; # Add nodes for the source type</span>
<span class="sd">    &gt;&gt;&gt; nx_g.add_nodes_from([1, 3], bipartite=0, feat1=np.zeros((2, 1)), feat2=np.ones((2, 1)))</span>
<span class="sd">    &gt;&gt;&gt; # Add nodes for the destination type</span>
<span class="sd">    &gt;&gt;&gt; nx_g.add_nodes_from([2, 4, 5], bipartite=1, feat3=np.zeros((3, 1)))</span>
<span class="sd">    &gt;&gt;&gt; nx_g.add_edge(1, 4, weight=np.ones((1, 1)), eid=np.array([1]))</span>
<span class="sd">    &gt;&gt;&gt; nx_g.add_edge(3, 5, weight=np.ones((1, 1)), eid=np.array([0]))</span>

<span class="sd">    Convert it into a DGLGraph with structure only.</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.bipartite_from_networkx(nx_g, utype='_U', etype='_E', vtype='_V')</span>

<span class="sd">    Retrieve the node/edge features of the graph.</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.bipartite_from_networkx(nx_g, utype='_U', etype='_E', vtype='_V',</span>
<span class="sd">    ...                                 u_attrs=['feat1', 'feat2'],</span>
<span class="sd">    ...                                 e_attrs=['weight'],</span>
<span class="sd">    ...                                 v_attrs=['feat3'])</span>

<span class="sd">    Use a pre-specified ordering of the edges.</span>

<span class="sd">    &gt;&gt;&gt; g.edges()</span>
<span class="sd">    (tensor([0, 1]), tensor([1, 2]))</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.bipartite_from_networkx(nx_g,</span>
<span class="sd">    ...                                 utype='_U', etype='_E', vtype='_V',</span>
<span class="sd">    ...                                 edge_id_attr_name='eid')</span>
<span class="sd">    (tensor([1, 0]), tensor([2, 1]))</span>

<span class="sd">    Create a graph on the first GPU with data type int32.</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.bipartite_from_networkx(nx_g, utype='_U', etype='_E', vtype='_V',</span>
<span class="sd">    ...                                 idtype=torch.int32, device='cuda:0')</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    heterograph</span>
<span class="sd">    bipartite_from_scipy</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">nx_graph</span><span class="o">.</span><span class="n">is_directed</span><span class="p">():</span>
        <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span><span class="s2">"Expect nx_graph to be a directed NetworkX graph."</span><span class="p">)</span>
    <span class="k">if</span> <span class="p">(</span>
        <span class="n">edge_id_attr_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="ow">and</span> <span class="ow">not</span> <span class="n">edge_id_attr_name</span> <span class="ow">in</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">nx_graph</span><span class="o">.</span><span class="n">edges</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="kc">True</span><span class="p">)))[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="p">):</span>
        <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
            <span class="s2">"Failed to find the pre-specified edge IDs in the edge features "</span>
            <span class="s2">"of the NetworkX graph with name </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">edge_id_attr_name</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="c1"># Get the source and destination node sets</span>
    <span class="n">top_nodes</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="n">bottom_nodes</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">ndata</span> <span class="ow">in</span> <span class="n">nx_graph</span><span class="o">.</span><span class="n">nodes</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="k">if</span> <span class="s2">"bipartite"</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">ndata</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                <span class="s2">"Expect the node </span><span class="si">{}</span><span class="s2"> to have attribute bipartite"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">ndata</span><span class="p">[</span><span class="s2">"bipartite"</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">top_nodes</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">ndata</span><span class="p">[</span><span class="s2">"bipartite"</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">bottom_nodes</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">"Expect the bipartite attribute of the node </span><span class="si">{}</span><span class="s2"> to be 0 or 1, "</span>
                <span class="s2">"got </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">ndata</span><span class="p">[</span><span class="s2">"bipartite"</span><span class="p">])</span>
            <span class="p">)</span>

    <span class="c1"># Separately relabel the source and destination nodes.</span>
    <span class="n">top_nodes</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">top_nodes</span><span class="p">)</span>
    <span class="n">bottom_nodes</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">bottom_nodes</span><span class="p">)</span>
    <span class="n">top_map</span> <span class="o">=</span> <span class="p">{</span><span class="n">n</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">top_nodes</span><span class="p">)}</span>
    <span class="n">bottom_map</span> <span class="o">=</span> <span class="p">{</span><span class="n">n</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">bottom_nodes</span><span class="p">)}</span>

    <span class="c1"># Get the node tensors and the number of nodes</span>
    <span class="p">(</span><span class="n">sparse_fmt</span><span class="p">,</span> <span class="n">arrays</span><span class="p">),</span> <span class="n">urange</span><span class="p">,</span> <span class="n">vrange</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">graphdata2tensors</span><span class="p">(</span>
        <span class="n">nx_graph</span><span class="p">,</span>
        <span class="n">idtype</span><span class="p">,</span>
        <span class="n">bipartite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">edge_id_attr_name</span><span class="o">=</span><span class="n">edge_id_attr_name</span><span class="p">,</span>
        <span class="n">top_map</span><span class="o">=</span><span class="n">top_map</span><span class="p">,</span>
        <span class="n">bottom_map</span><span class="o">=</span><span class="n">bottom_map</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">g</span> <span class="o">=</span> <span class="n">create_from_edges</span><span class="p">(</span>
        <span class="n">sparse_fmt</span><span class="p">,</span> <span class="n">arrays</span><span class="p">,</span> <span class="n">utype</span><span class="p">,</span> <span class="n">etype</span><span class="p">,</span> <span class="n">vtype</span><span class="p">,</span> <span class="n">urange</span><span class="p">,</span> <span class="n">vrange</span>
    <span class="p">)</span>

    <span class="c1"># nx_graph.edges(data=True) returns src, dst, attr_dict</span>
    <span class="n">has_edge_id</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">nx_graph</span><span class="o">.</span><span class="n">number_of_edges</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">edge_id_attr_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="p">)</span>

    <span class="c1"># handle features</span>
    <span class="c1"># copy attributes</span>
    <span class="k">if</span> <span class="n">u_attrs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># mapping from feature name to a list of tensors to be concatenated</span>
        <span class="n">src_attr_dict</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">nid</span> <span class="ow">in</span> <span class="n">top_map</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">attr</span> <span class="ow">in</span> <span class="n">u_attrs</span><span class="p">:</span>
                <span class="n">src_attr_dict</span><span class="p">[</span><span class="n">attr</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nx_graph</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">nid</span><span class="p">][</span><span class="n">attr</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">attr</span> <span class="ow">in</span> <span class="n">u_attrs</span><span class="p">:</span>
            <span class="n">g</span><span class="o">.</span><span class="n">srcdata</span><span class="p">[</span><span class="n">attr</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">copy_to</span><span class="p">(</span><span class="n">_batcher</span><span class="p">(</span><span class="n">src_attr_dict</span><span class="p">[</span><span class="n">attr</span><span class="p">]),</span> <span class="n">g</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">v_attrs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># mapping from feature name to a list of tensors to be concatenated</span>
        <span class="n">dst_attr_dict</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">nid</span> <span class="ow">in</span> <span class="n">bottom_map</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">attr</span> <span class="ow">in</span> <span class="n">v_attrs</span><span class="p">:</span>
                <span class="n">dst_attr_dict</span><span class="p">[</span><span class="n">attr</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nx_graph</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">nid</span><span class="p">][</span><span class="n">attr</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">attr</span> <span class="ow">in</span> <span class="n">v_attrs</span><span class="p">:</span>
            <span class="n">g</span><span class="o">.</span><span class="n">dstdata</span><span class="p">[</span><span class="n">attr</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">copy_to</span><span class="p">(</span><span class="n">_batcher</span><span class="p">(</span><span class="n">dst_attr_dict</span><span class="p">[</span><span class="n">attr</span><span class="p">]),</span> <span class="n">g</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">e_attrs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># mapping from feature name to a list of tensors to be concatenated</span>
        <span class="n">attr_dict</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">g</span><span class="o">.</span><span class="n">num_edges</span><span class="p">())</span>
        <span class="c1"># each defaultdict value is initialized to be a list of None</span>
        <span class="c1"># None here serves as placeholder to be replaced by feature with</span>
        <span class="c1"># corresponding edge id</span>
        <span class="k">if</span> <span class="n">has_edge_id</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">attrs</span> <span class="ow">in</span> <span class="n">nx_graph</span><span class="o">.</span><span class="n">edges</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">e_attrs</span><span class="p">:</span>
                    <span class="n">attr_dict</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="n">attrs</span><span class="p">[</span><span class="n">edge_id_attr_name</span><span class="p">]]</span> <span class="o">=</span> <span class="n">attrs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># XXX: assuming networkx iteration order is deterministic</span>
            <span class="c1">#      so the order is the same as graph_index.from_networkx</span>
            <span class="k">for</span> <span class="n">eid</span><span class="p">,</span> <span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">attrs</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">nx_graph</span><span class="o">.</span><span class="n">edges</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="kc">True</span><span class="p">)):</span>
                <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">e_attrs</span><span class="p">:</span>
                    <span class="n">attr_dict</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="n">eid</span><span class="p">]</span> <span class="o">=</span> <span class="n">attrs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">attr</span> <span class="ow">in</span> <span class="n">e_attrs</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">attr_dict</span><span class="p">[</span><span class="n">attr</span><span class="p">]:</span>
                <span class="k">if</span> <span class="n">val</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                        <span class="s2">"Not all edges have attribute </span><span class="si">{}</span><span class="s2">."</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">attr</span><span class="p">)</span>
                    <span class="p">)</span>
            <span class="n">g</span><span class="o">.</span><span class="n">edata</span><span class="p">[</span><span class="n">attr</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">copy_to</span><span class="p">(</span><span class="n">_batcher</span><span class="p">(</span><span class="n">attr_dict</span><span class="p">[</span><span class="n">attr</span><span class="p">]),</span> <span class="n">g</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">g</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span></div>



<span class="k">def</span> <span class="nf">_to_networkx_homogeneous</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">node_attrs</span><span class="p">,</span> <span class="n">edge_attrs</span><span class="p">):</span>
    <span class="c1"># TODO: consider adding an eid_attr parameter as in</span>
    <span class="c1">#  `_to_networkx_heterogeneous` when this function is properly tested</span>
    <span class="c1"># (see GitHub issue #5735)</span>
    <span class="n">src</span><span class="p">,</span> <span class="n">dst</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">edges</span><span class="p">()</span>
    <span class="n">src</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(</span><span class="n">src</span><span class="p">)</span>
    <span class="n">dst</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(</span><span class="n">dst</span><span class="p">)</span>
    <span class="c1"># xiangsx: Always treat graph as multigraph</span>
    <span class="n">nx_graph</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">MultiDiGraph</span><span class="p">()</span>
    <span class="n">nx_graph</span><span class="o">.</span><span class="n">add_nodes_from</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">()))</span>
    <span class="k">for</span> <span class="n">eid</span><span class="p">,</span> <span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">dst</span><span class="p">)):</span>
        <span class="n">nx_graph</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="nb">id</span><span class="o">=</span><span class="n">eid</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">node_attrs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">nid</span><span class="p">,</span> <span class="n">attr</span> <span class="ow">in</span> <span class="n">nx_graph</span><span class="o">.</span><span class="n">nodes</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
            <span class="n">feat_dict</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">_get_n_repr</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">nid</span><span class="p">)</span>
            <span class="n">attr</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">F</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">feat_dict</span><span class="p">[</span><span class="n">key</span><span class="p">],</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">node_attrs</span><span class="p">}</span>
            <span class="p">)</span>
    <span class="k">if</span> <span class="n">edge_attrs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">attr</span> <span class="ow">in</span> <span class="n">nx_graph</span><span class="o">.</span><span class="n">edges</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
            <span class="n">eid</span> <span class="o">=</span> <span class="n">attr</span><span class="p">[</span><span class="s2">"id"</span><span class="p">]</span>
            <span class="n">feat_dict</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">_get_e_repr</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">eid</span><span class="p">)</span>
            <span class="n">attr</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">F</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">feat_dict</span><span class="p">[</span><span class="n">key</span><span class="p">],</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">edge_attrs</span><span class="p">}</span>
            <span class="p">)</span>
    <span class="k">return</span> <span class="n">nx_graph</span>


<span class="k">def</span> <span class="nf">_to_networkx_heterogeneous</span><span class="p">(</span>
    <span class="n">g</span><span class="p">,</span> <span class="n">node_attrs</span><span class="p">,</span> <span class="n">edge_attrs</span><span class="p">,</span> <span class="n">ntype_attr</span><span class="p">,</span> <span class="n">etype_attr</span><span class="p">,</span> <span class="n">eid_attr</span>
<span class="p">):</span>
    <span class="n">nx_graph</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">MultiDiGraph</span><span class="p">()</span>

    <span class="c1"># This implementation does not use `ndata` and `edata` in the call to</span>
    <span class="c1"># `to_homogeneous` because the function expects node and edge attributes</span>
    <span class="c1"># both to be defined for every type and to have the same shape.</span>
    <span class="c1"># If the `to_homogeneous` function is updated to support non-uniform node</span>
    <span class="c1"># and edge attributes, the implementation can be simplified.</span>
    <span class="n">hom_g</span> <span class="o">=</span> <span class="n">to_homogeneous</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">store_type</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_count</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">ntypes</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">ntypes</span>
    <span class="n">etypes</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">canonical_etypes</span>

    <span class="k">for</span> <span class="n">hom_nid</span><span class="p">,</span> <span class="n">ndata</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">hom_g</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="n">NID</span><span class="p">],</span> <span class="n">hom_g</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="n">NTYPE</span><span class="p">])):</span>
        <span class="n">orig_nid</span><span class="p">,</span> <span class="n">ntype</span> <span class="o">=</span> <span class="n">ndata</span>
        <span class="n">attrs</span> <span class="o">=</span> <span class="p">{</span><span class="n">ntype_attr</span><span class="p">:</span> <span class="n">ntypes</span><span class="p">[</span><span class="n">ntype</span><span class="p">]}</span>

        <span class="k">if</span> <span class="n">node_attrs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">ntype_attr</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">node_attrs</span><span class="p">,</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">"'</span><span class="si">{</span><span class="n">ntype_attr</span><span class="si">}</span><span class="s2">' already used as node type attribute, "</span>
                <span class="sa">f</span><span class="s2">"please provide a different value for ntype_attr"</span>
            <span class="p">)</span>

            <span class="n">feat_dict</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">_get_n_repr</span><span class="p">(</span><span class="n">ntype</span><span class="p">,</span> <span class="n">orig_nid</span><span class="p">)</span>
            <span class="n">attrs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                <span class="p">{</span>
                    <span class="n">key</span><span class="p">:</span> <span class="n">F</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">feat_dict</span><span class="p">[</span><span class="n">key</span><span class="p">],</span> <span class="mi">0</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">node_attrs</span>
                    <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">feat_dict</span>
                <span class="p">}</span>
            <span class="p">)</span>

        <span class="n">nx_graph</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">hom_nid</span><span class="p">,</span> <span class="o">**</span><span class="n">attrs</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">hom_eid</span><span class="p">,</span> <span class="n">edata</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">hom_g</span><span class="o">.</span><span class="n">edata</span><span class="p">[</span><span class="n">EID</span><span class="p">],</span> <span class="n">hom_g</span><span class="o">.</span><span class="n">edata</span><span class="p">[</span><span class="n">ETYPE</span><span class="p">])):</span>
        <span class="n">orig_eid</span><span class="p">,</span> <span class="n">etype</span> <span class="o">=</span> <span class="n">edata</span>
        <span class="n">attrs</span> <span class="o">=</span> <span class="p">{</span><span class="n">eid_attr</span><span class="p">:</span> <span class="n">hom_eid</span><span class="p">,</span> <span class="n">etype_attr</span><span class="p">:</span> <span class="n">etypes</span><span class="p">[</span><span class="n">etype</span><span class="p">]}</span>

        <span class="k">if</span> <span class="n">edge_attrs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">etype_attr</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">edge_attrs</span><span class="p">,</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">"'</span><span class="si">{</span><span class="n">etype_attr</span><span class="si">}</span><span class="s2">' already used as edge type attribute, "</span>
                <span class="sa">f</span><span class="s2">"please provide a different value for etype_attr"</span>
            <span class="p">)</span>
            <span class="k">assert</span> <span class="n">eid_attr</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">edge_attrs</span><span class="p">,</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">"'</span><span class="si">{</span><span class="n">eid_attr</span><span class="si">}</span><span class="s2">' already used as edge ID attribute, "</span>
                <span class="sa">f</span><span class="s2">"please provide a different value for eid_attr"</span>
            <span class="p">)</span>

            <span class="n">feat_dict</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">_get_e_repr</span><span class="p">(</span><span class="n">etype</span><span class="p">,</span> <span class="n">orig_eid</span><span class="p">)</span>
            <span class="n">attrs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                <span class="p">{</span>
                    <span class="n">key</span><span class="p">:</span> <span class="n">F</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">feat_dict</span><span class="p">[</span><span class="n">key</span><span class="p">],</span> <span class="mi">0</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">edge_attrs</span>
                    <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">feat_dict</span>
                <span class="p">}</span>
            <span class="p">)</span>

        <span class="n">src</span><span class="p">,</span> <span class="n">dst</span> <span class="o">=</span> <span class="n">hom_g</span><span class="o">.</span><span class="n">find_edges</span><span class="p">(</span><span class="n">hom_eid</span><span class="p">)</span>
        <span class="n">nx_graph</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">src</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">dst</span><span class="p">),</span> <span class="o">**</span><span class="n">attrs</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">nx_graph</span>


<div class="viewcode-block" id="to_networkx">
<a class="viewcode-back" href="../../generated/dgl.to_networkx.html#dgl.to_networkx">[docs]</a>
<span class="k">def</span> <span class="nf">to_networkx</span><span class="p">(</span>
    <span class="n">g</span><span class="p">,</span>
    <span class="n">node_attrs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">edge_attrs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">ntype_attr</span><span class="o">=</span><span class="s2">"ntype"</span><span class="p">,</span>
    <span class="n">etype_attr</span><span class="o">=</span><span class="s2">"etype"</span><span class="p">,</span>
    <span class="n">eid_attr</span><span class="o">=</span><span class="s2">"id"</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">"""Convert a graph to a NetworkX graph and return.</span>

<span class="sd">    The resulting NetworkX graph also contains the node/edge features of the input graph.</span>
<span class="sd">    Additionally, DGL saves the edge IDs as the ``'id'`` edge attribute in the</span>
<span class="sd">    returned NetworkX graph.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    g : DGLGraph</span>
<span class="sd">        A homogeneous or heterogeneous graph.</span>
<span class="sd">    node_attrs : iterable of str, optional</span>
<span class="sd">        The node attributes to copy from ``g.ndata``. (Default: None)</span>
<span class="sd">    edge_attrs : iterable of str, optional</span>
<span class="sd">        The edge attributes to copy from ``g.edata``.</span>
<span class="sd">        (Default: None)</span>
<span class="sd">    ntype_attr : str, optional</span>
<span class="sd">        The name of the node attribute to store the node types in the NetworkX object.</span>
<span class="sd">        (Default: "ntype")</span>
<span class="sd">    etype_attr : str, optional</span>
<span class="sd">        The name of the edge attribute to store the edge canonical types in the NetworkX object.</span>
<span class="sd">        (Default: "etype")</span>
<span class="sd">    eid_attr : str, optional</span>
<span class="sd">        The name of the edge attribute to store the original edge ID in the NetworkX object.</span>
<span class="sd">        (Default: "id")</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    networkx.DiGraph</span>
<span class="sd">        The converted NetworkX graph.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The function only supports CPU graph input.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    The following examples use the PyTorch backend.</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>

<span class="sd">    With a homogeneous graph:</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.graph((torch.tensor([1, 2]), torch.tensor([1, 3])))</span>
<span class="sd">    &gt;&gt;&gt; g.ndata['h'] = torch.zeros(4, 1)</span>
<span class="sd">    &gt;&gt;&gt; g.edata['h1'] = torch.ones(2, 1)</span>
<span class="sd">    &gt;&gt;&gt; g.edata['h2'] = torch.zeros(2, 2)</span>
<span class="sd">    &gt;&gt;&gt; nx_g = dgl.to_networkx(g, node_attrs=['h'], edge_attrs=['h1', 'h2'])</span>
<span class="sd">    &gt;&gt;&gt; nx_g.nodes(data=True)</span>
<span class="sd">    NodeDataView({</span>
<span class="sd">        0: {'h': tensor([0.])},</span>
<span class="sd">        1: {'h': tensor([0.])},</span>
<span class="sd">        2: {'h': tensor([0.])},</span>
<span class="sd">        3: {'h': tensor([0.])}</span>
<span class="sd">    })</span>
<span class="sd">    &gt;&gt;&gt; nx_g.edges(data=True)</span>
<span class="sd">    OutMultiEdgeDataView([</span>
<span class="sd">        (1, 1, {'id': 0, 'h1': tensor([1.]), 'h2': tensor([0., 0.])}),</span>
<span class="sd">        (2, 3, {'id': 1, 'h1': tensor([1.]), 'h2': tensor([0., 0.])})</span>
<span class="sd">    ])</span>

<span class="sd">    With a heterogeneous graph:</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">    ...     ('user', 'follows', 'user'): (torch.tensor([0, 1]), torch.tensor([1, 2])),</span>
<span class="sd">    ...     ('user', 'follows', 'topic'): (torch.tensor([1, 1]), torch.tensor([1, 2])),</span>
<span class="sd">    ...     ('user', 'plays', 'game'): (torch.tensor([0, 3]), torch.tensor([3, 4]))</span>
<span class="sd">    ... })</span>
<span class="sd">    ... g.ndata['n'] = {</span>
<span class="sd">    ...     'game': torch.zeros(5, 1),</span>
<span class="sd">    ...     'user': torch.ones(4, 1)</span>
<span class="sd">    ... }</span>
<span class="sd">    ... g.edata['e'] = {</span>
<span class="sd">    ...     ('user', 'follows', 'user'): torch.zeros(2, 1),</span>
<span class="sd">    ...     'plays': torch.ones(2, 1)</span>
<span class="sd">    ... }</span>
<span class="sd">    &gt;&gt;&gt; nx_g = dgl.to_networkx(g, node_attrs=['n'], edge_attrs=['e'])</span>
<span class="sd">    &gt;&gt;&gt; nx_g.nodes(data=True)</span>
<span class="sd">    NodeDataView({</span>
<span class="sd">        0: {'ntype': 'game', 'n': tensor([0.])},</span>
<span class="sd">        1: {'ntype': 'game', 'n': tensor([0.])},</span>
<span class="sd">        2: {'ntype': 'game', 'n': tensor([0.])},</span>
<span class="sd">        3: {'ntype': 'game', 'n': tensor([0.])},</span>
<span class="sd">        4: {'ntype': 'game', 'n': tensor([0.])},</span>
<span class="sd">        5: {'ntype': 'topic'},</span>
<span class="sd">        6: {'ntype': 'topic'},</span>
<span class="sd">        7: {'ntype': 'topic'},</span>
<span class="sd">        8: {'ntype': 'user', 'n': tensor([1.])},</span>
<span class="sd">        9: {'ntype': 'user', 'n': tensor([1.])},</span>
<span class="sd">        10: {'ntype': 'user', 'n': tensor([1.])},</span>
<span class="sd">        11: {'ntype': 'user', 'n': tensor([1.])}</span>
<span class="sd">    })</span>
<span class="sd">    &gt;&gt;&gt; nx_g.edges(data=True)</span>
<span class="sd">    OutMultiEdgeDataView([</span>
<span class="sd">        (8, 9, {'id': 2, 'etype': ('user', 'follows', 'user'), 'e': tensor([0.])}),</span>
<span class="sd">        (8, 3, {'id': 4, 'etype': ('user', 'plays', 'game'), 'e': tensor([1.])}),</span>
<span class="sd">        (9, 6, {'id': 0, 'etype': ('user', 'follows', 'topic')}),</span>
<span class="sd">        (9, 7, {'id': 1, 'etype': ('user', 'follows', 'topic')}),</span>
<span class="sd">        (9, 10, {'id': 3, 'etype': ('user', 'follows', 'user'), 'e': tensor([0.])}),</span>
<span class="sd">        (11, 4, {'id': 5, 'etype': ('user', 'plays', 'game'), 'e': tensor([1.])})</span>
<span class="sd">    ])</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="n">g</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="n">F</span><span class="o">.</span><span class="n">cpu</span><span class="p">():</span>
        <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
            <span class="s2">"Cannot convert a CUDA graph to networkx. Call g.cpu() first."</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="n">g</span><span class="o">.</span><span class="n">is_homogeneous</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_to_networkx_homogeneous</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">node_attrs</span><span class="p">,</span> <span class="n">edge_attrs</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_to_networkx_heterogeneous</span><span class="p">(</span>
            <span class="n">g</span><span class="p">,</span> <span class="n">node_attrs</span><span class="p">,</span> <span class="n">edge_attrs</span><span class="p">,</span> <span class="n">ntype_attr</span><span class="p">,</span> <span class="n">etype_attr</span><span class="p">,</span> <span class="n">eid_attr</span>
        <span class="p">)</span></div>



<span class="n">DGLGraph</span><span class="o">.</span><span class="n">to_networkx</span> <span class="o">=</span> <span class="n">to_networkx</span>


<div class="viewcode-block" id="to_cugraph">
<a class="viewcode-back" href="../../generated/dgl.to_cugraph.html#dgl.to_cugraph">[docs]</a>
<span class="k">def</span> <span class="nf">to_cugraph</span><span class="p">(</span><span class="n">g</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Convert a DGL graph to a :class:`cugraph.Graph` and return.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    g : DGLGraph</span>
<span class="sd">        A homogeneous graph.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    cugraph.Graph</span>
<span class="sd">        The converted cugraph graph.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The function only supports GPU graph input.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    The following example uses PyTorch backend.</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import cugraph</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.graph((torch.tensor([1, 2]), torch.tensor([1, 3]))).to('cuda')</span>
<span class="sd">    &gt;&gt;&gt; cugraph_g = g.to_cugraph()</span>
<span class="sd">    &gt;&gt;&gt; cugraph_g.edges()</span>
<span class="sd">        src  dst</span>
<span class="sd">    0    2    3</span>
<span class="sd">    1    1    1</span>
<span class="sd">    """</span>

    <span class="k">if</span> <span class="n">g</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">!=</span> <span class="s2">"cuda"</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">"Cannot convert a </span><span class="si">{</span><span class="n">g</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span><span class="si">}</span><span class="s2"> graph to cugraph."</span>
            <span class="o">+</span> <span class="s2">"Call g.to('cuda') first."</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">g</span><span class="o">.</span><span class="n">is_homogeneous</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span><span class="s2">"dgl.to_cugraph only supports homogeneous graphs."</span><span class="p">)</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="kn">import</span> <span class="nn">cudf</span>
        <span class="kn">import</span> <span class="nn">cugraph</span>
    <span class="k">except</span> <span class="ne">ModuleNotFoundError</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ModuleNotFoundError</span><span class="p">(</span>
            <span class="s2">"to_cugraph requires cugraph which could not be imported"</span>
        <span class="p">)</span>

    <span class="n">edgelist</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">edges</span><span class="p">()</span>
    <span class="n">src_ser</span> <span class="o">=</span> <span class="n">cudf</span><span class="o">.</span><span class="n">from_dlpack</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">zerocopy_to_dlpack</span><span class="p">(</span><span class="n">edgelist</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="n">dst_ser</span> <span class="o">=</span> <span class="n">cudf</span><span class="o">.</span><span class="n">from_dlpack</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">zerocopy_to_dlpack</span><span class="p">(</span><span class="n">edgelist</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">cudf_data</span> <span class="o">=</span> <span class="n">cudf</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">"source"</span><span class="p">:</span> <span class="n">src_ser</span><span class="p">,</span> <span class="s2">"destination"</span><span class="p">:</span> <span class="n">dst_ser</span><span class="p">})</span>
    <span class="n">g_cugraph</span> <span class="o">=</span> <span class="n">cugraph</span><span class="o">.</span><span class="n">Graph</span><span class="p">(</span><span class="n">directed</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">g_cugraph</span><span class="o">.</span><span class="n">from_cudf_edgelist</span><span class="p">(</span>
        <span class="n">cudf_data</span><span class="p">,</span> <span class="n">source</span><span class="o">=</span><span class="s2">"source"</span><span class="p">,</span> <span class="n">destination</span><span class="o">=</span><span class="s2">"destination"</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">g_cugraph</span></div>



<span class="n">DGLGraph</span><span class="o">.</span><span class="n">to_cugraph</span> <span class="o">=</span> <span class="n">to_cugraph</span>


<div class="viewcode-block" id="from_cugraph">
<a class="viewcode-back" href="../../generated/dgl.from_cugraph.html#dgl.from_cugraph">[docs]</a>
<span class="k">def</span> <span class="nf">from_cugraph</span><span class="p">(</span><span class="n">cugraph_graph</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Create a graph from a :class:`cugraph.Graph` object.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    cugraph_graph : cugraph.Graph</span>
<span class="sd">        The cugraph graph object holding the graph structure. Node and edge attributes are</span>
<span class="sd">        dropped.</span>

<span class="sd">        If the input graph is undirected, DGL converts it to a directed graph</span>
<span class="sd">        by :func:`cugraph.Graph.to_directed`.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    DGLGraph</span>
<span class="sd">        The created graph.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    The following example uses PyTorch backend.</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import cugraph</span>
<span class="sd">    &gt;&gt;&gt; import cudf</span>

<span class="sd">    Create a cugraph graph.</span>
<span class="sd">    &gt;&gt;&gt; cugraph_g = cugraph.Graph(directed=True)</span>
<span class="sd">    &gt;&gt;&gt; df = cudf.DataFrame({"source":[0, 1, 2, 3],</span>
<span class="sd">                     "destination":[1, 2, 3, 0]})</span>
<span class="sd">    &gt;&gt;&gt; cugraph_g.from_cudf_edgelist(df)</span>

<span class="sd">    Convert it into a DGLGraph</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.from_cugraph(cugraph_g)</span>
<span class="sd">    &gt;&gt;&gt; g.edges()</span>
<span class="sd">    (tensor([1, 2, 3, 0], device='cuda:0'), tensor([2, 3, 0, 1], device='cuda:0'))</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">cugraph_graph</span><span class="o">.</span><span class="n">is_directed</span><span class="p">():</span>
        <span class="n">cugraph_graph</span> <span class="o">=</span> <span class="n">cugraph_graph</span><span class="o">.</span><span class="n">to_directed</span><span class="p">()</span>

    <span class="n">edges</span> <span class="o">=</span> <span class="n">cugraph_graph</span><span class="o">.</span><span class="n">edges</span><span class="p">()</span>
    <span class="n">src_t</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">zerocopy_from_dlpack</span><span class="p">(</span><span class="n">edges</span><span class="p">[</span><span class="s2">"src"</span><span class="p">]</span><span class="o">.</span><span class="n">to_dlpack</span><span class="p">())</span>
    <span class="n">dst_t</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">zerocopy_from_dlpack</span><span class="p">(</span><span class="n">edges</span><span class="p">[</span><span class="s2">"dst"</span><span class="p">]</span><span class="o">.</span><span class="n">to_dlpack</span><span class="p">())</span>
    <span class="n">g</span> <span class="o">=</span> <span class="n">graph</span><span class="p">((</span><span class="n">src_t</span><span class="p">,</span> <span class="n">dst_t</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">g</span></div>



<span class="c1">############################################################</span>
<span class="c1"># Internal APIs</span>
<span class="c1">############################################################</span>


<span class="k">def</span> <span class="nf">create_from_edges</span><span class="p">(</span>
    <span class="n">sparse_fmt</span><span class="p">,</span>
    <span class="n">arrays</span><span class="p">,</span>
    <span class="n">utype</span><span class="p">,</span>
    <span class="n">etype</span><span class="p">,</span>
    <span class="n">vtype</span><span class="p">,</span>
    <span class="n">urange</span><span class="p">,</span>
    <span class="n">vrange</span><span class="p">,</span>
    <span class="n">row_sorted</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">col_sorted</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">"""Internal function to create a graph from incident nodes with types.</span>

<span class="sd">    utype could be equal to vtype</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    sparse_fmt : str</span>
<span class="sd">        The sparse adjacency matrix format.</span>
<span class="sd">    arrays : tuple[Tensor]</span>
<span class="sd">        The sparse adjacency matrix arrays.</span>
<span class="sd">    utype : str</span>
<span class="sd">        Source node type name.</span>
<span class="sd">    etype : str</span>
<span class="sd">        Edge type name.</span>
<span class="sd">    vtype : str</span>
<span class="sd">        Destination node type name.</span>
<span class="sd">    urange : int, optional</span>
<span class="sd">        The source node ID range. If None, the value is the maximum</span>
<span class="sd">        of the source node IDs in the edge list plus 1. (Default: None)</span>
<span class="sd">    vrange : int, optional</span>
<span class="sd">        The destination node ID range. If None, the value is the</span>
<span class="sd">        maximum of the destination node IDs in the edge list plus 1. (Default: None)</span>
<span class="sd">    row_sorted : bool, optional</span>
<span class="sd">        Whether or not the rows of the COO are in ascending order.</span>
<span class="sd">    col_sorted : bool, optional</span>
<span class="sd">        Whether or not the columns of the COO are in ascending order within</span>
<span class="sd">        each row. This only has an effect when ``row_sorted`` is True.</span>


<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    DGLGraph</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="n">utype</span> <span class="o">==</span> <span class="n">vtype</span><span class="p">:</span>
        <span class="n">num_ntypes</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">num_ntypes</span> <span class="o">=</span> <span class="mi">2</span>

    <span class="k">if</span> <span class="n">sparse_fmt</span> <span class="o">==</span> <span class="s2">"coo"</span><span class="p">:</span>
        <span class="n">u</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">arrays</span>
        <span class="n">hgidx</span> <span class="o">=</span> <span class="n">heterograph_index</span><span class="o">.</span><span class="n">create_unitgraph_from_coo</span><span class="p">(</span>
            <span class="n">num_ntypes</span><span class="p">,</span>
            <span class="n">urange</span><span class="p">,</span>
            <span class="n">vrange</span><span class="p">,</span>
            <span class="n">u</span><span class="p">,</span>
            <span class="n">v</span><span class="p">,</span>
            <span class="p">[</span><span class="s2">"coo"</span><span class="p">,</span> <span class="s2">"csr"</span><span class="p">,</span> <span class="s2">"csc"</span><span class="p">],</span>
            <span class="n">row_sorted</span><span class="p">,</span>
            <span class="n">col_sorted</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>  <span class="c1"># 'csr' or 'csc'</span>
        <span class="n">indptr</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">eids</span> <span class="o">=</span> <span class="n">arrays</span>
        <span class="n">hgidx</span> <span class="o">=</span> <span class="n">heterograph_index</span><span class="o">.</span><span class="n">create_unitgraph_from_csr</span><span class="p">(</span>
            <span class="n">num_ntypes</span><span class="p">,</span>
            <span class="n">urange</span><span class="p">,</span>
            <span class="n">vrange</span><span class="p">,</span>
            <span class="n">indptr</span><span class="p">,</span>
            <span class="n">indices</span><span class="p">,</span>
            <span class="n">eids</span><span class="p">,</span>
            <span class="p">[</span><span class="s2">"coo"</span><span class="p">,</span> <span class="s2">"csr"</span><span class="p">,</span> <span class="s2">"csc"</span><span class="p">],</span>
            <span class="n">sparse_fmt</span> <span class="o">==</span> <span class="s2">"csc"</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="n">utype</span> <span class="o">==</span> <span class="n">vtype</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">DGLGraph</span><span class="p">(</span><span class="n">hgidx</span><span class="p">,</span> <span class="p">[</span><span class="n">utype</span><span class="p">],</span> <span class="p">[</span><span class="n">etype</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">DGLGraph</span><span class="p">(</span><span class="n">hgidx</span><span class="p">,</span> <span class="p">[</span><span class="n">utype</span><span class="p">,</span> <span class="n">vtype</span><span class="p">],</span> <span class="p">[</span><span class="n">etype</span><span class="p">])</span>
</pre></div>
</div>
</div>
<footer>
<hr/>
<div role="contentinfo">
<p>© Copyright 2018, DGL Team.</p>
</div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
</div>
</div>
</section>
</div>
<div aria-label="Versions" class="rst-versions" data-toggle="rst-versions" role="note">
<span class="rst-current-version" data-toggle="rst-current-version">
<span class="fa fa-book"> Read the Docs</span>
<span id="version-placeholder">v: latest</span>
<span class="fa fa-caret-down"></span>
</span>
<div class="rst-other-versions">
<dl>
<dt>Versions</dt>
<div id="version-list">
<!-- 动态插入的版本列表将出现在这里 -->
</div>
</dl>
<dl>
<dt>Downloads</dt>
<!-- 下载内容 -->
</dl>
<dl>
<dt>On Read the Docs</dt>
<dd><a href="//doc-build.dgl.ai/projects/dgl/?fromdocs=dgl">Project Home</a></dd>
<dd><a href="//doc-build.dgl.ai/builds/dgl/?fromdocs=dgl">Builds</a></dd>
</dl>
</div>
</div>
<script>
        document.addEventListener("DOMContentLoaded", function() {
            fetch('/dgl_docs/branches.json')
                .then(response => response.json())
                .then(data => {
                    var versionListDiv = document.getElementById('version-list');
                    data.branches.forEach(function(branch) {
                        var dd = document.createElement('dd');
                        var a = document.createElement('a');
                        a.href = branch.url;
                        a.textContent = branch.name;
                        dd.appendChild(a);
                        versionListDiv.appendChild(dd);
                    });
                })
                .catch(error => console.error('Error loading branches:', error));
        });
        document.addEventListener("DOMContentLoaded", function() {
            // 获取当前路径
            var path = window.location.pathname;
            var versionPlaceholder = document.getElementById('version-placeholder');

            // 检查路径中是否包含 'en'
            if (path.includes('/en/')) {
                // 提取 'en' 后的文件夹作为版本号
                var parts = path.split('/en/');
                if (parts[1]) {
                    var folders = parts[1].split('/');
                    if (folders.length > 0 && folders[0]) {
                        versionPlaceholder.textContent = 'v: ' + folders[0];
                    } else {
                        versionPlaceholder.textContent = 'v: latest';
                    }
                } else {
                    versionPlaceholder.textContent = 'v: latest';
                }
            } else {
                versionPlaceholder.textContent = 'v: latest';
            }
        });
    </script>

<script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
</body>
</html>