<!DOCTYPE html>

<html class="writer-html5" data-content_root="../" lang="en">
<head>
<meta charset="utf-8"/><meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>GraphConv — DGL 2.1.0 documentation</title>
<link href="../_static/pygments.css?v=80d5e7a1" rel="stylesheet" type="text/css"/>
<link href="../_static/css/theme.css?v=19f00094" rel="stylesheet" type="text/css"/>
<link href="../_static/graphviz.css?v=fd3f3429" rel="stylesheet" type="text/css"/>
<link href="../_static/copybutton.css?v=76b2166b" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery.css?v=d2d258e8" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery-binder.css?v=f4aeca0c" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery-dataframe.css?v=2082cf3c" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" rel="stylesheet" type="text/css"/>
<link href="../_static/css/custom.css?v=0bf289b5" rel="stylesheet" type="text/css"/>
<!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
<script src="../_static/jquery.js?v=5d32c60e"></script>
<script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
<script src="../_static/documentation_options.js?v=20623aea"></script>
<script src="../_static/doctools.js?v=9a2dae69"></script>
<script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
<script src="../_static/clipboard.min.js?v=a7894cd8"></script>
<script src="../_static/copybutton.js?v=ccdb6887"></script>
<script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
<script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
<script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script src="../_static/js/theme.js"></script>
<link href="../genindex.html" rel="index" title="Index"/>
<link href="../search.html" rel="search" title="Search"/>
<link href="dgl.nn.pytorch.conv.EdgeWeightNorm.html" rel="next" title="EdgeWeightNorm"/>
<link href="../api/python/nn-pytorch.html" rel="prev" title="dgl.nn (PyTorch)"/>
</head>
<body class="wy-body-for-nav">
<div class="wy-grid-for-nav">
<nav class="wy-nav-side" data-toggle="wy-nav-shift">
<div class="wy-side-scroll">
<div class="wy-side-nav-search">
<a class="icon icon-home" href="../index.html">
            DGL
          </a>
<div class="version">
                2.1.0
              </div>
<div role="search">
<form action="../search.html" class="wy-form" id="rtd-search-form" method="get">
<input aria-label="Search docs" name="q" placeholder="Search docs" type="text"/>
<input name="check_keywords" type="hidden" value="yes"/>
<input name="area" type="hidden" value="default"/>
</form>
</div>
</div><div aria-label="Navigation menu" class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation">
<p class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../install/index.html">Install and Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/blitz/index.html">A Blitz Introduction to DGL</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Materials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../stochastic_training/index.html">🆕 Stochastic Training of GNNs with GraphBolt</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guide/index.html">User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guide_cn/index.html">用户指南【包含过时信息】</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guide_ko/index.html">사용자 가이드[시대에 뒤쳐진]</a></li>
<li class="toctree-l1"><a class="reference internal" href="../graphtransformer/index.html">🆕 Tutorial: Graph Transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebooks/sparse/index.html">Tutorials: dgl.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/cpu/index.html">Training on CPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/multi/index.html">Training on Multiple GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/dist/index.html">Distributed training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/models/index.html">Paper Study with DGL</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.html">dgl</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.data.html">dgl.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.dataloading.html">dgl.dataloading</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.DGLGraph.html">dgl.DGLGraph</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.distributed.html">dgl.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.function.html">dgl.function</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.geometry.html">dgl.geometry</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.graphbolt.html">🆕 dgl.graphbolt</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../api/python/nn-pytorch.html">dgl.nn (PyTorch)</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../api/python/nn-pytorch.html#conv-layers">Conv Layers</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">GraphConv</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#dgl.nn.pytorch.conv.GraphConv"><code class="docutils literal notranslate"><span class="pre">GraphConv</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.EdgeWeightNorm.html">EdgeWeightNorm</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.RelGraphConv.html">RelGraphConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.TAGConv.html">TAGConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.GATConv.html">GATConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.GATv2Conv.html">GATv2Conv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.EGATConv.html">EGATConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.EdgeGATConv.html">EdgeGATConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.EdgeConv.html">EdgeConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.SAGEConv.html">SAGEConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.SGConv.html">SGConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.APPNPConv.html">APPNPConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.GINConv.html">GINConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.GINEConv.html">GINEConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.GatedGraphConv.html">GatedGraphConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.GatedGCNConv.html">GatedGCNConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.GMMConv.html">GMMConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.ChebConv.html">ChebConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.AGNNConv.html">AGNNConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.NNConv.html">NNConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.AtomicConv.html">AtomicConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.CFConv.html">CFConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.DotGatConv.html">DotGatConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.TWIRLSConv.html">TWIRLSConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.TWIRLSUnfoldingAndAttention.html">TWIRLSUnfoldingAndAttention</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.GCN2Conv.html">GCN2Conv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.HGTConv.html">HGTConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.GroupRevRes.html">GroupRevRes</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.EGNNConv.html">EGNNConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.PNAConv.html">PNAConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.DGNConv.html">DGNConv</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api/python/nn-pytorch.html#cugraph-conv-layers">CuGraph Conv Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/python/nn-pytorch.html#dense-conv-layers">Dense Conv Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/python/nn-pytorch.html#global-pooling-layers">Global Pooling Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/python/nn-pytorch.html#score-modules-for-link-prediction-and-knowledge-graph-completion">Score Modules for Link Prediction and Knowledge Graph Completion</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/python/nn-pytorch.html#heterogeneous-learning-modules">Heterogeneous Learning Modules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/python/nn-pytorch.html#utility-modules">Utility Modules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/python/nn-pytorch.html#network-embedding-modules">Network Embedding Modules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/python/nn-pytorch.html#utility-modules-for-graph-transformer">Utility Modules for Graph Transformer</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/nn.functional.html">dgl.nn.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.ops.html">dgl.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.optim.html">dgl.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.sampling.html">dgl.sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.sparse_v0.html">dgl.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.multiprocessing.html">dgl.multiprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/transforms.html">dgl.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/udf.html">User-defined Functions</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../contribute.html">Contribute to DGL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../developer/ffi.html">DGL Foreign Function Interface (FFI)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../performance.html">Performance Benchmarks</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Misc</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">Frequently Asked Questions (FAQ)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../env_var.html">Environment Variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="../resources.html">Resources</a></li>
</ul>
</div>
</div>
</nav>
<section class="wy-nav-content-wrap" data-toggle="wy-nav-shift"><nav aria-label="Mobile navigation menu" class="wy-nav-top">
<i class="fa fa-bars" data-toggle="wy-nav-top"></i>
<a href="../index.html">DGL</a>
</nav>
<div class="wy-nav-content">
<div class="rst-content">
<div aria-label="Page navigation" role="navigation">
<ul class="wy-breadcrumbs">
<li><a aria-label="Home" class="icon icon-home" href="../index.html"></a></li>
<li class="breadcrumb-item"><a href="../api/python/nn-pytorch.html">dgl.nn (PyTorch)</a></li>
<li class="breadcrumb-item active">GraphConv</li>
<li class="wy-breadcrumbs-aside">
<a href="../_sources/generated/dgl.nn.pytorch.conv.GraphConv.rst.txt" rel="nofollow"> View page source</a>
</li>
</ul>
<hr/>
</div>
<div class="document" itemscope="itemscope" itemtype="http://schema.org/Article" role="main">
<div itemprop="articleBody">
<section id="graphconv">
<h1>GraphConv<a class="headerlink" href="#graphconv" title="Link to this heading"></a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="dgl.nn.pytorch.conv.GraphConv">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dgl.nn.pytorch.conv.</span></span><span class="sig-name descname"><span class="pre">GraphConv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_feats</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_feats</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'both'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">allow_zero_in_degree</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/dgl/nn/pytorch/conv/graphconv.html#GraphConv"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dgl.nn.pytorch.conv.GraphConv" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Graph convolutional layer from <a class="reference external" href="https://arxiv.org/abs/1609.02907">Semi-Supervised Classification with Graph Convolutional
Networks</a></p>
<p>Mathematically it is defined as follows:</p>
<div class="math notranslate nohighlight">
\[h_i^{(l+1)} = \sigma(b^{(l)} + \sum_{j\in\mathcal{N}(i)}\frac{1}{c_{ji}}h_j^{(l)}W^{(l)})\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathcal{N}(i)\)</span> is the set of neighbors of node <span class="math notranslate nohighlight">\(i\)</span>,
<span class="math notranslate nohighlight">\(c_{ji}\)</span> is the product of the square root of node degrees
(i.e.,  <span class="math notranslate nohighlight">\(c_{ji} = \sqrt{|\mathcal{N}(j)|}\sqrt{|\mathcal{N}(i)|}\)</span>),
and <span class="math notranslate nohighlight">\(\sigma\)</span> is an activation function.</p>
<p>If a weight tensor on each edge is provided, the weighted graph convolution is defined as:</p>
<div class="math notranslate nohighlight">
\[h_i^{(l+1)} = \sigma(b^{(l)} + \sum_{j\in\mathcal{N}(i)}\frac{e_{ji}}{c_{ji}}h_j^{(l)}W^{(l)})\]</div>
<p>where <span class="math notranslate nohighlight">\(e_{ji}\)</span> is the scalar weight on the edge from node <span class="math notranslate nohighlight">\(j\)</span> to node <span class="math notranslate nohighlight">\(i\)</span>.
This is NOT equivalent to the weighted graph convolutional network formulation in the paper.</p>
<p>To customize the normalization term <span class="math notranslate nohighlight">\(c_{ji}\)</span>, one can first set <code class="docutils literal notranslate"><span class="pre">norm='none'</span></code> for
the model, and send the pre-normalized <span class="math notranslate nohighlight">\(e_{ji}\)</span> to the forward computation. We provide
<code class="xref py py-class docutils literal notranslate"><span class="pre">EdgeWeightNorm</span></code> to normalize scalar edge weight following the GCN paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_feats</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a>) – Input feature size; i.e, the number of dimensions of <span class="math notranslate nohighlight">\(h_j^{(l)}\)</span>.</p></li>
<li><p><strong>out_feats</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a>) – Output feature size; i.e., the number of dimensions of <span class="math notranslate nohighlight">\(h_i^{(l+1)}\)</span>.</p></li>
<li><p><strong>norm</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a><em>, </em><em>optional</em>) – <p>How to apply the normalizer.  Can be one of the following values:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">right</span></code>, to divide the aggregated messages by each node’s in-degrees,
which is equivalent to averaging the received messages.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">none</span></code>, where no normalization is applied.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">both</span></code> (default), where the messages are scaled with <span class="math notranslate nohighlight">\(1/c_{ji}\)</span> above, equivalent
to symmetric normalization.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">left</span></code>, to divide the messages sent out from each node by its out-degrees,
equivalent to random walk normalization.</p></li>
</ul>
</p></li>
<li><p><strong>weight</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – If True, apply a linear layer. Otherwise, aggregating the messages
without a weight matrix.</p></li>
<li><p><strong>bias</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – If True, adds a learnable bias to the output. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></li>
<li><p><strong>activation</strong> (<em>callable activation function/layer</em><em> or </em><em>None</em><em>, </em><em>optional</em>) – If not None, applies an activation function to the updated node features.
Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>allow_zero_in_degree</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – If there are 0-in-degree nodes in the graph, output for those nodes will be invalid
since no message will be passed to those nodes. This is harmful for some applications
causing silent performance regression. This module will raise a DGLError if it detects
0-in-degree nodes in input graph. By setting <code class="docutils literal notranslate"><span class="pre">True</span></code>, it will suppress the check
and let the users handle it by themselves. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="dgl.nn.pytorch.conv.GraphConv.weight">
<span class="sig-name descname"><span class="pre">weight</span></span><a class="headerlink" href="#dgl.nn.pytorch.conv.GraphConv.weight" title="Link to this definition"></a></dt>
<dd><p>The learnable weight tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="dgl.nn.pytorch.conv.GraphConv.bias">
<span class="sig-name descname"><span class="pre">bias</span></span><a class="headerlink" href="#dgl.nn.pytorch.conv.GraphConv.bias" title="Link to this definition"></a></dt>
<dd><p>The learnable bias tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Zero in-degree nodes will lead to invalid output value. This is because no message
will be passed to those nodes, the aggregation function will be appied on empty input.
A common practice to avoid this is to add a self-loop for each node in the graph if
it is homogeneous, which can be achieved by:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">g</span> <span class="o">=</span> <span class="o">...</span> <span class="c1"># a DGLGraph</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">g</span> <span class="o">=</span> <span class="n">dgl</span><span class="o">.</span><span class="n">add_self_loop</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>
</pre></div>
</div>
<p>Calling <code class="docutils literal notranslate"><span class="pre">add_self_loop</span></code> will not work for some graphs, for example, heterogeneous graph
since the edge type can not be decided for self_loop edges. Set <code class="docutils literal notranslate"><span class="pre">allow_zero_in_degree</span></code>
to <code class="docutils literal notranslate"><span class="pre">True</span></code> for those cases to unblock the code and handle zero-in-degree nodes manually.
A common practise to handle this is to filter out the nodes with zero-in-degree when use
after conv.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">dgl</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">dgl.nn</span> <span class="kn">import</span> <span class="n">GraphConv</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Case 1: Homogeneous graph</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">g</span> <span class="o">=</span> <span class="n">dgl</span><span class="o">.</span><span class="n">graph</span><span class="p">(([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">3</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">g</span> <span class="o">=</span> <span class="n">dgl</span><span class="o">.</span><span class="n">add_self_loop</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">feat</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">conv</span> <span class="o">=</span> <span class="n">GraphConv</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="s1">'both'</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">feat</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
<span class="go">tensor([[ 1.3326, -0.2797],</span>
<span class="go">        [ 1.4673, -0.3080],</span>
<span class="go">        [ 1.3326, -0.2797],</span>
<span class="go">        [ 1.6871, -0.3541],</span>
<span class="go">        [ 1.7711, -0.3717],</span>
<span class="go">        [ 1.0375, -0.2178]], grad_fn=&lt;AddBackward0&gt;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># allow_zero_in_degree example</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">g</span> <span class="o">=</span> <span class="n">dgl</span><span class="o">.</span><span class="n">graph</span><span class="p">(([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">3</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">conv</span> <span class="o">=</span> <span class="n">GraphConv</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="s1">'both'</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">allow_zero_in_degree</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">feat</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
<span class="go">tensor([[-0.2473, -0.4631],</span>
<span class="go">        [-0.3497, -0.6549],</span>
<span class="go">        [-0.3497, -0.6549],</span>
<span class="go">        [-0.4221, -0.7905],</span>
<span class="go">        [-0.3497, -0.6549],</span>
<span class="go">        [ 0.0000,  0.0000]], grad_fn=&lt;AddBackward0&gt;)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Case 2: Unidirectional bipartite graph</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">u</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">g</span> <span class="o">=</span> <span class="n">dgl</span><span class="o">.</span><span class="n">heterograph</span><span class="p">({(</span><span class="s1">'_U'</span><span class="p">,</span> <span class="s1">'_E'</span><span class="p">,</span> <span class="s1">'_V'</span><span class="p">)</span> <span class="p">:</span> <span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">)})</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">u_fea</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v_fea</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">conv</span> <span class="o">=</span> <span class="n">GraphConv</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="s1">'both'</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="p">(</span><span class="n">u_fea</span><span class="p">,</span> <span class="n">v_fea</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span>
<span class="go">tensor([[-0.2994,  0.6106],</span>
<span class="go">        [-0.4482,  0.5540],</span>
<span class="go">        [-0.5287,  0.8235],</span>
<span class="go">        [-0.2994,  0.6106]], grad_fn=&lt;AddBackward0&gt;)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="dgl.nn.pytorch.conv.GraphConv.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">graph</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feat</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">edge_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/dgl/nn/pytorch/conv/graphconv.html#GraphConv.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dgl.nn.pytorch.conv.GraphConv.forward" title="Link to this definition"></a></dt>
<dd><section id="description">
<h2>Description<a class="headerlink" href="#description" title="Link to this heading"></a></h2>
<p>Compute graph convolution.</p>
<dl class="field-list simple">
<dt class="field-odd">param graph<span class="colon">:</span></dt>
<dd class="field-odd"><p>The graph.</p>
</dd>
<dt class="field-even">type graph<span class="colon">:</span></dt>
<dd class="field-even"><p>DGLGraph</p>
</dd>
<dt class="field-odd">param feat<span class="colon">:</span></dt>
<dd class="field-odd"><p>If a torch.Tensor is given, it represents the input feature of shape
<span class="math notranslate nohighlight">\((N, D_{in})\)</span>
where <span class="math notranslate nohighlight">\(D_{in}\)</span> is size of input feature, <span class="math notranslate nohighlight">\(N\)</span> is the number of nodes.
If a pair of torch.Tensor is given, which is the case for bipartite graph, the pair
must contain two tensors of shape <span class="math notranslate nohighlight">\((N_{in}, D_{in_{src}})\)</span> and
<span class="math notranslate nohighlight">\((N_{out}, D_{in_{dst}})\)</span>.</p>
</dd>
<dt class="field-even">type feat<span class="colon">:</span></dt>
<dd class="field-even"><p>torch.Tensor or pair of torch.Tensor</p>
</dd>
<dt class="field-odd">param weight<span class="colon">:</span></dt>
<dd class="field-odd"><p>Optional external weight tensor.</p>
</dd>
<dt class="field-even">type weight<span class="colon">:</span></dt>
<dd class="field-even"><p>torch.Tensor, optional</p>
</dd>
<dt class="field-odd">param edge_weight<span class="colon">:</span></dt>
<dd class="field-odd"><p>Optional tensor on the edge. If given, the convolution will weight
with regard to the message.</p>
</dd>
<dt class="field-even">type edge_weight<span class="colon">:</span></dt>
<dd class="field-even"><p>torch.Tensor, optional</p>
</dd>
<dt class="field-odd">returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The output feature</p>
</dd>
<dt class="field-even">rtype<span class="colon">:</span></dt>
<dd class="field-even"><p>torch.Tensor</p>
</dd>
<dt class="field-odd">raises DGLError<span class="colon">:</span></dt>
<dd class="field-odd"><p>Case 1:
    If there are 0-in-degree nodes in the input graph, it will raise DGLError
    since no message will be passed to those nodes. This will cause invalid output.
    The error can be ignored by setting <code class="docutils literal notranslate"><span class="pre">allow_zero_in_degree</span></code> parameter to <code class="docutils literal notranslate"><span class="pre">True</span></code>.
    
    Case 2:
    External weight is provided while at the same time the module
    has defined its own weight parameter.</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>Input shape: <span class="math notranslate nohighlight">\((N, *, \text{in_feats})\)</span> where * means any number of additional
dimensions, <span class="math notranslate nohighlight">\(N\)</span> is the number of nodes.</p></li>
<li><p>Output shape: <span class="math notranslate nohighlight">\((N, *, \text{out_feats})\)</span> where all but the last dimension are
the same shape as the input.</p></li>
<li><p>Weight shape: <span class="math notranslate nohighlight">\((\text{in_feats}, \text{out_feats})\)</span>.</p></li>
</ul>
</div>
</section>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="dgl.nn.pytorch.conv.GraphConv.reset_parameters">
<span class="sig-name descname"><span class="pre">reset_parameters</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/dgl/nn/pytorch/conv/graphconv.html#GraphConv.reset_parameters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dgl.nn.pytorch.conv.GraphConv.reset_parameters" title="Link to this definition"></a></dt>
<dd><section id="id1">
<h2>Description<a class="headerlink" href="#id1" title="Link to this heading"></a></h2>
<p>Reinitialize learnable parameters.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The model parameters are initialized as in the
<a class="reference external" href="https://github.com/tkipf/gcn/blob/master/gcn/layers.py">original implementation</a>
where the weight <span class="math notranslate nohighlight">\(W^{(l)}\)</span> is initialized using Glorot uniform initialization
and the bias is initialized to be zero.</p>
</div>
</section>
</dd></dl>
</dd></dl>
</section>
</div>
</div>
<footer><div aria-label="Footer" class="rst-footer-buttons" role="navigation">
<a accesskey="p" class="btn btn-neutral float-left" href="../api/python/nn-pytorch.html" rel="prev" title="dgl.nn (PyTorch)"><span aria-hidden="true" class="fa fa-arrow-circle-left"></span> Previous</a>
<a accesskey="n" class="btn btn-neutral float-right" href="dgl.nn.pytorch.conv.EdgeWeightNorm.html" rel="next" title="EdgeWeightNorm">Next <span aria-hidden="true" class="fa fa-arrow-circle-right"></span></a>
</div>
<hr/>
<div role="contentinfo">
<p>© Copyright 2018, DGL Team.</p>
</div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
</div>
</div>
</section>
</div>
<div aria-label="Versions" class="rst-versions" data-toggle="rst-versions" role="note">
<span class="rst-current-version" data-toggle="rst-current-version">
<span class="fa fa-book"> Read the Docs</span>
            v: 1.1.x
            <span class="fa fa-caret-down"></span>
</span>
<div class="rst-other-versions">
<dl>
<dt>Versions</dt>
<div id="version-list">
<!-- 动态插入的版本列表将出现在这里 -->
</div>
</dl>
<dl>
<dt>Downloads</dt>
<!-- 下载内容 -->
</dl>
<dl>
<dt>On Read the Docs</dt>
<dd><a href="//doc-build.dgl.ai/projects/dgl/?fromdocs=dgl">Project Home</a></dd>
<dd><a href="//doc-build.dgl.ai/builds/dgl/?fromdocs=dgl">Builds</a></dd>
</dl>
</div>
</div>
<script>
        document.addEventListener("DOMContentLoaded", function() {
            // 假设 branches.json 位于同目录下
            fetch('/branches.json')
                .then(response => response.json())
                .then(data => {
                    var versionListDiv = document.getElementById('version-list');
                    data.branches.forEach(function(branch) {
                        var dd = document.createElement('dd');
                        var a = document.createElement('a');
                        a.href = branch.url;
                        a.textContent = branch.name;
                        dd.appendChild(a);
                        versionListDiv.appendChild(dd);
                    });
                })
                .catch(error => console.error('Error loading branches:', error));
        });
    </script>

<script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
</body>
</html>