<!DOCTYPE html>

<html class="writer-html5" data-content_root="../" lang="en">
<head>
<meta charset="utf-8"/><meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Build Model — DGL 2.1.0 documentation</title>
<link href="../_static/pygments.css?v=80d5e7a1" rel="stylesheet" type="text/css"/>
<link href="../_static/css/theme.css?v=19f00094" rel="stylesheet" type="text/css"/>
<link href="../_static/graphviz.css?v=fd3f3429" rel="stylesheet" type="text/css"/>
<link href="../_static/copybutton.css?v=76b2166b" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery.css?v=d2d258e8" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery-binder.css?v=f4aeca0c" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery-dataframe.css?v=2082cf3c" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" rel="stylesheet" type="text/css"/>
<link href="../_static/css/custom.css?v=0bf289b5" rel="stylesheet" type="text/css"/>
<!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
<script src="../_static/jquery.js?v=5d32c60e"></script>
<script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
<script src="../_static/documentation_options.js?v=20623aea"></script>
<script src="../_static/doctools.js?v=9a2dae69"></script>
<script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
<script src="../_static/clipboard.min.js?v=a7894cd8"></script>
<script src="../_static/copybutton.js?v=ccdb6887"></script>
<script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
<script src="../_static/js/theme.js"></script>
<link href="../genindex.html" rel="index" title="Index"/>
<link href="../search.html" rel="search" title="Search"/>
<link href="data.html" rel="next" title="Prepare Data"/>
<link href="index.html" rel="prev" title="🆕 Tutorial: Graph Transformer"/>
</head>
<body class="wy-body-for-nav">
<div class="wy-grid-for-nav">
<nav class="wy-nav-side" data-toggle="wy-nav-shift">
<div class="wy-side-scroll">
<div class="wy-side-nav-search">
<a class="icon icon-home" href="../index.html">
            DGL
          </a>
<div class="version">
                2.1.0
              </div>
<div role="search">
<form action="../search.html" class="wy-form" id="rtd-search-form" method="get">
<input aria-label="Search docs" name="q" placeholder="Search docs" type="text"/>
<input name="check_keywords" type="hidden" value="yes"/>
<input name="area" type="hidden" value="default"/>
</form>
</div>
</div><div aria-label="Navigation menu" class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation">
<p class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../install/index.html">Install and Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/blitz/index.html">A Blitz Introduction to DGL</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Materials</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../stochastic_training/index.html">🆕 Stochastic Training of GNNs with GraphBolt</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guide/index.html">User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guide_cn/index.html">用户指南【包含过时信息】</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guide_ko/index.html">사용자 가이드[시대에 뒤쳐진]</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">🆕 Tutorial: Graph Transformer</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Build Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="data.html">Prepare Data</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../notebooks/sparse/index.html">Tutorials: dgl.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/cpu/index.html">Training on CPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/multi/index.html">Training on Multiple GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/dist/index.html">Distributed training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/models/index.html">Paper Study with DGL</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.html">dgl</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.data.html">dgl.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.dataloading.html">dgl.dataloading</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.DGLGraph.html">dgl.DGLGraph</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.distributed.html">dgl.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.function.html">dgl.function</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.geometry.html">dgl.geometry</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.graphbolt.html">🆕 dgl.graphbolt</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/nn-pytorch.html">dgl.nn (PyTorch)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/nn.functional.html">dgl.nn.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.ops.html">dgl.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.optim.html">dgl.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.sampling.html">dgl.sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.sparse_v0.html">dgl.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.multiprocessing.html">dgl.multiprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/transforms.html">dgl.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/udf.html">User-defined Functions</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../contribute.html">Contribute to DGL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../developer/ffi.html">DGL Foreign Function Interface (FFI)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../performance.html">Performance Benchmarks</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Misc</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">Frequently Asked Questions (FAQ)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../env_var.html">Environment Variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="../resources.html">Resources</a></li>
</ul>
</div>
</div>
</nav>
<section class="wy-nav-content-wrap" data-toggle="wy-nav-shift"><nav aria-label="Mobile navigation menu" class="wy-nav-top">
<i class="fa fa-bars" data-toggle="wy-nav-top"></i>
<a href="../index.html">DGL</a>
</nav>
<div class="wy-nav-content">
<div class="rst-content">
<div aria-label="Page navigation" role="navigation">
<ul class="wy-breadcrumbs">
<li><a aria-label="Home" class="icon icon-home" href="../index.html"></a></li>
<li class="breadcrumb-item"><a href="index.html">🆕 Tutorial: Graph Transformer</a></li>
<li class="breadcrumb-item active">Build Model</li>
<li class="wy-breadcrumbs-aside">
<a href="../_sources/graphtransformer/model.rst.txt" rel="nofollow"> View page source</a>
</li>
</ul>
<hr/>
</div>
<div class="document" itemscope="itemscope" itemtype="http://schema.org/Article" role="main">
<div itemprop="articleBody">
<section id="build-model">
<h1>Build Model<a class="headerlink" href="#build-model" title="Link to this heading"></a></h1>
<p><strong>GraphTransformer</strong> is a graph neural network that uses multi-head self-attention (sparse or dense) to encode the graph structure and node features. It is a generalization of the <a class="reference external" href="https://arxiv.org/abs/1706.03762">Transformer</a> architecture to arbitrary graphs.</p>
<p>In this tutorial, we will show how to build a graph transformer model with DGL using the <a class="reference external" href="https://arxiv.org/abs/2106.05234">Graphormer</a> model as an example.</p>
<p>Graphormer is a Transformer model designed for graph-structured data, which encodes the structural information of a graph into the standard Transformer. Specifically, Graphormer utilizes degree encoding to measure the importance of nodes, spatial and path Encoding to measure the relation between node pairs. The degree encoding and the node features serve as input to Graphormer, while the spatial and path encoding act as bias terms in the self-attention module.</p>
<section id="degree-encoding">
<h2>Degree Encoding<a class="headerlink" href="#degree-encoding" title="Link to this heading"></a></h2>
<p>The degree encoder is a learnable embedding layer that encodes the degree of each node into a vector. It takes as input the batched input and output degrees of graph nodes, and outputs the degree embeddings of the nodes.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">degree_encoder</span> <span class="o">=</span> <span class="n">dgl</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">DegreeEncoder</span><span class="p">(</span>
    <span class="n">max_degree</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>  <span class="c1"># the maximum degree to cut off</span>
    <span class="n">embedding_dim</span><span class="o">=</span><span class="mi">512</span>  <span class="c1"># the dimension of the degree embedding</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="path-encoding">
<h2>Path Encoding<a class="headerlink" href="#path-encoding" title="Link to this heading"></a></h2>
<p>The path encoder encodes the edge features on the shortest path between two nodes to get attention bias for the self-attention module. It takes as input the batched edge features in shape  and outputs the attention bias based on path encoding.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">path_encoder</span> <span class="o">=</span> <span class="n">PathEncoder</span><span class="p">(</span>
    <span class="n">max_len</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>  <span class="c1"># the maximum length of the shortest path</span>
    <span class="n">feat_dim</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>  <span class="c1"># the dimension of the edge feature</span>
    <span class="n">num_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>  <span class="c1"># the number of attention heads</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="spatial-encoding">
<h2>Spatial Encoding<a class="headerlink" href="#spatial-encoding" title="Link to this heading"></a></h2>
<p>The spatial encoder encodes the shortest distance between two nodes to get attention bias for the self-attention module. It takes as input the shortest distance between two nodes and outputs the attention bias based on spatial encoding.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">spatial_encoder</span> <span class="o">=</span> <span class="n">SpatialEncoder</span><span class="p">(</span>
    <span class="n">max_dist</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>  <span class="c1"># the maximum distance between two nodes</span>
    <span class="n">num_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>  <span class="c1"># the number of attention heads</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="graphormer-layer">
<h2>Graphormer Layer<a class="headerlink" href="#graphormer-layer" title="Link to this heading"></a></h2>
<p>The Graphormer layer is like a Transformer encoder layer with the Multi-head Attention part replaced with <code class="xref py py-class docutils literal notranslate"><span class="pre">BiasedMHA</span></code>. It takes in not only the input node features, but also the attention bias computed computed above, and outputs the updated node features.</p>
<p>We can stack multiple Graphormer layers as a list just like implementing a Transformer encoder in PyTorch.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">layers</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span>
    <span class="n">GraphormerLayer</span><span class="p">(</span>
        <span class="n">feat_size</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>  <span class="c1"># the dimension of the input node features</span>
        <span class="n">hidden_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>  <span class="c1"># the dimension of the hidden layer</span>
        <span class="n">num_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>  <span class="c1"># the number of attention heads</span>
        <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>  <span class="c1"># the dropout rate</span>
        <span class="n">activation</span><span class="o">=</span><span class="n">th</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>  <span class="c1"># the activation function</span>
        <span class="n">norm_first</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># whether to put the normalization before attention and feedforward</span>
    <span class="p">)</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
<span class="p">])</span>
</pre></div>
</div>
</section>
<section id="model-forward">
<h2>Model Forward<a class="headerlink" href="#model-forward" title="Link to this heading"></a></h2>
<p>Grouping the modules above defines the primary components of the Graphormer model. We then can define the forward process as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">node_feat</span><span class="p">,</span> <span class="n">in_degree</span><span class="p">,</span> <span class="n">out_degree</span><span class="p">,</span> <span class="n">attn_mask</span><span class="p">,</span> <span class="n">path_data</span><span class="p">,</span> <span class="n">dist</span> <span class="o">=</span> \
    <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">dataloader</span><span class="p">))</span>  <span class="c1">#  we will use the first batch as an example</span>
<span class="n">num_graphs</span><span class="p">,</span> <span class="n">max_num_nodes</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">node_feat</span><span class="o">.</span><span class="n">shape</span>
<span class="n">deg_emb</span> <span class="o">=</span> <span class="n">degree_encoder</span><span class="p">(</span><span class="n">th</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">in_degree</span><span class="p">,</span> <span class="n">out_degree</span><span class="p">)))</span>

<span class="c1"># node feature + degree encoding as input</span>
<span class="n">node_feat</span> <span class="o">=</span> <span class="n">node_feat</span> <span class="o">+</span> <span class="n">deg_emb</span>

<span class="c1"># spatial encoding and path encoding serve as attention bias</span>
<span class="n">path_encoding</span> <span class="o">=</span> <span class="n">path_encoder</span><span class="p">(</span><span class="n">dist</span><span class="p">,</span> <span class="n">path_data</span><span class="p">)</span>
<span class="n">spatial_encoding</span> <span class="o">=</span> <span class="n">spatial_encoder</span><span class="p">(</span><span class="n">dist</span><span class="p">)</span>
<span class="n">attn_bias</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:,</span> <span class="mi">1</span><span class="p">:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">path_encoding</span> <span class="o">+</span> <span class="n">spatial_encoding</span>

<span class="c1"># graphormer layers</span>
<span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">layers</span><span class="p">:</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span>
        <span class="n">x</span><span class="p">,</span>
        <span class="n">attn_mask</span><span class="o">=</span><span class="n">attn_mask</span><span class="p">,</span>
        <span class="n">attn_bias</span><span class="o">=</span><span class="n">attn_bias</span><span class="p">,</span>
    <span class="p">)</span>
</pre></div>
</div>
<p>For simplicity, we omit some details in the forward process. For the complete implementation, please refer to the <a class="reference external" href="https://github.com/dmlc/dgl/tree/master/examples/core/Graphormer">Graphormer example</a>.</p>
<p>You can also explore other <a class="reference external" href="https://docs.dgl.ai/api/python/nn-pytorch.html#utility-modules-for-graph-transformer">utility modules</a> to customize your own graph transformer model. In the next section, we will show how to prepare the data for training.</p>
</section>
</section>
</div>
</div>
<footer><div aria-label="Footer" class="rst-footer-buttons" role="navigation">
<a accesskey="p" class="btn btn-neutral float-left" href="index.html" rel="prev" title="🆕 Tutorial: Graph Transformer"><span aria-hidden="true" class="fa fa-arrow-circle-left"></span> Previous</a>
<a accesskey="n" class="btn btn-neutral float-right" href="data.html" rel="next" title="Prepare Data">Next <span aria-hidden="true" class="fa fa-arrow-circle-right"></span></a>
</div>
<hr/>
<div role="contentinfo">
<p>© Copyright 2018, DGL Team.</p>
</div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
</div>
</div>
</section>
</div>
<div aria-label="Versions" class="rst-versions" data-toggle="rst-versions" role="note">
<span class="rst-current-version" data-toggle="rst-current-version">
<span class="fa fa-book"> Read the Docs</span>
<span id="version-placeholder">v: latest</span>
<span class="fa fa-caret-down"></span>
</span>
<div class="rst-other-versions">
<dl>
<dt>Versions</dt>
<div id="version-list">
<!-- 动态插入的版本列表将出现在这里 -->
</div>
</dl>
<dl>
<dt>Downloads</dt>
<!-- 下载内容 -->
</dl>
<dl>
<dt>On Read the Docs</dt>
<dd><a href="//doc-build.dgl.ai/projects/dgl/?fromdocs=dgl">Project Home</a></dd>
<dd><a href="//doc-build.dgl.ai/builds/dgl/?fromdocs=dgl">Builds</a></dd>
</dl>
</div>
</div>
<script>
        document.addEventListener("DOMContentLoaded", function() {
            fetch('/dgl_docs/branches.json')
                .then(response => response.json())
                .then(data => {
                    var versionListDiv = document.getElementById('version-list');
                    data.branches.forEach(function(branch) {
                        var dd = document.createElement('dd');
                        var a = document.createElement('a');
                        a.href = branch.url;
                        a.textContent = branch.name;
                        dd.appendChild(a);
                        versionListDiv.appendChild(dd);
                    });
                })
                .catch(error => console.error('Error loading branches:', error));
        });
        document.addEventListener("DOMContentLoaded", function() {
            // 获取当前路径
            var path = window.location.pathname;
            var versionPlaceholder = document.getElementById('version-placeholder');

            // 检查路径中是否包含 'en'
            if (path.includes('/en/')) {
                // 提取 'en' 后的文件夹作为版本号
                var parts = path.split('/en/');
                if (parts[1]) {
                    var folders = parts[1].split('/');
                    if (folders.length > 0 && folders[0]) {
                        versionPlaceholder.textContent = 'v: ' + folders[0];
                    } else {
                        versionPlaceholder.textContent = 'v: latest';
                    }
                } else {
                    versionPlaceholder.textContent = 'v: latest';
                }
            } else {
                versionPlaceholder.textContent = 'v: latest';
            }
        });
    </script>

<div aria-label="Versions" class="rst-versions" data-toggle="rst-versions" role="note">
<span class="rst-current-version" data-toggle="rst-current-version">
<span class="fa fa-book"> Read the Docs</span>
<span id="version-placeholder">v: latest</span>
<span class="fa fa-caret-down"></span>
</span>
<div class="rst-other-versions">
<dl>
<dt>Versions</dt>
<div id="version-list">
<!-- 动态插入的版本列表将出现在这里 -->
</div>
</dl>
<dl>
<dt>Downloads</dt>
<!-- 下载内容 -->
</dl>
<dl>
<dt>On Read the Docs</dt>
<dd><a href="//doc-build.dgl.ai/projects/dgl/?fromdocs=dgl">Project Home</a></dd>
<dd><a href="//doc-build.dgl.ai/builds/dgl/?fromdocs=dgl">Builds</a></dd>
</dl>
</div>
</div>
<script>
        document.addEventListener("DOMContentLoaded", function() {
            fetch('/dgl_docs/branches.json')
                .then(response => response.json())
                .then(data => {
                    var versionListDiv = document.getElementById('version-list');
                    data.branches.forEach(function(branch) {
                        var dd = document.createElement('dd');
                        var a = document.createElement('a');
                        a.href = branch.url;
                        a.textContent = branch.name;
                        dd.appendChild(a);
                        versionListDiv.appendChild(dd);
                    });
                })
                .catch(error => console.error('Error loading branches:', error));
        });
        document.addEventListener("DOMContentLoaded", function() {
            // 获取当前路径
            var path = window.location.pathname;
            var versionPlaceholder = document.getElementById('version-placeholder');

            // 检查路径中是否包含 'en'
            if (path.includes('/en/')) {
                // 提取 'en' 后的文件夹作为版本号
                var parts = path.split('/en/');
                if (parts[1]) {
                    var folders = parts[1].split('/');
                    if (folders.length > 0 && folders[0]) {
                        versionPlaceholder.textContent = 'v: ' + folders[0];
                    } else {
                        versionPlaceholder.textContent = 'v: latest';
                    }
                } else {
                    versionPlaceholder.textContent = 'v: latest';
                }
            } else {
                versionPlaceholder.textContent = 'v: latest';
            }
        });
    </script>
<script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
</body>
</html>