<!DOCTYPE html>

<html class="writer-html5" data-content_root="../../../" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>dgl.utils.internal — DGL 2.5 documentation</title>
<link href="../../../_static/pygments.css?v=80d5e7a1" rel="stylesheet" type="text/css"/>
<link href="../../../_static/css/theme.css?v=19f00094" rel="stylesheet" type="text/css"/>
<link href="../../../_static/graphviz.css?v=fd3f3429" rel="stylesheet" type="text/css"/>
<link href="../../../_static/copybutton.css?v=76b2166b" rel="stylesheet" type="text/css"/>
<link href="../../../_static/sg_gallery.css?v=d2d258e8" rel="stylesheet" type="text/css"/>
<link href="../../../_static/sg_gallery-binder.css?v=f4aeca0c" rel="stylesheet" type="text/css"/>
<link href="../../../_static/sg_gallery-dataframe.css?v=2082cf3c" rel="stylesheet" type="text/css"/>
<link href="../../../_static/sg_gallery-rendered-html.css?v=1277b6f3" rel="stylesheet" type="text/css"/>
<link href="../../../_static/css/custom.css?v=0bf289b5" rel="stylesheet" type="text/css"/>
<!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
<script src="../../../_static/jquery.js?v=5d32c60e"></script>
<script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
<script src="../../../_static/documentation_options.js?v=38d273f4"></script>
<script src="../../../_static/doctools.js?v=9a2dae69"></script>
<script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
<script src="../../../_static/clipboard.min.js?v=a7894cd8"></script>
<script src="../../../_static/copybutton.js?v=ccdb6887"></script>
<script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
<script src="../../../_static/js/theme.js"></script>
<link href="../../../genindex.html" rel="index" title="Index"/>
<link href="../../../search.html" rel="search" title="Search"/>
</head>
<body class="wy-body-for-nav">
<div class="wy-grid-for-nav">
<nav class="wy-nav-side" data-toggle="wy-nav-shift">
<div class="wy-side-scroll">
<div class="wy-side-nav-search">
<a class="icon icon-home" href="../../../index.html">
            DGL
          </a>
<div class="version">
                2.5
              </div>
<div role="search">
<form action="../../../search.html" class="wy-form" id="rtd-search-form" method="get">
<input aria-label="Search docs" name="q" placeholder="Search docs" type="text"/>
<input name="check_keywords" type="hidden" value="yes"/>
<input name="area" type="hidden" value="default"/>
</form>
</div>
</div><div aria-label="Navigation menu" class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation">
<p class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../install/index.html">Install and Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/blitz/index.html">A Blitz Introduction to DGL</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Materials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../stochastic_training/index.html">🆕 Stochastic Training of GNNs with GraphBolt</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../guide/index.html">User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../guide_cn/index.html">用户指南【包含过时信息】</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../guide_ko/index.html">사용자 가이드[시대에 뒤쳐진]</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../graphtransformer/index.html">🆕 Tutorial: Graph Transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notebooks/sparse/index.html">Tutorials: dgl.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/cpu/index.html">Training on CPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/multi/index.html">Training on Multiple GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/dist/index.html">Distributed training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/models/index.html">Paper Study with DGL</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.html">dgl</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.data.html">dgl.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.dataloading.html">dgl.dataloading</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.DGLGraph.html">dgl.DGLGraph</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.distributed.html">dgl.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.function.html">dgl.function</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.geometry.html">dgl.geometry</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.graphbolt.html">🆕 dgl.graphbolt</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/nn-pytorch.html">dgl.nn (PyTorch)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/nn.functional.html">dgl.nn.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.ops.html">dgl.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.optim.html">dgl.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.sampling.html">dgl.sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.sparse_v0.html">dgl.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.multiprocessing.html">dgl.multiprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/transforms.html">dgl.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/udf.html">User-defined Functions</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../contribute.html">Contribute to DGL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../developer/ffi.html">DGL Foreign Function Interface (FFI)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../performance.html">Performance Benchmarks</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Misc</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../faq.html">Frequently Asked Questions (FAQ)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../env_var.html">Environment Variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../resources.html">Resources</a></li>
</ul>
</div>
</div>
</nav>
<section class="wy-nav-content-wrap" data-toggle="wy-nav-shift"><nav aria-label="Mobile navigation menu" class="wy-nav-top">
<i class="fa fa-bars" data-toggle="wy-nav-top"></i>
<a href="../../../index.html">DGL</a>
</nav>
<div class="wy-nav-content">
<div class="rst-content">
<div aria-label="Page navigation" role="navigation">
<ul class="wy-breadcrumbs">
<li><a aria-label="Home" class="icon icon-home" href="../../../index.html"></a></li>
<li class="breadcrumb-item"><a href="../../index.html">Module code</a></li>
<li class="breadcrumb-item active">dgl.utils.internal</li>
<li class="wy-breadcrumbs-aside">
</li>
</ul>
<hr/>
</div>
<div class="document" itemscope="itemscope" itemtype="http://schema.org/Article" role="main">
<div itemprop="articleBody">
<h1>Source code for dgl.utils.internal</h1><div class="highlight"><pre>
<span></span><span class="sd">"""Internal utilities."""</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">absolute_import</span><span class="p">,</span> <span class="n">division</span>

<span class="kn">import</span> <span class="nn">glob</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>
<span class="kn">from</span> <span class="nn">collections.abc</span> <span class="kn">import</span> <span class="n">Iterable</span><span class="p">,</span> <span class="n">Mapping</span><span class="p">,</span> <span class="n">Sequence</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">wraps</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">..</span> <span class="kn">import</span> <span class="n">backend</span> <span class="k">as</span> <span class="n">F</span><span class="p">,</span> <span class="n">ndarray</span> <span class="k">as</span> <span class="n">nd</span>
<span class="kn">from</span> <span class="nn">.._ffi.function</span> <span class="kn">import</span> <span class="n">_init_api</span>
<span class="kn">from</span> <span class="nn">..base</span> <span class="kn">import</span> <span class="n">dgl_warning</span><span class="p">,</span> <span class="n">DGLError</span><span class="p">,</span> <span class="n">EID</span><span class="p">,</span> <span class="n">NID</span>


<span class="k">def</span> <span class="nf">is_listlike</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Return if the data is a sequence but not a string."""</span>
    <span class="k">return</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">InconsistentDtypeException</span><span class="p">(</span><span class="n">DGLError</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Exception class for inconsistent dtype between graph and tensor"""</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">msg</span><span class="o">=</span><span class="s2">""</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>  <span class="c1"># pylint: disable=W1113</span>
        <span class="n">prefix_message</span> <span class="o">=</span> <span class="s2">"DGL now requires the input tensor to have</span><span class="se">\</span>
<span class="s2">            the same dtype as the graph index's dtype(which you can get by g.idype). "</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">prefix_message</span> <span class="o">+</span> <span class="n">msg</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">Index</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Index class that can be easily converted to list/tensor."""</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">"int64"</span><span class="p">):</span>
        <span class="k">assert</span> <span class="n">dtype</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">"int32"</span><span class="p">,</span> <span class="s2">"int64"</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_data</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_initialize_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_pydata</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># a numpy type data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_user_tensor_data</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>  <span class="c1"># dictionary of user tensors</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dgl_tensor_data</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># a dgl ndarray</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_slice_data</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># a slice type data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dispatch</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tonumpy</span><span class="p">():</span>
            <span class="k">yield</span> <span class="nb">int</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_slice_data</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">slc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_slice_data</span>
            <span class="k">return</span> <span class="n">slc</span><span class="o">.</span><span class="n">stop</span> <span class="o">-</span> <span class="n">slc</span><span class="o">.</span><span class="n">start</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pydata</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_pydata</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_user_tensor_data</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">data</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_user_tensor_data</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span>
            <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_dgl_tensor_data</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tonumpy</span><span class="p">()[</span><span class="n">i</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">_dispatch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""Store data based on its type."""</span>
        <span class="k">if</span> <span class="n">F</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">F</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">!=</span> <span class="n">F</span><span class="o">.</span><span class="n">data_type_dict</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">]:</span>
                <span class="k">raise</span> <span class="n">InconsistentDtypeException</span><span class="p">(</span>
                    <span class="s2">"Index data specified as </span><span class="si">%s</span><span class="s2">, but got: </span><span class="si">%s</span><span class="s2">"</span>
                    <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">reverse_data_type_dict</span><span class="p">[</span><span class="n">F</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">data</span><span class="p">)])</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">data</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">InconsistentDtypeException</span><span class="p">(</span>
                    <span class="s2">"Index data must be 1D int32/int64 vector,</span><span class="se">\</span>
<span class="s2">                    but got shape: </span><span class="si">%s</span><span class="s2">"</span>
                    <span class="o">%</span> <span class="nb">str</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">data</span><span class="p">))</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="c1"># a tensor of one int</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_dispatch</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_user_tensor_data</span><span class="p">[</span><span class="n">F</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">data</span><span class="p">)]</span> <span class="o">=</span> <span class="n">data</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">nd</span><span class="o">.</span><span class="n">NDArray</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">):</span>
                <span class="k">raise</span> <span class="n">InconsistentDtypeException</span><span class="p">(</span>
                    <span class="s2">"Index data must be 1D </span><span class="si">%s</span><span class="s2"> vector, but got: </span><span class="si">%s</span><span class="s2">"</span>
                    <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
                <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_dgl_tensor_data</span> <span class="o">=</span> <span class="n">data</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">slice</span><span class="p">):</span>
            <span class="c1"># save it in the _pydata temporarily; materialize it if `tonumpy` is called</span>
            <span class="k">assert</span> <span class="p">(</span>
                <span class="n">data</span><span class="o">.</span><span class="n">step</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">data</span><span class="o">.</span><span class="n">step</span> <span class="ow">is</span> <span class="kc">None</span>
            <span class="p">),</span> <span class="s2">"step for slice type must be 1"</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_slice_data</span> <span class="o">=</span> <span class="nb">slice</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">start</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">stop</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>  <span class="c1"># pylint: disable=broad-except</span>
                <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span><span class="s2">"Error index data: </span><span class="si">%s</span><span class="s2">"</span> <span class="o">%</span> <span class="nb">str</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">data</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># scalar array</span>
                <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">data</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                    <span class="s2">"Index data must be 1D int64 vector,"</span>
                    <span class="s2">" but got: </span><span class="si">%s</span><span class="s2">"</span> <span class="o">%</span> <span class="nb">str</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
                <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_pydata</span> <span class="o">=</span> <span class="n">data</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_user_tensor_data</span><span class="p">[</span><span class="n">F</span><span class="o">.</span><span class="n">cpu</span><span class="p">()]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">zerocopy_from_numpy</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_pydata</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">tonumpy</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""Convert to a numpy ndarray."""</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pydata</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_slice_data</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">slc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_slice_data</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_pydata</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">slc</span><span class="o">.</span><span class="n">start</span><span class="p">,</span> <span class="n">slc</span><span class="o">.</span><span class="n">stop</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dgl_tensor_data</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_pydata</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dgl_tensor_data</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tousertensor</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_pydata</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">zerocopy_to_numpy</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pydata</span>

    <span class="k">def</span> <span class="nf">tousertensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""Convert to user tensor (defined in `backend`)."""</span>
        <span class="k">if</span> <span class="n">ctx</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ctx</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_user_tensor_data</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dgl_tensor_data</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># zero copy from dgl tensor</span>
                <span class="n">dlpack</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dgl_tensor_data</span><span class="o">.</span><span class="n">to_dlpack</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_user_tensor_data</span><span class="p">[</span><span class="n">F</span><span class="o">.</span><span class="n">cpu</span><span class="p">()]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">zerocopy_from_dlpack</span><span class="p">(</span><span class="n">dlpack</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># zero copy from numpy array</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_user_tensor_data</span><span class="p">[</span><span class="n">F</span><span class="o">.</span><span class="n">cpu</span><span class="p">()]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">zerocopy_from_numpy</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">tonumpy</span><span class="p">()</span>
                <span class="p">)</span>
        <span class="k">if</span> <span class="n">ctx</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_user_tensor_data</span><span class="p">:</span>
            <span class="c1"># copy from cpu to another device</span>
            <span class="n">data</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_user_tensor_data</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_user_tensor_data</span><span class="p">[</span><span class="n">ctx</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">copy_to</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">ctx</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_user_tensor_data</span><span class="p">[</span><span class="n">ctx</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">todgltensor</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""Convert to dgl.NDArray."""</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dgl_tensor_data</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># zero copy from user tensor</span>
            <span class="n">tsor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tousertensor</span><span class="p">()</span>
            <span class="n">dlpack</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">zerocopy_to_dlpack</span><span class="p">(</span><span class="n">tsor</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_dgl_tensor_data</span> <span class="o">=</span> <span class="n">nd</span><span class="o">.</span><span class="n">from_dlpack</span><span class="p">(</span><span class="n">dlpack</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dgl_tensor_data</span>

    <span class="k">def</span> <span class="nf">slice_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""Return the internal slice data.</span>

<span class="sd">        If this index is not initialized from slice, the return will be None.</span>
<span class="sd">        """</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_slice_data</span>

    <span class="k">def</span> <span class="nf">is_slice</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""Check if Index wraps a slice data with given start and stop"""</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_slice_data</span> <span class="o">==</span> <span class="nb">slice</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__getstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_slice_data</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># the index can be represented by a slice</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_slice_data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tousertensor</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span>

    <span class="k">def</span> <span class="nf">__setstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="c1"># Pickle compatibility check</span>
        <span class="c1"># TODO: we should store a storage version number in later releases.</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">state</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="c1"># post-0.4.4</span>
            <span class="n">data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">state</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_data</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># pre-0.4.3</span>
            <span class="n">dgl_warning</span><span class="p">(</span>
                <span class="s2">"The object is pickled before 0.4.3.  Setting dtype of graph to int64"</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="s2">"int64"</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_data</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_items</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""Return values at given positions of an Index</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        index: utils.Index</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        utils.Index</span>
<span class="sd">            The values at the given position.</span>
<span class="sd">        """</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_slice_data</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_slice_data</span><span class="o">.</span><span class="n">start</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># short-cut for identical mapping</span>
            <span class="c1"># NOTE: we don't check for out-of-bound error</span>
            <span class="k">return</span> <span class="n">index</span>
        <span class="k">elif</span> <span class="n">index</span><span class="o">.</span><span class="n">_slice_data</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># the provided index is not a slice</span>
            <span class="n">tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tousertensor</span><span class="p">()</span>
            <span class="n">index</span> <span class="o">=</span> <span class="n">index</span><span class="o">.</span><span class="n">tousertensor</span><span class="p">()</span>
            <span class="c1"># TODO(Allen): Change F.gather_row to dgl operation</span>
            <span class="k">return</span> <span class="n">Index</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">gather_row</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">index</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_slice_data</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># the current index is not a slice but the provided is a slice</span>
            <span class="n">tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tousertensor</span><span class="p">()</span>
            <span class="n">index</span> <span class="o">=</span> <span class="n">index</span><span class="o">.</span><span class="n">_slice_data</span>
            <span class="c1"># TODO(Allen): Change F.narrow_row to dgl operation</span>
            <span class="k">return</span> <span class="n">Index</span><span class="p">(</span>
                <span class="n">F</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span>
                    <span class="n">F</span><span class="o">.</span><span class="n">narrow_row</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">index</span><span class="o">.</span><span class="n">start</span><span class="p">,</span> <span class="n">index</span><span class="o">.</span><span class="n">stop</span><span class="p">),</span>
                    <span class="n">F</span><span class="o">.</span><span class="n">data_type_dict</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">],</span>
                <span class="p">),</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># both self and index wrap a slice object, then return another</span>
            <span class="c1"># Index wrapping a slice</span>
            <span class="n">start</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_slice_data</span><span class="o">.</span><span class="n">start</span>
            <span class="n">index</span> <span class="o">=</span> <span class="n">index</span><span class="o">.</span><span class="n">_slice_data</span>
            <span class="k">return</span> <span class="n">Index</span><span class="p">(</span>
                <span class="nb">slice</span><span class="p">(</span><span class="n">start</span> <span class="o">+</span> <span class="n">index</span><span class="o">.</span><span class="n">start</span><span class="p">,</span> <span class="n">start</span> <span class="o">+</span> <span class="n">index</span><span class="o">.</span><span class="n">stop</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">set_items</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""Set values at given positions of an Index. Set is not done in place,</span>
<span class="sd">        instead, a new Index object will be returned.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        index: utils.Index</span>
<span class="sd">            Positions to set values</span>
<span class="sd">        value: int or utils.Index</span>
<span class="sd">            Values to set. If value is an integer, then all positions are set</span>
<span class="sd">            to the same value</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        utils.Index</span>
<span class="sd">            The new values.</span>
<span class="sd">        """</span>
        <span class="n">tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tousertensor</span><span class="p">()</span>
        <span class="n">index</span> <span class="o">=</span> <span class="n">index</span><span class="o">.</span><span class="n">tousertensor</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">value</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">full_1d</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">index</span><span class="p">),</span> <span class="n">value</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">F</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">F</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">value</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">tousertensor</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">Index</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">scatter_row</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">value</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">append_zeros</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""Append zeros to an Index</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        num: int</span>
<span class="sd">            number of zeros to append</span>
<span class="sd">        """</span>
        <span class="k">if</span> <span class="n">num</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span>
        <span class="n">new_items</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">F</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">F</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">Index</span><span class="p">(</span><span class="n">new_items</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tousertensor</span><span class="p">()</span>
            <span class="n">tensor</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">tensor</span><span class="p">,</span> <span class="n">new_items</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">Index</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">nonzero</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""Return the nonzero positions"""</span>
        <span class="n">tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tousertensor</span><span class="p">()</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">nonzero_1d</span><span class="p">(</span><span class="n">tensor</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Index</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">has_nonzero</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""Check if there is any nonzero value in this Index"""</span>
        <span class="n">tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tousertensor</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span>


<span class="k">def</span> <span class="nf">toindex</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">"int64"</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Convert the given data to Index object.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : index data</span>
<span class="sd">        Data to create the index.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Index</span>
<span class="sd">        The index object.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    Index</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="n">data</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">Index</span><span class="p">)</span> <span class="k">else</span> <span class="n">Index</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">zero_index</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">"int64"</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Create a index with provided size initialized to zero</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    size: int</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="n">Index</span><span class="p">(</span>
        <span class="n">F</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">size</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">F</span><span class="o">.</span><span class="n">data_type_dict</span><span class="p">[</span><span class="n">dtype</span><span class="p">],</span> <span class="n">ctx</span><span class="o">=</span><span class="n">F</span><span class="o">.</span><span class="n">cpu</span><span class="p">()),</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
    <span class="p">)</span>


<span class="k">def</span> <span class="nf">set_diff</span><span class="p">(</span><span class="n">ar1</span><span class="p">,</span> <span class="n">ar2</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Find the set difference of two index arrays.</span>
<span class="sd">    Return the unique values in ar1 that are not in ar2.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    ar1: utils.Index</span>
<span class="sd">        Input index array.</span>

<span class="sd">    ar2: utils.Index</span>
<span class="sd">        Input comparison index array.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    setdiff:</span>
<span class="sd">        Array of values in ar1 that are not in ar2.</span>
<span class="sd">    """</span>
    <span class="n">ar1_np</span> <span class="o">=</span> <span class="n">ar1</span><span class="o">.</span><span class="n">tonumpy</span><span class="p">()</span>
    <span class="n">ar2_np</span> <span class="o">=</span> <span class="n">ar2</span><span class="o">.</span><span class="n">tonumpy</span><span class="p">()</span>
    <span class="n">setdiff</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">setdiff1d</span><span class="p">(</span><span class="n">ar1_np</span><span class="p">,</span> <span class="n">ar2_np</span><span class="p">)</span>
    <span class="n">setdiff</span> <span class="o">=</span> <span class="n">toindex</span><span class="p">(</span><span class="n">setdiff</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">setdiff</span>


<span class="k">class</span> <span class="nc">LazyDict</span><span class="p">(</span><span class="n">Mapping</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""A readonly dictionary that does not materialize the storage."""</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="n">keys</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_fn</span> <span class="o">=</span> <span class="n">fn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_keys</span> <span class="o">=</span> <span class="n">keys</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_keys</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fn</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__contains__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_keys</span>

    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_keys</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_keys</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">keys</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_keys</span>


<span class="k">class</span> <span class="nc">HybridDict</span><span class="p">(</span><span class="n">Mapping</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""A readonly dictonary that merges several dict-like (python dict, LazyDict).</span>

<span class="sd">    If there are duplicate keys, early keys have priority over latter ones.</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">dict_like_list</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dict_like_list</span> <span class="o">=</span> <span class="n">dict_like_list</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_keys</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">obj</span> <span class="ow">in</span> <span class="n">dict_like_list</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_keys</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">obj</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">keys</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_keys</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">obj</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dict_like_list</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">obj</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">obj</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
        <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__contains__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>

    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>


<span class="k">class</span> <span class="nc">ReadOnlyDict</span><span class="p">(</span><span class="n">Mapping</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""A readonly dictionary wrapper."""</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dict_like</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dict_like</span> <span class="o">=</span> <span class="n">dict_like</span>

    <span class="k">def</span> <span class="nf">keys</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dict_like</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dict_like</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">__contains__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dict_like</span>

    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_dict_like</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_dict_like</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">build_relabel_map</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">is_sorted</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Relabel the input ids to continuous ids that starts from zero.</span>

<span class="sd">    Ids are assigned new ids according to their ascending order.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; x = [1, 5, 3, 6]</span>
<span class="sd">    &gt;&gt;&gt; n2o, o2n = build_relabel_map(x)</span>
<span class="sd">    &gt;&gt;&gt; n2o</span>
<span class="sd">    [1, 3, 5, 6]</span>
<span class="sd">    &gt;&gt;&gt; o2n</span>
<span class="sd">    [n/a, 0, n/a, 1, n/a, 2, 3]</span>

<span class="sd">    "n/a" will be filled with 0</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x : Index</span>
<span class="sd">        The input ids.</span>
<span class="sd">    is_sorted : bool, default=False</span>
<span class="sd">        Whether the input has already been unique and sorted.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    new_to_old : tensor</span>
<span class="sd">        The mapping from new id to old id.</span>
<span class="sd">    old_to_new : tensor</span>
<span class="sd">        The mapping from old id to new id. It is a vector of length MAX(x).</span>
<span class="sd">        One can use advanced indexing to convert an old id tensor to a</span>
<span class="sd">        new id tensor: new_id = old_to_new[old_id]</span>
<span class="sd">    """</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">tousertensor</span><span class="p">()</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">is_sorted</span><span class="p">:</span>
        <span class="n">unique_x</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">sort_1d</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">unique_x</span> <span class="o">=</span> <span class="n">x</span>
    <span class="n">map_len</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">unique_x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)))</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">old_to_new</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">map_len</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">F</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">F</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span>
    <span class="n">old_to_new</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">scatter_row</span><span class="p">(</span><span class="n">old_to_new</span><span class="p">,</span> <span class="n">unique_x</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">unique_x</span><span class="p">)))</span>
    <span class="k">return</span> <span class="n">unique_x</span><span class="p">,</span> <span class="n">old_to_new</span>


<span class="k">def</span> <span class="nf">build_relabel_dict</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Relabel the input ids to continuous ids that starts from zero.</span>

<span class="sd">    The new id follows the order of the given node id list.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x : list</span>
<span class="sd">      The input ids.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    relabel_dict : dict</span>
<span class="sd">      Dict from old id to new id.</span>
<span class="sd">    """</span>
    <span class="n">relabel_dict</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
        <span class="n">relabel_dict</span><span class="p">[</span><span class="n">v</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>
    <span class="k">return</span> <span class="n">relabel_dict</span>


<span class="k">class</span> <span class="nc">CtxCachedObject</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""A wrapper to cache object generated by different context.</span>

<span class="sd">    Note: such wrapper may incur significant overhead if the wrapped object is very light.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    generator : callable</span>
<span class="sd">        A callable function that can create the object given ctx as the only argument.</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">generator</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_generator</span> <span class="o">=</span> <span class="n">generator</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_ctx_dict</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">ctx</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ctx_dict</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_ctx_dict</span><span class="p">[</span><span class="n">ctx</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generator</span><span class="p">(</span><span class="n">ctx</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ctx_dict</span><span class="p">[</span><span class="n">ctx</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">cached_member</span><span class="p">(</span><span class="n">cache</span><span class="p">,</span> <span class="n">prefix</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""A member function decorator to memorize the result.</span>

<span class="sd">    Note that the member function cannot support kwargs after being decorated.</span>
<span class="sd">    The member function must be functional. Otherwise, the behavior is undefined.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    cache : str</span>
<span class="sd">        The cache name. The cache should be a dictionary attribute</span>
<span class="sd">        in the class object.</span>
<span class="sd">    prefix : str</span>
<span class="sd">        The key prefix to save the result of the function.</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="nf">_creator</span><span class="p">(</span><span class="n">func</span><span class="p">):</span>
        <span class="nd">@wraps</span><span class="p">(</span><span class="n">func</span><span class="p">)</span>
        <span class="k">def</span> <span class="nf">wrapper</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
            <span class="n">dic</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cache</span><span class="p">)</span>
            <span class="n">key</span> <span class="o">=</span> <span class="s2">"</span><span class="si">%s</span><span class="s2">-</span><span class="si">%s</span><span class="s2">-</span><span class="si">%s</span><span class="s2">"</span> <span class="o">%</span> <span class="p">(</span>
                <span class="n">prefix</span><span class="p">,</span>
                <span class="s2">"-"</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">args</span><span class="p">]),</span>
                <span class="s2">"-"</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="o">+</span> <span class="s2">":"</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">items</span><span class="p">()]),</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">dic</span><span class="p">:</span>
                <span class="n">dic</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">dic</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">wrapper</span>

    <span class="k">return</span> <span class="n">_creator</span>


<span class="k">def</span> <span class="nf">is_dict_like</span><span class="p">(</span><span class="n">obj</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Return true if the object can be treated as a dictionary."""</span>
    <span class="k">return</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">Mapping</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">reorder</span><span class="p">(</span><span class="n">dict_like</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Reorder each column in the dict according to the index.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    dict_like : dict of tensors</span>
<span class="sd">        The dict to be reordered.</span>
<span class="sd">    index : dgl.utils.Index</span>
<span class="sd">        The reorder index.</span>
<span class="sd">    """</span>
    <span class="n">new_dict</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">dict_like</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">idx_ctx</span> <span class="o">=</span> <span class="n">index</span><span class="o">.</span><span class="n">tousertensor</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">val</span><span class="p">))</span>
        <span class="n">new_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">gather_row</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">idx_ctx</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">new_dict</span>


<span class="k">def</span> <span class="nf">reorder_index</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="n">order</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Reorder the idx according to the given order</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    idx : utils.Index</span>
<span class="sd">        The index to be reordered.</span>
<span class="sd">    order : utils.Index</span>
<span class="sd">        The order to follow.</span>
<span class="sd">    """</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">idx</span><span class="o">.</span><span class="n">tousertensor</span><span class="p">()</span>
    <span class="n">order</span> <span class="o">=</span> <span class="n">order</span><span class="o">.</span><span class="n">tousertensor</span><span class="p">()</span>
    <span class="n">new_idx</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">gather_row</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="n">order</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">toindex</span><span class="p">(</span><span class="n">new_idx</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">is_iterable</span><span class="p">(</span><span class="n">obj</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Return true if the object is an iterable."""</span>
    <span class="k">return</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">to_dgl_context</span><span class="p">(</span><span class="n">ctx</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Convert a backend context to DGLContext"""</span>
    <span class="n">device_type</span> <span class="o">=</span> <span class="n">nd</span><span class="o">.</span><span class="n">DGLContext</span><span class="o">.</span><span class="n">STR2MASK</span><span class="p">[</span><span class="n">F</span><span class="o">.</span><span class="n">device_type</span><span class="p">(</span><span class="n">ctx</span><span class="p">)]</span>
    <span class="n">device_id</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">device_id</span><span class="p">(</span><span class="n">ctx</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">nd</span><span class="o">.</span><span class="n">DGLContext</span><span class="p">(</span><span class="n">device_type</span><span class="p">,</span> <span class="n">device_id</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">to_nbits_int</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">nbits</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Change the dtype of integer tensor</span>
<span class="sd">    The dtype of returned tensor uses nbits, nbits can only be 32 or 64</span>
<span class="sd">    """</span>
    <span class="k">assert</span> <span class="n">nbits</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span> <span class="s2">"nbits can either be 32 or 64"</span>
    <span class="k">if</span> <span class="n">nbits</span> <span class="o">==</span> <span class="mi">32</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">make_invmap</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">use_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Find the unique elements of the array and return another array with indices</span>
<span class="sd">    to the array of unique elements."""</span>
    <span class="k">if</span> <span class="n">use_numpy</span><span class="p">:</span>
        <span class="n">uniques</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">array</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">uniques</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">array</span><span class="p">))</span>
    <span class="n">invmap</span> <span class="o">=</span> <span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">uniques</span><span class="p">)}</span>
    <span class="n">remapped</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">invmap</span><span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">array</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">uniques</span><span class="p">,</span> <span class="n">invmap</span><span class="p">,</span> <span class="n">remapped</span>


<span class="k">def</span> <span class="nf">expand_as_pair</span><span class="p">(</span><span class="n">input_</span><span class="p">,</span> <span class="n">g</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Return a pair of same element if the input is not a pair.</span>

<span class="sd">    If the graph is a block, obtain the feature of destination nodes from the source nodes.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    input_ : Tensor, dict[str, Tensor], or their pairs</span>
<span class="sd">        The input features</span>
<span class="sd">    g : DGLGraph or None</span>
<span class="sd">        The graph.</span>

<span class="sd">        If None, skip checking if the graph is a block.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    tuple[Tensor, Tensor] or tuple[dict[str, Tensor], dict[str, Tensor]]</span>
<span class="sd">        The features for input and output nodes</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">input_</span>
    <span class="k">elif</span> <span class="n">g</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">g</span><span class="o">.</span><span class="n">is_block</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_</span><span class="p">,</span> <span class="n">Mapping</span><span class="p">):</span>
            <span class="n">input_dst</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">k</span><span class="p">:</span> <span class="n">F</span><span class="o">.</span><span class="n">narrow_row</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">number_of_dst_nodes</span><span class="p">(</span><span class="n">k</span><span class="p">))</span>
                <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">input_</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="p">}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">input_dst</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">narrow_row</span><span class="p">(</span><span class="n">input_</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">number_of_dst_nodes</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">input_</span><span class="p">,</span> <span class="n">input_dst</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">input_</span><span class="p">,</span> <span class="n">input_</span>


<span class="k">def</span> <span class="nf">check_eq_shape</span><span class="p">(</span><span class="n">input_</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""If input_ is a pair of features, check if the feature shape of source</span>
<span class="sd">    nodes is equal to the feature shape of destination nodes.</span>
<span class="sd">    """</span>
    <span class="n">srcdata</span><span class="p">,</span> <span class="n">dstdata</span> <span class="o">=</span> <span class="n">expand_as_pair</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span>
    <span class="n">src_feat_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">srcdata</span><span class="p">))[</span><span class="mi">1</span><span class="p">:]</span>
    <span class="n">dst_feat_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">dstdata</span><span class="p">))[</span><span class="mi">1</span><span class="p">:]</span>
    <span class="k">if</span> <span class="n">src_feat_shape</span> <span class="o">!=</span> <span class="n">dst_feat_shape</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
            <span class="s2">"The feature shape of source nodes: </span><span class="si">{}</span><span class="s2"> </span><span class="se">\</span>
<span class="s2">            should be equal to the feature shape of destination </span><span class="se">\</span>
<span class="s2">            nodes: </span><span class="si">{}</span><span class="s2">."</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">src_feat_shape</span><span class="p">,</span> <span class="n">dst_feat_shape</span>
            <span class="p">)</span>
        <span class="p">)</span>


<span class="k">def</span> <span class="nf">retry_method_with_fix</span><span class="p">(</span><span class="n">fix_method</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Decorator that executes a fix method before retrying again when the decorated method</span>
<span class="sd">    fails once with any exception.</span>

<span class="sd">    If the decorated method fails again, the execution fails with that exception.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    This decorator only works on class methods, and the fix function must also be a class method.</span>
<span class="sd">    It would not work on functions.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    fix_func : callable</span>
<span class="sd">        The fix method to execute.  It should not accept any arguments.  Its return values are</span>
<span class="sd">        ignored.</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="nf">_creator</span><span class="p">(</span><span class="n">func</span><span class="p">):</span>
        <span class="nd">@wraps</span><span class="p">(</span><span class="n">func</span><span class="p">)</span>
        <span class="k">def</span> <span class="nf">wrapper</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
            <span class="c1"># pylint: disable=W0703,bare-except</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">func</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="k">except</span><span class="p">:</span>
                <span class="n">fix_method</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
                <span class="k">return</span> <span class="n">func</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">wrapper</span>

    <span class="k">return</span> <span class="n">_creator</span>


<span class="k">def</span> <span class="nf">group_as_dict</span><span class="p">(</span><span class="n">pairs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Combines a list of key-value pairs to a dictionary of keys and value lists.</span>

<span class="sd">    Does not require the pairs to be sorted by keys.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    pairs : iterable</span>
<span class="sd">        Iterable of key-value pairs</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    dict</span>
<span class="sd">        The dictionary of keys and value lists.</span>
<span class="sd">    """</span>
    <span class="n">dic</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">pairs</span><span class="p">:</span>
        <span class="n">dic</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">dic</span>


<span class="k">class</span> <span class="nc">FlattenedDict</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Iterates over each item in a dictionary of groups.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    groups : dict</span>
<span class="sd">        The item groups.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; groups = FlattenedDict({'a': [1, 3], 'b': [2, 5, 8], 'c': [7]})</span>
<span class="sd">    &gt;&gt;&gt; list(groups)</span>
<span class="sd">    [('a', 1), ('a', 3), ('b', 2), ('b', 5), ('b', 8), ('c', 7)]</span>
<span class="sd">    &gt;&gt;&gt; groups[2]</span>
<span class="sd">    ('b', 2)</span>
<span class="sd">    &gt;&gt;&gt; len(groups)</span>
<span class="sd">    6</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">groups</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_groups</span> <span class="o">=</span> <span class="n">groups</span>
        <span class="n">group_sizes</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">groups</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_group_keys</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_group_sizes</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">group_sizes</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_group_offsets</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_group_sizes</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="c1"># TODO: this is faster (37s -&gt; 21s per epoch compared to searchsorted in GCMC) but takes</span>
        <span class="c1"># O(E) memory.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_idx_to_group</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_group_offsets</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">"int32"</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_groups</span><span class="p">)):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_idx_to_group</span><span class="p">[</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_group_offsets</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_group_offsets</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
            <span class="p">]</span> <span class="o">=</span> <span class="n">i</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""Return the total number of items."""</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_group_offsets</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""Return the iterator of all items with the key of its original group."""</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_group_keys</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_group_sizes</span><span class="p">[</span><span class="n">i</span><span class="p">]):</span>
                <span class="k">yield</span> <span class="n">k</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_groups</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="n">j</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""Return the item at the given position with the key of its original group."""</span>
        <span class="n">i</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_idx_to_group</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_group_keys</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">j</span> <span class="o">=</span> <span class="n">idx</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_group_offsets</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">g</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_groups</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">k</span><span class="p">,</span> <span class="n">g</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">maybe_flatten_dict</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Return a FlattenedDict if the input is a Mapping, or the data itself otherwise."""</span>
    <span class="k">return</span> <span class="n">FlattenedDict</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">Mapping</span><span class="p">)</span> <span class="k">else</span> <span class="n">data</span>


<span class="k">def</span> <span class="nf">compensate</span><span class="p">(</span><span class="n">ids</span><span class="p">,</span> <span class="n">origin_ids</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""computing the compensate set of ids from origin_ids</span>

<span class="sd">    Note: ids should be a subset of origin_ids.</span>
<span class="sd">    Any of ids and origin_ids can be non-consecutive,</span>
<span class="sd">    and origin_ids should be sorted.</span>

<span class="sd">    Example:</span>
<span class="sd">    &gt;&gt;&gt; ids = th.Tensor([0, 2, 4])</span>
<span class="sd">    &gt;&gt;&gt; origin_ids = th.Tensor([0, 1, 2, 4, 5])</span>
<span class="sd">    &gt;&gt;&gt; compensate(ids, origin_ids)</span>
<span class="sd">    th.Tensor([1, 5])</span>
<span class="sd">    """</span>
    <span class="c1"># trick here, eid_0 or nid_0 can be 0.</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">scatter_row</span><span class="p">(</span>
        <span class="n">origin_ids</span><span class="p">,</span>
        <span class="n">F</span><span class="o">.</span><span class="n">copy_to</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">F</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">F</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">origin_ids</span><span class="p">)),</span>
        <span class="n">F</span><span class="o">.</span><span class="n">copy_to</span><span class="p">(</span>
            <span class="n">F</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">F</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">origin_ids</span><span class="p">)),</span> <span class="n">F</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">origin_ids</span><span class="p">)</span>
        <span class="p">),</span>
    <span class="p">)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">scatter_row</span><span class="p">(</span>
        <span class="n">mask</span><span class="p">,</span> <span class="n">ids</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">full_1d</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ids</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">ids</span><span class="p">),</span> <span class="n">F</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">ids</span><span class="p">))</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">nonzero_1d</span><span class="p">(</span><span class="n">mask</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">F</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">ids</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">relabel</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Relabel the input ids to continuous ids that starts from zero.</span>

<span class="sd">    Ids are assigned new ids according to their ascending order.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; x = [1, 5, 3, 6]</span>
<span class="sd">    &gt;&gt;&gt; n2o, o2n = build_relabel_map(x)</span>
<span class="sd">    &gt;&gt;&gt; n2o</span>
<span class="sd">    [1, 3, 5, 6]</span>
<span class="sd">    &gt;&gt;&gt; o2n</span>
<span class="sd">    [n/a, 0, n/a, 1, n/a, 2, 3]</span>

<span class="sd">    "n/a" will be filled with 0</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x : Tensor</span>
<span class="sd">        ID tensor.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    new_to_old : Tensor</span>
<span class="sd">        The mapping from new id to old id.</span>
<span class="sd">    old_to_new : Tensor</span>
<span class="sd">        The mapping from old id to new id. It is a vector of length MAX(x).</span>
<span class="sd">        One can use advanced indexing to convert an old id tensor to a</span>
<span class="sd">        new id tensor: new_id = old_to_new[old_id]</span>
<span class="sd">    """</span>
    <span class="n">unique_x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">map_len</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">as_scalar</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">unique_x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">ctx</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">old_to_new</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">map_len</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">)</span>
    <span class="n">old_to_new</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">scatter_row</span><span class="p">(</span>
        <span class="n">old_to_new</span><span class="p">,</span> <span class="n">unique_x</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">copy_to</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">unique_x</span><span class="p">),</span> <span class="n">dtype</span><span class="p">),</span> <span class="n">ctx</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">unique_x</span><span class="p">,</span> <span class="n">old_to_new</span>


<span class="k">def</span> <span class="nf">extract_node_subframes</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="n">nodes_or_device</span><span class="p">,</span> <span class="n">store_ids</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Extract node features of the given nodes from :attr:`graph`</span>
<span class="sd">    and return them in frames on the given device.</span>

<span class="sd">    Note that this function does not perform actual tensor memory copy but using `Frame.subframe`</span>
<span class="sd">    to get the features. If :attr:`nodes` is None, it performs a shallow copy of the</span>
<span class="sd">    original node frames that only copies the dictionary structure but not the tensor</span>
<span class="sd">    contents.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    graph : DGLGraph</span>
<span class="sd">        The graph to extract features from.</span>
<span class="sd">    nodes : list[Tensor] or device or None</span>
<span class="sd">        Node IDs or device.</span>
<span class="sd">        If a list, the list length must be equal to the number of node types</span>
<span class="sd">        in the graph.</span>
<span class="sd">        If None, the whole frame is shallow-copied.</span>
<span class="sd">    store_ids : bool</span>
<span class="sd">        If True, the returned frames will store :attr:`nodes` in the ``dgl.NID`` field</span>
<span class="sd">        unless it is None.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    list[Frame]</span>
<span class="sd">        Extracted node frames.</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="n">nodes_or_device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">node_frames</span> <span class="o">=</span> <span class="p">[</span><span class="n">nf</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">for</span> <span class="n">nf</span> <span class="ow">in</span> <span class="n">graph</span><span class="o">.</span><span class="n">_node_frames</span><span class="p">]</span>
    <span class="k">elif</span> <span class="n">is_listlike</span><span class="p">(</span><span class="n">nodes_or_device</span><span class="p">):</span>
        <span class="n">node_frames</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ind_nodes</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">nodes_or_device</span><span class="p">):</span>
            <span class="n">subf</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">_node_frames</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">subframe</span><span class="p">(</span><span class="n">ind_nodes</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">store_ids</span><span class="p">:</span>
                <span class="n">subf</span><span class="p">[</span><span class="n">NID</span><span class="p">]</span> <span class="o">=</span> <span class="n">ind_nodes</span>
            <span class="n">node_frames</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">subf</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>  <span class="c1"># device object</span>
        <span class="n">node_frames</span> <span class="o">=</span> <span class="p">[</span><span class="n">nf</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">nodes_or_device</span><span class="p">)</span> <span class="k">for</span> <span class="n">nf</span> <span class="ow">in</span> <span class="n">graph</span><span class="o">.</span><span class="n">_node_frames</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">node_frames</span>


<span class="k">def</span> <span class="nf">extract_node_subframes_for_block</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="n">srcnodes</span><span class="p">,</span> <span class="n">dstnodes</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Extract the input node features and output node features of the given nodes from</span>
<span class="sd">    :attr:`graph` and return them in frames ready for a block.</span>

<span class="sd">    Note that this function does not perform actual tensor memory copy but using `Frame.subframe`</span>
<span class="sd">    to get the features. If :attr:`srcnodes` or :attr:`dstnodes` is None, it performs a</span>
<span class="sd">    shallow copy of the original node frames that only copies the dictionary structure</span>
<span class="sd">    but not the tensor contents.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    graph : DGLGraph</span>
<span class="sd">        The graph to extract features from.</span>
<span class="sd">    srcnodes : list[Tensor]</span>
<span class="sd">        Input node IDs. The list length must be equal to the number of node types</span>
<span class="sd">        in the graph. The returned frames store the node IDs in the ``dgl.NID`` field.</span>
<span class="sd">    dstnodes : list[Tensor]</span>
<span class="sd">        Output node IDs. The list length must be equal to the number of node types</span>
<span class="sd">        in the graph. The returned frames store the node IDs in the ``dgl.NID`` field.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    list[Frame]</span>
<span class="sd">        Extracted node frames.</span>
<span class="sd">    """</span>
    <span class="n">node_frames</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ind_nodes</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">srcnodes</span><span class="p">):</span>
        <span class="n">subf</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">_node_frames</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">subframe</span><span class="p">(</span><span class="n">ind_nodes</span><span class="p">)</span>
        <span class="n">subf</span><span class="p">[</span><span class="n">NID</span><span class="p">]</span> <span class="o">=</span> <span class="n">ind_nodes</span>
        <span class="n">node_frames</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">subf</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ind_nodes</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dstnodes</span><span class="p">):</span>
        <span class="n">subf</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">_node_frames</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">subframe</span><span class="p">(</span><span class="n">ind_nodes</span><span class="p">)</span>
        <span class="n">subf</span><span class="p">[</span><span class="n">NID</span><span class="p">]</span> <span class="o">=</span> <span class="n">ind_nodes</span>
        <span class="n">node_frames</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">subf</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">node_frames</span>


<span class="k">def</span> <span class="nf">extract_edge_subframes</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="n">edges_or_device</span><span class="p">,</span> <span class="n">store_ids</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Extract edge features of the given edges from :attr:`graph`</span>
<span class="sd">    and return them in frames.</span>

<span class="sd">    Note that this function does not perform actual tensor memory copy but using `Frame.subframe`</span>
<span class="sd">    to get the features. If :attr:`edges` is None, it performs a shallow copy of the</span>
<span class="sd">    original edge frames that only copies the dictionary structure but not the tensor</span>
<span class="sd">    contents.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    graph : DGLGraph</span>
<span class="sd">        The graph to extract features from.</span>
<span class="sd">    edges_or_device : list[Tensor] or device or None</span>
<span class="sd">        Edge IDs.</span>
<span class="sd">        If a list, the list length must be equal to the number of edge types</span>
<span class="sd">        in the graph.</span>
<span class="sd">        If None, the whole frame is shallow-copied.</span>
<span class="sd">    store_ids : bool</span>
<span class="sd">        If True, the returned frames will store :attr:`edges` in the ``dgl.EID`` field</span>
<span class="sd">        unless it is None.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    list[Frame]</span>
<span class="sd">        Extracted edge frames.</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="n">edges_or_device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">edge_frames</span> <span class="o">=</span> <span class="p">[</span><span class="n">nf</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">for</span> <span class="n">nf</span> <span class="ow">in</span> <span class="n">graph</span><span class="o">.</span><span class="n">_edge_frames</span><span class="p">]</span>
    <span class="k">elif</span> <span class="n">is_listlike</span><span class="p">(</span><span class="n">edges_or_device</span><span class="p">):</span>
        <span class="n">edge_frames</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ind_edges</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">edges_or_device</span><span class="p">):</span>
            <span class="n">subf</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">_edge_frames</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">subframe</span><span class="p">(</span><span class="n">ind_edges</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">store_ids</span><span class="p">:</span>
                <span class="n">subf</span><span class="p">[</span><span class="n">EID</span><span class="p">]</span> <span class="o">=</span> <span class="n">ind_edges</span>
            <span class="n">edge_frames</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">subf</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>  <span class="c1"># device object</span>
        <span class="n">edge_frames</span> <span class="o">=</span> <span class="p">[</span><span class="n">nf</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">edges_or_device</span><span class="p">)</span> <span class="k">for</span> <span class="n">nf</span> <span class="ow">in</span> <span class="n">graph</span><span class="o">.</span><span class="n">_edge_frames</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">edge_frames</span>


<span class="k">def</span> <span class="nf">set_new_frames</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">node_frames</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">edge_frames</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Set the node and edge frames of a given graph to new ones.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    graph : DGLGraph</span>
<span class="sd">        The graph whose node and edge frames are to be updated.</span>
<span class="sd">    node_frames : list[Frame], optional</span>
<span class="sd">        New node frames.</span>

<span class="sd">        Default is None, where the node frames are not updated.</span>
<span class="sd">    edge_frames : list[Frame], optional</span>
<span class="sd">        New edge frames</span>

<span class="sd">        Default is None, where the edge frames are not updated.</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="n">node_frames</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">node_frames</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span>
            <span class="n">graph</span><span class="o">.</span><span class="n">ntypes</span>
        <span class="p">),</span> <span class="s2">"[BUG] number of node frames different from number of node types"</span>
        <span class="n">graph</span><span class="o">.</span><span class="n">_node_frames</span> <span class="o">=</span> <span class="n">node_frames</span>
    <span class="k">if</span> <span class="n">edge_frames</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">edge_frames</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span>
            <span class="n">graph</span><span class="o">.</span><span class="n">etypes</span>
        <span class="p">),</span> <span class="s2">"[BUG] number of edge frames different from number of edge types"</span>
        <span class="n">graph</span><span class="o">.</span><span class="n">_edge_frames</span> <span class="o">=</span> <span class="n">edge_frames</span>


<span class="k">def</span> <span class="nf">set_num_threads</span><span class="p">(</span><span class="n">num_threads</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Set the number of OMP threads in the process.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    num_threads : int</span>
<span class="sd">        The number of OMP threads in the process.</span>
<span class="sd">    """</span>
    <span class="n">_CAPI_DGLSetOMPThreads</span><span class="p">(</span><span class="n">num_threads</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">get_num_threads</span><span class="p">():</span>
<span class="w">    </span><span class="sd">"""Get the number of OMP threads in the process"""</span>
    <span class="k">return</span> <span class="n">_CAPI_DGLGetOMPThreads</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">get_numa_nodes_cores</span><span class="p">():</span>
<span class="w">    </span><span class="sd">"""Returns numa nodes info, format:</span>
<span class="sd">    {&lt;node_id&gt;: [(&lt;core_id&gt;, [&lt;sibling_thread_id_0&gt;, &lt;sibling_thread_id_1&gt;, ...]), ...], ...}</span>
<span class="sd">    E.g.: {0: [(0, [0, 4]), (1, [1, 5])], 1: [(2, [2, 6]), (3, [3, 7])]}</span>

<span class="sd">    If not available, returns {}</span>
<span class="sd">    """</span>
    <span class="n">numa_node_paths</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s2">"/sys/devices/system/node/node[0-9]*"</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">numa_node_paths</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">{}</span>

    <span class="n">nodes</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">node_path</span> <span class="ow">in</span> <span class="n">numa_node_paths</span><span class="p">:</span>
            <span class="n">numa_node_id</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">node_path</span><span class="p">)[</span><span class="mi">4</span><span class="p">:])</span>

            <span class="n">thread_siblings</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">cpu_dir</span> <span class="ow">in</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">node_path</span><span class="p">,</span> <span class="s2">"cpu[0-9]*"</span><span class="p">)):</span>
                <span class="n">cpu_id</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">cpu_dir</span><span class="p">)[</span><span class="mi">3</span><span class="p">:])</span>

                <span class="k">with</span> <span class="nb">open</span><span class="p">(</span>
                    <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">cpu_dir</span><span class="p">,</span> <span class="s2">"topology"</span><span class="p">,</span> <span class="s2">"core_id"</span><span class="p">)</span>
                <span class="p">)</span> <span class="k">as</span> <span class="n">core_id_file</span><span class="p">:</span>
                    <span class="n">core_id</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">core_id_file</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>
                    <span class="k">if</span> <span class="n">core_id</span> <span class="ow">in</span> <span class="n">thread_siblings</span><span class="p">:</span>
                        <span class="n">thread_siblings</span><span class="p">[</span><span class="n">core_id</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cpu_id</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">thread_siblings</span><span class="p">[</span><span class="n">core_id</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">cpu_id</span><span class="p">]</span>

            <span class="n">nodes</span><span class="p">[</span><span class="n">numa_node_id</span><span class="p">]</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span>
                <span class="p">[(</span><span class="n">k</span><span class="p">,</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">v</span><span class="p">))</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">thread_siblings</span><span class="o">.</span><span class="n">items</span><span class="p">()]</span>
            <span class="p">)</span>

    <span class="k">except</span> <span class="p">(</span><span class="ne">OSError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">,</span> <span class="ne">IndexError</span><span class="p">,</span> <span class="ne">IOError</span><span class="p">):</span>
        <span class="n">dgl_warning</span><span class="p">(</span><span class="s2">"Failed to read NUMA info"</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">{}</span>

    <span class="k">return</span> <span class="n">nodes</span>


<span class="k">def</span> <span class="nf">alias_func</span><span class="p">(</span><span class="n">func</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Return an alias function with proper docstring."""</span>

    <span class="nd">@wraps</span><span class="p">(</span><span class="n">func</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">_fn</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="n">_fn</span><span class="o">.</span><span class="vm">__doc__</span> <span class="o">=</span> <span class="s2">"""Alias of :func:`dgl.</span><span class="si">{}</span><span class="s2">`."""</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">func</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">_fn</span>


<div class="viewcode-block" id="apply_each">
<a class="viewcode-back" href="../../../generated/dgl.apply_each.html#dgl.apply_each">[docs]</a>
<span class="k">def</span> <span class="nf">apply_each</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Apply a function to every element in a container.</span>

<span class="sd">    If the input data is a list or any sequence other than a string, returns a list</span>
<span class="sd">    whose elements are the same elements applied with the given function.</span>

<span class="sd">    If the input data is a dict or any mapping, returns a dict whose keys are the same</span>
<span class="sd">    and values are the elements applied with the given function.</span>

<span class="sd">    The first argument of the function will be passed with the individual elements from</span>
<span class="sd">    the input data, followed by the arguments in :attr:`args` and :attr:`kwargs`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : any</span>
<span class="sd">        Any object.</span>
<span class="sd">    fn : callable</span>
<span class="sd">        Any function.</span>
<span class="sd">    args, kwargs :</span>
<span class="sd">        Additional arguments and keyword-arguments passed to the function.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    Applying a ReLU function to a dictionary of tensors:</span>

<span class="sd">    &gt;&gt;&gt; h = {k: torch.randn(3) for k in ['A', 'B', 'C']}</span>
<span class="sd">    &gt;&gt;&gt; h = apply_each(h, torch.nn.functional.relu)</span>
<span class="sd">    &gt;&gt;&gt; assert all((v &gt;= 0).all() for v in h.values())</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">Mapping</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">fn</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
    <span class="k">elif</span> <span class="n">is_listlike</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">fn</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">data</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">fn</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>



<span class="k">def</span> <span class="nf">recursive_apply</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Recursively apply a function to every element in a container.</span>

<span class="sd">    If the input data is a list or any sequence other than a string, returns a list</span>
<span class="sd">    whose elements are the same elements applied with the given function.</span>

<span class="sd">    If the input data is a dict or any mapping, returns a dict whose keys are the same</span>
<span class="sd">    and values are the elements applied with the given function.</span>

<span class="sd">    If the input data is a nested container, the result will have the same nested</span>
<span class="sd">    structure where each element is transformed recursively.</span>

<span class="sd">    The first argument of the function will be passed with the individual elements from</span>
<span class="sd">    the input data, followed by the arguments in :attr:`args` and :attr:`kwargs`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : any</span>
<span class="sd">        Any object.</span>
<span class="sd">    fn : callable</span>
<span class="sd">        Any function.</span>
<span class="sd">    args, kwargs :</span>
<span class="sd">        Additional arguments and keyword-arguments passed to the function.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    Applying a ReLU function to a dictionary of tensors:</span>

<span class="sd">    &gt;&gt;&gt; h = {k: torch.randn(3) for k in ['A', 'B', 'C']}</span>
<span class="sd">    &gt;&gt;&gt; h = recursive_apply(h, torch.nn.functional.relu)</span>
<span class="sd">    &gt;&gt;&gt; assert all((v &gt;= 0).all() for v in h.values())</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">Mapping</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="n">k</span><span class="p">:</span> <span class="n">recursive_apply</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
        <span class="p">}</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">recursive_apply</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">data</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">is_listlike</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">recursive_apply</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">data</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">fn</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">recursive_apply_pair</span><span class="p">(</span><span class="n">data1</span><span class="p">,</span> <span class="n">data2</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Recursively apply a function to every pair of elements in two containers with the</span>
<span class="sd">    same nested structure.</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data1</span><span class="p">,</span> <span class="n">Mapping</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data2</span><span class="p">,</span> <span class="n">Mapping</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="n">k</span><span class="p">:</span> <span class="n">recursive_apply_pair</span><span class="p">(</span><span class="n">data1</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">data2</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">data1</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
        <span class="p">}</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data1</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data2</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span>
            <span class="n">recursive_apply_pair</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">data1</span><span class="p">,</span> <span class="n">data2</span><span class="p">)</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="n">is_listlike</span><span class="p">(</span><span class="n">data1</span><span class="p">)</span> <span class="ow">and</span> <span class="n">is_listlike</span><span class="p">(</span><span class="n">data2</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span>
            <span class="n">recursive_apply_pair</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">data1</span><span class="p">,</span> <span class="n">data2</span><span class="p">)</span>
        <span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">fn</span><span class="p">(</span><span class="n">data1</span><span class="p">,</span> <span class="n">data2</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">context_of</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Return the device of the data which can be either a tensor or a list/dict of tensors."""</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">Mapping</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">values</span><span class="p">())))</span>
    <span class="k">elif</span> <span class="n">is_listlike</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">data</span><span class="p">)))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">dtype_of</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Return the dtype of the data which can be either a tensor or a dict of tensors."""</span>
    <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span>
        <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">Mapping</span><span class="p">)</span> <span class="k">else</span> <span class="n">data</span>
    <span class="p">)</span>


<span class="n">_init_api</span><span class="p">(</span><span class="s2">"dgl.utils.internal"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<footer>
<hr/>
<div role="contentinfo">
<p>© Copyright 2018, DGL Team.</p>
</div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
</div>
</div>
</section>
</div>
<div aria-label="Versions" class="rst-versions" data-toggle="rst-versions" role="note">
<span class="rst-current-version" data-toggle="rst-current-version">
<span class="fa fa-book"> Read the Docs</span>
<span id="version-placeholder">v: latest</span>
<span class="fa fa-caret-down"></span>
</span>
<div class="rst-other-versions">
<dl>
<dt>Versions</dt>
<div id="version-list">
<!-- 动态插入的版本列表将出现在这里 -->
</div>
</dl>
<dl>
<dt>Downloads</dt>
<!-- 下载内容 -->
</dl>
<dl>
<dt>On Read the Docs</dt>
<dd><a href="//doc-build.dgl.ai/projects/dgl/?fromdocs=dgl">Project Home</a></dd>
<dd><a href="//doc-build.dgl.ai/builds/dgl/?fromdocs=dgl">Builds</a></dd>
</dl>
</div>
</div>
<script>
        document.addEventListener("DOMContentLoaded", function() {
            fetch('/dgl_docs/branches.json')
                .then(response => response.json())
                .then(data => {
                    var versionListDiv = document.getElementById('version-list');
                    data.branches.forEach(function(branch) {
                        var dd = document.createElement('dd');
                        var a = document.createElement('a');
                        a.href = branch.url;
                        a.textContent = branch.name;
                        dd.appendChild(a);
                        versionListDiv.appendChild(dd);
                    });
                })
                .catch(error => console.error('Error loading branches:', error));
        });
        document.addEventListener("DOMContentLoaded", function() {
            // 获取当前路径
            var path = window.location.pathname;
            var versionPlaceholder = document.getElementById('version-placeholder');

            // 检查路径中是否包含 'en'
            if (path.includes('/en/')) {
                // 提取 'en' 后的文件夹作为版本号
                var parts = path.split('/en/');
                if (parts[1]) {
                    var folders = parts[1].split('/');
                    if (folders.length > 0 && folders[0]) {
                        versionPlaceholder.textContent = 'v: ' + folders[0];
                    } else {
                        versionPlaceholder.textContent = 'v: latest';
                    }
                } else {
                    versionPlaceholder.textContent = 'v: latest';
                }
            } else {
                versionPlaceholder.textContent = 'v: latest';
            }
        });
    </script>

<script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
</body>
</html>