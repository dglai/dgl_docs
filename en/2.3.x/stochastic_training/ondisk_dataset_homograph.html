<!DOCTYPE html>

<html class="writer-html5" data-content_root="../" lang="en">
<head>
<meta charset="utf-8"/><meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>OnDiskDataset for Homogeneous Graph — DGL 2.3.1 documentation</title>
<link href="../_static/pygments.css?v=80d5e7a1" rel="stylesheet" type="text/css"/>
<link href="../_static/css/theme.css?v=19f00094" rel="stylesheet" type="text/css"/>
<link href="../_static/graphviz.css?v=fd3f3429" rel="stylesheet" type="text/css"/>
<link href="../_static/copybutton.css?v=76b2166b" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery.css?v=d2d258e8" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery-binder.css?v=f4aeca0c" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery-dataframe.css?v=2082cf3c" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" rel="stylesheet" type="text/css"/>
<link href="../_static/nbsphinx-code-cells.css?v=2aa19091" rel="stylesheet" type="text/css"/>
<link href="../_static/css/custom.css?v=0bf289b5" rel="stylesheet" type="text/css"/>
<!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
<script src="../_static/jquery.js?v=5d32c60e"></script>
<script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
<script src="../_static/documentation_options.js?v=67b02a41"></script>
<script src="../_static/doctools.js?v=9a2dae69"></script>
<script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
<script src="../_static/clipboard.min.js?v=a7894cd8"></script>
<script src="../_static/copybutton.js?v=ccdb6887"></script>
<script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
<script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
<script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script src="../_static/js/theme.js"></script>
<link href="../genindex.html" rel="index" title="Index"/>
<link href="../search.html" rel="search" title="Search"/>
<link href="ondisk_dataset_heterograph.html" rel="next" title="OnDiskDataset for Heterogeneous Graph"/>
<link href="ondisk-dataset.html" rel="prev" title="Composing OnDiskDataset from raw data"/>
</head>
<body class="wy-body-for-nav">
<div class="wy-grid-for-nav">
<nav class="wy-nav-side" data-toggle="wy-nav-shift">
<div class="wy-side-scroll">
<div class="wy-side-nav-search">
<a class="icon icon-home" href="../index.html">
            DGL
          </a>
<div class="version">
                2.3.1
              </div>
<div role="search">
<form action="../search.html" class="wy-form" id="rtd-search-form" method="get">
<input aria-label="Search docs" name="q" placeholder="Search docs" type="text"/>
<input name="check_keywords" type="hidden" value="yes"/>
<input name="area" type="hidden" value="default"/>
</form>
</div>
</div><div aria-label="Navigation menu" class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation">
<p class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../install/index.html">Install and Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/blitz/index.html">A Blitz Introduction to DGL</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Materials</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">🆕 Stochastic Training of GNNs with GraphBolt</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="neighbor_sampling_overview.html">Neighbor Sampling Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="node_classification.html">Node Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="link_prediction.html">Link Prediction</a></li>
<li class="toctree-l2"><a class="reference internal" href="multigpu_node_classification.html">Multi-GPU Node Classification</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="ondisk-dataset.html">Composing OnDiskDataset from raw data</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">OnDiskDataset for Homogeneous Graph</a></li>
<li class="toctree-l3"><a class="reference internal" href="ondisk_dataset_heterograph.html">OnDiskDataset for Heterogeneous Graph</a></li>
<li class="toctree-l3"><a class="reference internal" href="ondisk-dataset-specification.html">YAML specification</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../guide/index.html">User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guide_cn/index.html">用户指南【包含过时信息】</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guide_ko/index.html">사용자 가이드[시대에 뒤쳐진]</a></li>
<li class="toctree-l1"><a class="reference internal" href="../graphtransformer/index.html">🆕 Tutorial: Graph Transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebooks/sparse/index.html">Tutorials: dgl.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/cpu/index.html">Training on CPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/multi/index.html">Training on Multiple GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/dist/index.html">Distributed training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/models/index.html">Paper Study with DGL</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.html">dgl</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.data.html">dgl.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.dataloading.html">dgl.dataloading</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.DGLGraph.html">dgl.DGLGraph</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.distributed.html">dgl.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.function.html">dgl.function</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.geometry.html">dgl.geometry</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.graphbolt.html">🆕 dgl.graphbolt</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/nn-pytorch.html">dgl.nn (PyTorch)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/nn.functional.html">dgl.nn.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.ops.html">dgl.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.optim.html">dgl.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.sampling.html">dgl.sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.sparse_v0.html">dgl.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.multiprocessing.html">dgl.multiprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/transforms.html">dgl.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/udf.html">User-defined Functions</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../contribute.html">Contribute to DGL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../developer/ffi.html">DGL Foreign Function Interface (FFI)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../performance.html">Performance Benchmarks</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Misc</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">Frequently Asked Questions (FAQ)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../env_var.html">Environment Variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="../resources.html">Resources</a></li>
</ul>
</div>
</div>
</nav>
<section class="wy-nav-content-wrap" data-toggle="wy-nav-shift"><nav aria-label="Mobile navigation menu" class="wy-nav-top">
<i class="fa fa-bars" data-toggle="wy-nav-top"></i>
<a href="../index.html">DGL</a>
</nav>
<div class="wy-nav-content">
<div class="rst-content">
<div aria-label="Page navigation" role="navigation">
<ul class="wy-breadcrumbs">
<li><a aria-label="Home" class="icon icon-home" href="../index.html"></a></li>
<li class="breadcrumb-item"><a href="index.html">🆕 Stochastic Training of GNNs with GraphBolt</a></li>
<li class="breadcrumb-item"><a href="ondisk-dataset.html">Composing OnDiskDataset from raw data</a></li>
<li class="breadcrumb-item active">OnDiskDataset for Homogeneous Graph</li>
<li class="wy-breadcrumbs-aside">
<a href="../_sources/stochastic_training/ondisk_dataset_homograph.nblink.txt" rel="nofollow"> View page source</a>
</li>
</ul>
<hr/>
</div>
<div class="document" itemscope="itemscope" itemtype="http://schema.org/Article" role="main">
<div itemprop="articleBody">
<section id="OnDiskDataset-for-Homogeneous-Graph">
<h1>OnDiskDataset for Homogeneous Graph<a class="headerlink" href="#OnDiskDataset-for-Homogeneous-Graph" title="Link to this heading"></a></h1>
<p><a class="reference external" href="https://colab.research.google.com/github/dmlc/dgl/blob/master/notebooks/stochastic_training/ondisk_dataset_homograph.ipynb"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"/></a> <a class="reference external" href="https://github.com/dmlc/dgl/blob/master/notebooks/stochastic_training/ondisk_dataset_homograph.ipynb"><img alt="GitHub" src="https://img.shields.io/badge/-View%20on%20GitHub-181717?logo=github&amp;logoColor=ffffff"/></a></p>
<p>This tutorial shows how to create <code class="docutils literal notranslate"><span class="pre">OnDiskDataset</span></code> for homogeneous graph that could be used in <strong>GraphBolt</strong> framework.</p>
<p>By the end of this tutorial, you will be able to</p>
<ul class="simple">
<li><p>organize graph structure data.</p></li>
<li><p>organize feature data.</p></li>
<li><p>organize training/validation/test set for specific tasks.</p></li>
</ul>
<p>To create an <code class="docutils literal notranslate"><span class="pre">OnDiskDataset</span></code> object, you need to organize all the data including graph structure, feature data and tasks into a directory. The directory should contain a <code class="docutils literal notranslate"><span class="pre">metadata.yaml</span></code> file that describes the metadata of the dataset.</p>
<p>Now let’s generate various data step by step and organize them together to instantiate <code class="docutils literal notranslate"><span class="pre">OnDiskDataset</span></code> finally.</p>
<section id="Install-DGL-package">
<h2>Install DGL package<a class="headerlink" href="#Install-DGL-package" title="Link to this heading"></a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Install required packages.</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">'TORCH'</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">__version__</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">'DGLBACKEND'</span><span class="p">]</span> <span class="o">=</span> <span class="s2">"pytorch"</span>

<span class="c1"># Install the CPU version.</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cpu"</span><span class="p">)</span>
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>--pre<span class="w"> </span>dgl<span class="w"> </span>-f<span class="w"> </span>https://data.dgl.ai/wheels-test/repo.html

<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">dgl</span>
    <span class="kn">import</span> <span class="nn">dgl.graphbolt</span> <span class="k">as</span> <span class="nn">gb</span>
    <span class="n">installed</span> <span class="o">=</span> <span class="kc">True</span>
<span class="k">except</span> <span class="ne">ImportError</span> <span class="k">as</span> <span class="n">error</span><span class="p">:</span>
    <span class="n">installed</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">error</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"DGL installed!"</span> <span class="k">if</span> <span class="n">installed</span> <span class="k">else</span> <span class="s2">"DGL not found!"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Looking in links: https://data.dgl.ai/wheels-test/repo.html
Requirement already satisfied: dgl in /opt/conda/envs/dgl-dev-cpu/lib/python3.10/site-packages (2.2a240410)
Requirement already satisfied: numpy&gt;=1.14.0 in /opt/conda/envs/dgl-dev-cpu/lib/python3.10/site-packages (from dgl) (1.26.4)
Requirement already satisfied: scipy&gt;=1.1.0 in /opt/conda/envs/dgl-dev-cpu/lib/python3.10/site-packages (from dgl) (1.14.0)
Requirement already satisfied: networkx&gt;=2.1 in /opt/conda/envs/dgl-dev-cpu/lib/python3.10/site-packages (from dgl) (3.3)
Requirement already satisfied: requests&gt;=2.19.0 in /opt/conda/envs/dgl-dev-cpu/lib/python3.10/site-packages (from dgl) (2.32.3)
Requirement already satisfied: tqdm in /opt/conda/envs/dgl-dev-cpu/lib/python3.10/site-packages (from dgl) (4.66.5)
Requirement already satisfied: psutil&gt;=5.8.0 in /opt/conda/envs/dgl-dev-cpu/lib/python3.10/site-packages (from dgl) (6.0.0)
Requirement already satisfied: torchdata&gt;=0.5.0 in /opt/conda/envs/dgl-dev-cpu/lib/python3.10/site-packages (from dgl) (0.7.1)
Requirement already satisfied: pandas in /opt/conda/envs/dgl-dev-cpu/lib/python3.10/site-packages (from dgl) (2.2.2)
Requirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /opt/conda/envs/dgl-dev-cpu/lib/python3.10/site-packages (from requests&gt;=2.19.0-&gt;dgl) (3.3.2)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /opt/conda/envs/dgl-dev-cpu/lib/python3.10/site-packages (from requests&gt;=2.19.0-&gt;dgl) (3.8)
Requirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /opt/conda/envs/dgl-dev-cpu/lib/python3.10/site-packages (from requests&gt;=2.19.0-&gt;dgl) (2.2.2)
Requirement already satisfied: certifi&gt;=2017.4.17 in /opt/conda/envs/dgl-dev-cpu/lib/python3.10/site-packages (from requests&gt;=2.19.0-&gt;dgl) (2024.7.4)
Requirement already satisfied: torch&gt;=2 in /opt/conda/envs/dgl-dev-cpu/lib/python3.10/site-packages (from torchdata&gt;=0.5.0-&gt;dgl) (2.4.0+cpu)
Requirement already satisfied: python-dateutil&gt;=2.8.2 in /opt/conda/envs/dgl-dev-cpu/lib/python3.10/site-packages (from pandas-&gt;dgl) (2.9.0.post0)
Requirement already satisfied: pytz&gt;=2020.1 in /opt/conda/envs/dgl-dev-cpu/lib/python3.10/site-packages (from pandas-&gt;dgl) (2024.1)
Requirement already satisfied: tzdata&gt;=2022.7 in /opt/conda/envs/dgl-dev-cpu/lib/python3.10/site-packages (from pandas-&gt;dgl) (2024.1)
Requirement already satisfied: six&gt;=1.5 in /opt/conda/envs/dgl-dev-cpu/lib/python3.10/site-packages (from python-dateutil&gt;=2.8.2-&gt;pandas-&gt;dgl) (1.16.0)
Requirement already satisfied: filelock in /opt/conda/envs/dgl-dev-cpu/lib/python3.10/site-packages (from torch&gt;=2-&gt;torchdata&gt;=0.5.0-&gt;dgl) (3.15.4)
Requirement already satisfied: typing-extensions&gt;=4.8.0 in /opt/conda/envs/dgl-dev-cpu/lib/python3.10/site-packages (from torch&gt;=2-&gt;torchdata&gt;=0.5.0-&gt;dgl) (4.12.2)
Requirement already satisfied: sympy in /opt/conda/envs/dgl-dev-cpu/lib/python3.10/site-packages (from torch&gt;=2-&gt;torchdata&gt;=0.5.0-&gt;dgl) (1.13.2)
Requirement already satisfied: jinja2 in /opt/conda/envs/dgl-dev-cpu/lib/python3.10/site-packages (from torch&gt;=2-&gt;torchdata&gt;=0.5.0-&gt;dgl) (3.1.4)
Requirement already satisfied: fsspec in /opt/conda/envs/dgl-dev-cpu/lib/python3.10/site-packages (from torch&gt;=2-&gt;torchdata&gt;=0.5.0-&gt;dgl) (2024.6.1)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /opt/conda/envs/dgl-dev-cpu/lib/python3.10/site-packages (from jinja2-&gt;torch&gt;=2-&gt;torchdata&gt;=0.5.0-&gt;dgl) (2.1.5)
Requirement already satisfied: mpmath&lt;1.4,&gt;=1.1.0 in /opt/conda/envs/dgl-dev-cpu/lib/python3.10/site-packages (from sympy-&gt;torch&gt;=2-&gt;torchdata&gt;=0.5.0-&gt;dgl) (1.3.0)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/home/ubuntu/regression_test/dgl/python/dgl/graphbolt/base.py:82: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
  @torch.library.impl_abstract("graphbolt::expand_indptr")
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
DGL installed!
</pre></div></div>
</div>
</section>
<section id="Data-preparation">
<h2>Data preparation<a class="headerlink" href="#Data-preparation" title="Link to this heading"></a></h2>
<p>In order to demonstrate how to organize various data, let’s create a base directory first.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">base_dir</span> <span class="o">=</span> <span class="s1">'./ondisk_dataset_homograph'</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Created base directory: </span><span class="si">{</span><span class="n">base_dir</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Created base directory: ./ondisk_dataset_homograph
</pre></div></div>
</div>
<section id="Generate-graph-structure-data">
<h3>Generate graph structure data<a class="headerlink" href="#Generate-graph-structure-data" title="Link to this heading"></a></h3>
<p>For homogeneous graph, we just need to save edges(namely seeds) into <strong>Numpy</strong> or <strong>CSV</strong> file.</p>
<p>Note: - when saving to <strong>Numpy</strong>, the array requires to be in shape of <code class="docutils literal notranslate"><span class="pre">(2,</span> <span class="pre">N)</span></code>. This format is recommended as constructing graph from it is much faster than <strong>CSV</strong> file. - when saving to <strong>CSV</strong> file, do not save index and header.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">num_nodes</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">num_edges</span> <span class="o">=</span> <span class="mi">10</span> <span class="o">*</span> <span class="n">num_nodes</span>
<span class="n">edges_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s2">"edges.csv"</span><span class="p">)</span>
<span class="n">edges</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_nodes</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">num_edges</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Part of edges: </span><span class="si">{</span><span class="n">edges</span><span class="p">[:</span><span class="mi">5</span><span class="p">,</span><span class="w"> </span><span class="p">:]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">edges</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">edges_path</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Edges are saved into </span><span class="si">{</span><span class="n">edges_path</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Part of edges: [[427 810]
 [482 156]
 [739 383]
 [515 361]
 [823 253]]
Edges are saved into ./ondisk_dataset_homograph/edges.csv
</pre></div></div>
</div>
</section>
<section id="Generate-feature-data-for-graph">
<h3>Generate feature data for graph<a class="headerlink" href="#Generate-feature-data-for-graph" title="Link to this heading"></a></h3>
<p>For feature data, numpy arrays and torch tensors are supported for now.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generate node feature in numpy array.</span>
<span class="n">node_feat_0_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s2">"node-feat-0.npy"</span><span class="p">)</span>
<span class="n">node_feat_0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">num_nodes</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Part of node feature [feat_0]: </span><span class="si">{</span><span class="n">node_feat_0</span><span class="p">[:</span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="p">:]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">node_feat_0_path</span><span class="p">,</span> <span class="n">node_feat_0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Node feature [feat_0] is saved to </span><span class="si">{</span><span class="n">node_feat_0_path</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Generate another node feature in torch tensor</span>
<span class="n">node_feat_1_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s2">"node-feat-1.pt"</span><span class="p">)</span>
<span class="n">node_feat_1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">num_nodes</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Part of node feature [feat_1]: </span><span class="si">{</span><span class="n">node_feat_1</span><span class="p">[:</span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="p">:]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">node_feat_1</span><span class="p">,</span> <span class="n">node_feat_1_path</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Node feature [feat_1] is saved to </span><span class="si">{</span><span class="n">node_feat_1_path</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Generate edge feature in numpy array.</span>
<span class="n">edge_feat_0_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s2">"edge-feat-0.npy"</span><span class="p">)</span>
<span class="n">edge_feat_0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">num_edges</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Part of edge feature [feat_0]: </span><span class="si">{</span><span class="n">edge_feat_0</span><span class="p">[:</span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="p">:]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">edge_feat_0_path</span><span class="p">,</span> <span class="n">edge_feat_0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Edge feature [feat_0] is saved to </span><span class="si">{</span><span class="n">edge_feat_0_path</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Generate another edge feature in torch tensor</span>
<span class="n">edge_feat_1_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s2">"edge-feat-1.pt"</span><span class="p">)</span>
<span class="n">edge_feat_1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">num_edges</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Part of edge feature [feat_1]: </span><span class="si">{</span><span class="n">edge_feat_1</span><span class="p">[:</span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="p">:]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">edge_feat_1</span><span class="p">,</span> <span class="n">edge_feat_1_path</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Edge feature [feat_1] is saved to </span><span class="si">{</span><span class="n">edge_feat_1_path</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<br/></pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Part of node feature [feat_0]: [[0.18756113 0.8263093  0.69531218 0.77329349 0.25144377]
 [0.81287002 0.46255598 0.28790539 0.39118476 0.70067461]
 [0.07416777 0.87980422 0.81736906 0.65193808 0.94687969]]
Node feature [feat_0] is saved to ./ondisk_dataset_homograph/node-feat-0.npy

Part of node feature [feat_1]: tensor([[0.0049, 0.2713, 0.4365, 0.6562, 0.1680],
        [0.8289, 0.9832, 0.2571, 0.6492, 0.1832],
        [0.1485, 0.1582, 0.3427, 0.3278, 0.4168]])
Node feature [feat_1] is saved to ./ondisk_dataset_homograph/node-feat-1.pt

Part of edge feature [feat_0]: [[0.97929532 0.26219736 0.77051533 0.74585649 0.82825006]
 [0.88215126 0.64766533 0.99787335 0.64830204 0.04433256]
 [0.73490086 0.50615544 0.62849607 0.44198614 0.54274978]]
Edge feature [feat_0] is saved to ./ondisk_dataset_homograph/edge-feat-0.npy

Part of edge feature [feat_1]: tensor([[0.4510, 0.9419, 0.2873, 0.9467, 0.7067],
        [0.0965, 0.9493, 0.3095, 0.7945, 0.4386],
        [0.9132, 0.3329, 0.7457, 0.9974, 0.5723]])
Edge feature [feat_1] is saved to ./ondisk_dataset_homograph/edge-feat-1.pt

</pre></div></div>
</div>
</section>
<section id="Generate-tasks">
<h3>Generate tasks<a class="headerlink" href="#Generate-tasks" title="Link to this heading"></a></h3>
<p><code class="docutils literal notranslate"><span class="pre">OnDiskDataset</span></code> supports multiple tasks. For each task, we need to prepare training/validation/test sets respectively. Such sets usually vary among different tasks. In this tutorial, let’s create a <strong>Node Classification</strong> task and <strong>Link Prediction</strong> task.</p>
<section id="Node-Classification-Task">
<h4>Node Classification Task<a class="headerlink" href="#Node-Classification-Task" title="Link to this heading"></a></h4>
<p>For node classification task, we need <strong>node IDs</strong> and corresponding <strong>labels</strong> for each training/validation/test set. Like feature data, numpy arrays and torch tensors are supported for these sets.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num_trains</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">num_nodes</span> <span class="o">*</span> <span class="mf">0.6</span><span class="p">)</span>
<span class="n">num_vals</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">num_nodes</span> <span class="o">*</span> <span class="mf">0.2</span><span class="p">)</span>
<span class="n">num_tests</span> <span class="o">=</span> <span class="n">num_nodes</span> <span class="o">-</span> <span class="n">num_trains</span> <span class="o">-</span> <span class="n">num_vals</span>

<span class="n">ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">num_nodes</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">ids</span><span class="p">)</span>

<span class="n">nc_train_ids_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s2">"nc-train-ids.npy"</span><span class="p">)</span>
<span class="n">nc_train_ids</span> <span class="o">=</span> <span class="n">ids</span><span class="p">[:</span><span class="n">num_trains</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Part of train ids for node classification: </span><span class="si">{</span><span class="n">nc_train_ids</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">nc_train_ids_path</span><span class="p">,</span> <span class="n">nc_train_ids</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"NC train ids are saved to </span><span class="si">{</span><span class="n">nc_train_ids_path</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>

<span class="n">nc_train_labels_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s2">"nc-train-labels.pt"</span><span class="p">)</span>
<span class="n">nc_train_labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="p">(</span><span class="n">num_trains</span><span class="p">,))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Part of train labels for node classification: </span><span class="si">{</span><span class="n">nc_train_labels</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">nc_train_labels</span><span class="p">,</span> <span class="n">nc_train_labels_path</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"NC train labels are saved to </span><span class="si">{</span><span class="n">nc_train_labels_path</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>

<span class="n">nc_val_ids_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s2">"nc-val-ids.npy"</span><span class="p">)</span>
<span class="n">nc_val_ids</span> <span class="o">=</span> <span class="n">ids</span><span class="p">[</span><span class="n">num_trains</span><span class="p">:</span><span class="n">num_trains</span><span class="o">+</span><span class="n">num_vals</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Part of val ids for node classification: </span><span class="si">{</span><span class="n">nc_val_ids</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">nc_val_ids_path</span><span class="p">,</span> <span class="n">nc_val_ids</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"NC val ids are saved to </span><span class="si">{</span><span class="n">nc_val_ids_path</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>

<span class="n">nc_val_labels_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s2">"nc-val-labels.pt"</span><span class="p">)</span>
<span class="n">nc_val_labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="p">(</span><span class="n">num_vals</span><span class="p">,))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Part of val labels for node classification: </span><span class="si">{</span><span class="n">nc_val_labels</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">nc_val_labels</span><span class="p">,</span> <span class="n">nc_val_labels_path</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"NC val labels are saved to </span><span class="si">{</span><span class="n">nc_val_labels_path</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>

<span class="n">nc_test_ids_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s2">"nc-test-ids.npy"</span><span class="p">)</span>
<span class="n">nc_test_ids</span> <span class="o">=</span> <span class="n">ids</span><span class="p">[</span><span class="o">-</span><span class="n">num_tests</span><span class="p">:]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Part of test ids for node classification: </span><span class="si">{</span><span class="n">nc_test_ids</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">nc_test_ids_path</span><span class="p">,</span> <span class="n">nc_test_ids</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"NC test ids are saved to </span><span class="si">{</span><span class="n">nc_test_ids_path</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>

<span class="n">nc_test_labels_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s2">"nc-test-labels.pt"</span><span class="p">)</span>
<span class="n">nc_test_labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="p">(</span><span class="n">num_tests</span><span class="p">,))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Part of test labels for node classification: </span><span class="si">{</span><span class="n">nc_test_labels</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">nc_test_labels</span><span class="p">,</span> <span class="n">nc_test_labels_path</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"NC test labels are saved to </span><span class="si">{</span><span class="n">nc_test_labels_path</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Part of train ids for node classification: [319 941  14]
NC train ids are saved to ./ondisk_dataset_homograph/nc-train-ids.npy

Part of train labels for node classification: tensor([1, 3, 6])
NC train labels are saved to ./ondisk_dataset_homograph/nc-train-labels.pt

Part of val ids for node classification: [690 926 216]
NC val ids are saved to ./ondisk_dataset_homograph/nc-val-ids.npy

Part of val labels for node classification: tensor([2, 5, 6])
NC val labels are saved to ./ondisk_dataset_homograph/nc-val-labels.pt

Part of test ids for node classification: [701  67  16]
NC test ids are saved to ./ondisk_dataset_homograph/nc-test-ids.npy

Part of test labels for node classification: tensor([6, 7, 1])
NC test labels are saved to ./ondisk_dataset_homograph/nc-test-labels.pt

</pre></div></div>
</div>
</section>
<section id="Link-Prediction-Task">
<h4>Link Prediction Task<a class="headerlink" href="#Link-Prediction-Task" title="Link to this heading"></a></h4>
<p>For link prediction task, we need <strong>seeds</strong> or <strong>corresponding labels and indexes</strong> which representing the pos/neg property and group of the seeds for each training/validation/test set. Like feature data, numpy arrays and torch tensors are supported for these sets.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num_trains</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">num_edges</span> <span class="o">*</span> <span class="mf">0.6</span><span class="p">)</span>
<span class="n">num_vals</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">num_edges</span> <span class="o">*</span> <span class="mf">0.2</span><span class="p">)</span>
<span class="n">num_tests</span> <span class="o">=</span> <span class="n">num_edges</span> <span class="o">-</span> <span class="n">num_trains</span> <span class="o">-</span> <span class="n">num_vals</span>

<span class="n">lp_train_seeds_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s2">"lp-train-seeds.npy"</span><span class="p">)</span>
<span class="n">lp_train_seeds</span> <span class="o">=</span> <span class="n">edges</span><span class="p">[:</span><span class="n">num_trains</span><span class="p">,</span> <span class="p">:]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Part of train seeds for link prediction: </span><span class="si">{</span><span class="n">lp_train_seeds</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">lp_train_seeds_path</span><span class="p">,</span> <span class="n">lp_train_seeds</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"LP train seeds are saved to </span><span class="si">{</span><span class="n">lp_train_seeds_path</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>

<span class="n">lp_val_seeds_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s2">"lp-val-seeds.npy"</span><span class="p">)</span>
<span class="n">lp_val_seeds</span> <span class="o">=</span> <span class="n">edges</span><span class="p">[</span><span class="n">num_trains</span><span class="p">:</span><span class="n">num_trains</span><span class="o">+</span><span class="n">num_vals</span><span class="p">,</span> <span class="p">:]</span>
<span class="n">lp_val_neg_dsts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_nodes</span><span class="p">,</span> <span class="p">(</span><span class="n">num_vals</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">lp_val_neg_srcs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">lp_val_seeds</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">lp_val_neg_seeds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">lp_val_neg_srcs</span><span class="p">,</span> <span class="n">lp_val_neg_dsts</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
<span class="n">lp_val_seeds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">lp_val_seeds</span><span class="p">,</span> <span class="n">lp_val_neg_seeds</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Part of val seeds for link prediction: </span><span class="si">{</span><span class="n">lp_val_seeds</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">lp_val_seeds_path</span><span class="p">,</span> <span class="n">lp_val_seeds</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"LP val seeds are saved to </span><span class="si">{</span><span class="n">lp_val_seeds_path</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>

<span class="n">lp_val_labels_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s2">"lp-val-labels.npy"</span><span class="p">)</span>
<span class="n">lp_val_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">num_vals</span> <span class="o">*</span> <span class="p">(</span><span class="mi">10</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">lp_val_labels</span><span class="p">[:</span><span class="n">num_vals</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">lp_val_labels</span><span class="p">[</span><span class="n">num_vals</span><span class="p">:]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Part of val labels for link prediction: </span><span class="si">{</span><span class="n">lp_val_labels</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">lp_val_labels_path</span><span class="p">,</span> <span class="n">lp_val_labels</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"LP val labels are saved to </span><span class="si">{</span><span class="n">lp_val_labels_path</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>

<span class="n">lp_val_indexes_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s2">"lp-val-indexes.npy"</span><span class="p">)</span>
<span class="n">lp_val_indexes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_vals</span><span class="p">)</span>
<span class="n">lp_val_neg_indexes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">lp_val_indexes</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">lp_val_indexes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">lp_val_indexes</span><span class="p">,</span> <span class="n">lp_val_neg_indexes</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Part of val indexes for link prediction: </span><span class="si">{</span><span class="n">lp_val_indexes</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">lp_val_indexes_path</span><span class="p">,</span> <span class="n">lp_val_indexes</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"LP val indexes are saved to </span><span class="si">{</span><span class="n">lp_val_indexes_path</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>

<span class="n">lp_test_seeds_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s2">"lp-test-seeds.npy"</span><span class="p">)</span>
<span class="n">lp_test_seeds</span> <span class="o">=</span> <span class="n">edges</span><span class="p">[</span><span class="o">-</span><span class="n">num_tests</span><span class="p">:,</span> <span class="p">:]</span>
<span class="n">lp_test_neg_dsts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_nodes</span><span class="p">,</span> <span class="p">(</span><span class="n">num_tests</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">lp_test_neg_srcs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">lp_test_seeds</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">lp_test_neg_seeds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">lp_test_neg_srcs</span><span class="p">,</span> <span class="n">lp_test_neg_dsts</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
<span class="n">lp_test_seeds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">lp_test_seeds</span><span class="p">,</span> <span class="n">lp_test_neg_seeds</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Part of test seeds for link prediction: </span><span class="si">{</span><span class="n">lp_test_seeds</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">lp_test_seeds_path</span><span class="p">,</span> <span class="n">lp_test_seeds</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"LP test seeds are saved to </span><span class="si">{</span><span class="n">lp_test_seeds_path</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>

<span class="n">lp_test_labels_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s2">"lp-test-labels.npy"</span><span class="p">)</span>
<span class="n">lp_test_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">num_tests</span> <span class="o">*</span> <span class="p">(</span><span class="mi">10</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">lp_test_labels</span><span class="p">[:</span><span class="n">num_tests</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">lp_test_labels</span><span class="p">[</span><span class="n">num_tests</span><span class="p">:]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Part of val labels for link prediction: </span><span class="si">{</span><span class="n">lp_test_labels</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">lp_test_labels_path</span><span class="p">,</span> <span class="n">lp_test_labels</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"LP test labels are saved to </span><span class="si">{</span><span class="n">lp_test_labels_path</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>

<span class="n">lp_test_indexes_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s2">"lp-test-indexes.npy"</span><span class="p">)</span>
<span class="n">lp_test_indexes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_tests</span><span class="p">)</span>
<span class="n">lp_test_neg_indexes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">lp_test_indexes</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">lp_test_indexes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">lp_test_indexes</span><span class="p">,</span> <span class="n">lp_test_neg_indexes</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Part of test indexes for link prediction: </span><span class="si">{</span><span class="n">lp_test_indexes</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">lp_test_indexes_path</span><span class="p">,</span> <span class="n">lp_test_indexes</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"LP test indexes are saved to </span><span class="si">{</span><span class="n">lp_test_indexes_path</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Part of train seeds for link prediction: [[427 810]
 [482 156]
 [739 383]]
LP train seeds are saved to ./ondisk_dataset_homograph/lp-train-seeds.npy

Part of val seeds for link prediction: [[616 238]
 [909 408]
 [642 753]]
LP val seeds are saved to ./ondisk_dataset_homograph/lp-val-seeds.npy

Part of val labels for link prediction: [1. 1. 1.]
LP val labels are saved to ./ondisk_dataset_homograph/lp-val-labels.npy

Part of val indexes for link prediction: [0 1 2]
LP val indexes are saved to ./ondisk_dataset_homograph/lp-val-indexes.npy

Part of test seeds for link prediction: [[647 821]
 [159 262]
 [ 43 294]]
LP test seeds are saved to ./ondisk_dataset_homograph/lp-test-seeds.npy

Part of val labels for link prediction: [1. 1. 1.]
LP test labels are saved to ./ondisk_dataset_homograph/lp-test-labels.npy

Part of test indexes for link prediction: [0 1 2]
LP test indexes are saved to ./ondisk_dataset_homograph/lp-test-indexes.npy

</pre></div></div>
</div>
</section>
</section>
</section>
<section id="Organize-Data-into-YAML-File">
<h2>Organize Data into YAML File<a class="headerlink" href="#Organize-Data-into-YAML-File" title="Link to this heading"></a></h2>
<p>Now we need to create a <code class="docutils literal notranslate"><span class="pre">metadata.yaml</span></code> file which contains the paths, dadta types of graph structure, feature data, training/validation/test sets.</p>
<p>Notes: - all path should be relative to <code class="docutils literal notranslate"><span class="pre">metadata.yaml</span></code>. - Below fields are optional and not specified in below example. - <code class="docutils literal notranslate"><span class="pre">in_memory</span></code>: indicates whether to load dada into memory or <code class="docutils literal notranslate"><span class="pre">mmap</span></code>. Default is <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
<p>Please refer to <a class="reference external" href="https://github.com/dmlc/dgl/blob/master/docs/source/stochastic_training/ondisk-dataset-specification.rst">YAML specification</a> for more details.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">yaml_content</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"""</span>
<span class="s2">    dataset_name: homogeneous_graph_nc_lp</span>
<span class="s2">    graph:</span>
<span class="s2">      nodes:</span>
<span class="s2">        - num: </span><span class="si">{</span><span class="n">num_nodes</span><span class="si">}</span>
<span class="s2">      edges:</span>
<span class="s2">        - format: csv</span>
<span class="s2">          path: </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">edges_path</span><span class="p">)</span><span class="si">}</span>
<span class="s2">    feature_data:</span>
<span class="s2">      - domain: node</span>
<span class="s2">        name: feat_0</span>
<span class="s2">        format: numpy</span>
<span class="s2">        path: </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">node_feat_0_path</span><span class="p">)</span><span class="si">}</span>
<span class="s2">      - domain: node</span>
<span class="s2">        name: feat_1</span>
<span class="s2">        format: torch</span>
<span class="s2">        path: </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">node_feat_1_path</span><span class="p">)</span><span class="si">}</span>
<span class="s2">      - domain: edge</span>
<span class="s2">        name: feat_0</span>
<span class="s2">        format: numpy</span>
<span class="s2">        path: </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">edge_feat_0_path</span><span class="p">)</span><span class="si">}</span>
<span class="s2">      - domain: edge</span>
<span class="s2">        name: feat_1</span>
<span class="s2">        format: torch</span>
<span class="s2">        path: </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">edge_feat_1_path</span><span class="p">)</span><span class="si">}</span>
<span class="s2">    tasks:</span>
<span class="s2">      - name: node_classification</span>
<span class="s2">        num_classes: 10</span>
<span class="s2">        train_set:</span>
<span class="s2">          - data:</span>
<span class="s2">              - name: seeds</span>
<span class="s2">                format: numpy</span>
<span class="s2">                path: </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">nc_train_ids_path</span><span class="p">)</span><span class="si">}</span>
<span class="s2">              - name: labels</span>
<span class="s2">                format: torch</span>
<span class="s2">                path: </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">nc_train_labels_path</span><span class="p">)</span><span class="si">}</span>
<span class="s2">        validation_set:</span>
<span class="s2">          - data:</span>
<span class="s2">              - name: seeds</span>
<span class="s2">                format: numpy</span>
<span class="s2">                path: </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">nc_val_ids_path</span><span class="p">)</span><span class="si">}</span>
<span class="s2">              - name: labels</span>
<span class="s2">                format: torch</span>
<span class="s2">                path: </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">nc_val_labels_path</span><span class="p">)</span><span class="si">}</span>
<span class="s2">        test_set:</span>
<span class="s2">          - data:</span>
<span class="s2">              - name: seeds</span>
<span class="s2">                format: numpy</span>
<span class="s2">                path: </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">nc_test_ids_path</span><span class="p">)</span><span class="si">}</span>
<span class="s2">              - name: labels</span>
<span class="s2">                format: torch</span>
<span class="s2">                path: </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">nc_test_labels_path</span><span class="p">)</span><span class="si">}</span>
<span class="s2">      - name: link_prediction</span>
<span class="s2">        num_classes: 10</span>
<span class="s2">        train_set:</span>
<span class="s2">          - data:</span>
<span class="s2">              - name: seeds</span>
<span class="s2">                format: numpy</span>
<span class="s2">                path: </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">lp_train_seeds_path</span><span class="p">)</span><span class="si">}</span>
<span class="s2">        validation_set:</span>
<span class="s2">          - data:</span>
<span class="s2">              - name: seeds</span>
<span class="s2">                format: numpy</span>
<span class="s2">                path: </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">lp_val_seeds_path</span><span class="p">)</span><span class="si">}</span>
<span class="s2">              - name: labels</span>
<span class="s2">                format: numpy</span>
<span class="s2">                path: </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">lp_val_labels_path</span><span class="p">)</span><span class="si">}</span>
<span class="s2">              - name: indexes</span>
<span class="s2">                format: numpy</span>
<span class="s2">                path: </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">lp_val_indexes_path</span><span class="p">)</span><span class="si">}</span>
<span class="s2">        test_set:</span>
<span class="s2">          - data:</span>
<span class="s2">              - name: seeds</span>
<span class="s2">                format: numpy</span>
<span class="s2">                path: </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">lp_test_seeds_path</span><span class="p">)</span><span class="si">}</span>
<span class="s2">              - name: labels</span>
<span class="s2">                format: numpy</span>
<span class="s2">                path: </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">lp_test_labels_path</span><span class="p">)</span><span class="si">}</span>
<span class="s2">              - name: indexes</span>
<span class="s2">                format: numpy</span>
<span class="s2">                path: </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">lp_test_indexes_path</span><span class="p">)</span><span class="si">}</span>
<span class="s2">"""</span>
<span class="n">metadata_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s2">"metadata.yaml"</span><span class="p">)</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">metadata_path</span><span class="p">,</span> <span class="s2">"w"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
  <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">yaml_content</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="Instantiate-OnDiskDataset">
<h2>Instantiate <code class="docutils literal notranslate"><span class="pre">OnDiskDataset</span></code><a class="headerlink" href="#Instantiate-OnDiskDataset" title="Link to this heading"></a></h2>
<p>Now we’re ready to load dataset via <code class="docutils literal notranslate"><span class="pre">dgl.graphbolt.OnDiskDataset</span></code>. When instantiating, we just pass in the base directory where <code class="docutils literal notranslate"><span class="pre">metadata.yaml</span></code> file lies.</p>
<p>During first instantiation, GraphBolt preprocesses the raw data such as constructing <code class="docutils literal notranslate"><span class="pre">FusedCSCSamplingGraph</span></code> from edges. All data including graph, feature data, training/validation/test sets are put into <code class="docutils literal notranslate"><span class="pre">preprocessed</span></code> directory after preprocessing. Any following dataset loading will skip the preprocess stage.</p>
<p>After preprocessing, <code class="docutils literal notranslate"><span class="pre">load()</span></code> is required to be called explicitly in order to load graph, feature data and tasks.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">gb</span><span class="o">.</span><span class="n">OnDiskDataset</span><span class="p">(</span><span class="n">base_dir</span><span class="p">)</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
<span class="n">graph</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">graph</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Loaded graph: </span><span class="si">{</span><span class="n">graph</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>

<span class="n">feature</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">feature</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Loaded feature store: </span><span class="si">{</span><span class="n">feature</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>

<span class="n">tasks</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">tasks</span>
<span class="n">nc_task</span> <span class="o">=</span> <span class="n">tasks</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Loaded node classification task: </span><span class="si">{</span><span class="n">nc_task</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="n">lp_task</span> <span class="o">=</span> <span class="n">tasks</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Loaded link prediction task: </span><span class="si">{</span><span class="n">lp_task</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
The on-disk dataset is re-preprocessing, so the existing preprocessed dataset has been removed.
Start to preprocess the on-disk dataset.
Finish preprocessing the on-disk dataset.
Loaded graph: FusedCSCSamplingGraph(csc_indptr=tensor([    0,     7,    17,  ...,  9986,  9994, 10000], dtype=torch.int32),
                      indices=tensor([485,  22, 451,  ..., 162,  83, 244], dtype=torch.int32),
                      total_num_nodes=1000, num_edges=10000,)

Loaded feature store: TorchBasedFeatureStore(
    {(&lt;OnDiskFeatureDataDomain.NODE: 'node'&gt;, None, 'feat_0'): TorchBasedFeature(
        feature=tensor([[0.1876, 0.8263, 0.6953, 0.7733, 0.2514],
                        [0.8129, 0.4626, 0.2879, 0.3912, 0.7007],
                        [0.0742, 0.8798, 0.8174, 0.6519, 0.9469],
                        ...,
                        [0.1306, 0.4217, 0.2288, 0.7774, 0.2758],
                        [0.7249, 0.5999, 0.2864, 0.8552, 0.6333],
                        [0.9196, 0.4662, 0.4508, 0.3615, 0.3961]], dtype=torch.float64),
        metadata={},
    ), (&lt;OnDiskFeatureDataDomain.NODE: 'node'&gt;, None, 'feat_1'): TorchBasedFeature(
        feature=tensor([[0.0049, 0.2713, 0.4365, 0.6562, 0.1680],
                        [0.8289, 0.9832, 0.2571, 0.6492, 0.1832],
                        [0.1485, 0.1582, 0.3427, 0.3278, 0.4168],
                        ...,
                        [0.9984, 0.0874, 0.2436, 0.6776, 0.4748],
                        [0.1451, 0.8869, 0.7228, 0.4476, 0.2962],
                        [0.1328, 0.4454, 0.7663, 0.0562, 0.5917]]),
        metadata={},
    ), (&lt;OnDiskFeatureDataDomain.EDGE: 'edge'&gt;, None, 'feat_0'): TorchBasedFeature(
        feature=tensor([[0.9793, 0.2622, 0.7705, 0.7459, 0.8283],
                        [0.8822, 0.6477, 0.9979, 0.6483, 0.0443],
                        [0.7349, 0.5062, 0.6285, 0.4420, 0.5427],
                        ...,
                        [0.5834, 0.8433, 0.2425, 0.7302, 0.8129],
                        [0.6204, 0.9772, 0.0481, 0.7689, 0.8268],
                        [0.7149, 0.2703, 0.2319, 0.6791, 0.7113]], dtype=torch.float64),
        metadata={},
    ), (&lt;OnDiskFeatureDataDomain.EDGE: 'edge'&gt;, None, 'feat_1'): TorchBasedFeature(
        feature=tensor([[0.4510, 0.9419, 0.2873, 0.9467, 0.7067],
                        [0.0965, 0.9493, 0.3095, 0.7945, 0.4386],
                        [0.9132, 0.3329, 0.7457, 0.9974, 0.5723],
                        ...,
                        [0.3990, 0.0913, 0.4191, 0.6689, 0.0301],
                        [0.3289, 0.8927, 0.6004, 0.7120, 0.8760],
                        [0.2898, 0.6798, 0.1388, 0.6638, 0.1701]]),
        metadata={},
    )}
)

Loaded node classification task: OnDiskTask(validation_set=ItemSet(
               items=(tensor([690, 926, 216, 757, 596, 161, 643, 141, 837, 310, 720, 390, 169, 245,
                   398, 996, 989,   3, 937, 496, 208, 773, 900, 744, 984, 530, 231, 336,
                   722, 829, 494, 692, 367, 872, 290, 127, 914,  55, 212, 540, 543,  32,
                   774, 345, 377, 568, 870, 752, 241, 979, 369, 479, 420, 528, 306, 518,
                   591,  57, 737, 794, 725, 614, 225, 721, 961, 150, 386, 798, 246, 651,
                   948, 805, 258, 537, 776, 176, 921, 139, 913, 263, 471,  17, 512, 163,
                    96, 569, 441, 593, 595, 795, 410, 549, 136, 738,  28, 204, 298, 303,
                   612, 492, 573, 893, 106, 202, 388, 659, 769, 634, 229, 218, 192, 272,
                   323, 115, 465, 953, 983, 355, 538, 729, 585,  73, 799, 416, 276, 777,
                   362, 346, 389, 453, 312,  30, 586,  79, 358, 686, 422, 683, 314, 742,
                   484, 326, 765, 385, 541, 997, 924, 600, 806,  19, 785, 779, 438, 393,
                   178, 923, 252, 911, 688, 626, 251, 871, 935, 609, 234, 755,  51, 526,
                   790, 711, 300, 868, 262, 395, 655, 239,  21, 584, 847, 464, 353, 361,
                   665, 808, 160, 760, 242, 931,  35, 248, 663, 647, 191, 404, 257, 840,
                   562,   5, 516, 629], dtype=torch.int32), tensor([2, 5, 6, 0, 7, 6, 8, 4, 6, 0, 8, 9, 1, 5, 6, 1, 7, 1, 0, 3, 7, 7, 1, 9,
                   8, 4, 9, 1, 4, 6, 9, 5, 1, 1, 8, 8, 8, 8, 5, 7, 9, 3, 1, 7, 5, 3, 4, 2,
                   6, 5, 8, 3, 3, 8, 8, 5, 3, 7, 6, 6, 4, 5, 4, 1, 7, 4, 0, 3, 7, 9, 0, 6,
                   8, 5, 8, 7, 9, 5, 9, 7, 4, 6, 5, 4, 1, 1, 1, 2, 1, 8, 6, 9, 9, 7, 7, 1,
                   4, 5, 2, 9, 4, 1, 7, 2, 0, 8, 9, 8, 3, 4, 8, 4, 9, 9, 7, 0, 1, 5, 8, 7,
                   6, 6, 4, 3, 3, 8, 6, 2, 8, 8, 5, 4, 0, 7, 9, 5, 0, 2, 4, 5, 2, 3, 2, 3,
                   8, 0, 2, 4, 7, 1, 7, 7, 8, 7, 8, 2, 7, 8, 0, 4, 2, 0, 4, 0, 4, 1, 8, 1,
                   1, 4, 2, 3, 0, 4, 1, 1, 5, 9, 5, 1, 9, 2, 5, 2, 2, 9, 8, 1, 9, 0, 9, 8,
                   7, 7, 4, 0, 2, 6, 4, 5])),
               names=('seeds', 'labels'),
           ),
           train_set=ItemSet(
               items=(tensor([319, 941,  14, 203, 444,  10, 740, 716, 775, 954, 301,  40, 589,  29,
                   439, 706, 401, 145, 181, 335, 296, 536, 916, 564, 745, 841, 277, 919,
                   574, 557, 359, 822, 862,  43, 580, 322, 374, 836, 171, 222, 743, 999,
                    24, 823, 884, 981, 489, 960,  56, 110, 691, 459, 940, 645, 930, 190,
                   772,  87, 205, 431, 689, 550, 461, 669, 618, 117, 130, 874, 656, 366,
                   630, 468, 344, 581, 286, 101, 710, 639, 544, 675, 834, 220, 490, 320,
                   392, 759, 732,  23, 566, 175, 950, 293, 217, 998, 646,  95, 860, 832,
                   801, 857, 879, 680, 539,  34, 892, 644, 791, 833, 676, 504, 387, 628,
                    12, 118, 887, 198, 337, 485,  33, 527, 768, 942, 708, 270, 370, 177,
                   146, 815, 788,   7, 442, 962, 787, 570, 920, 778, 604, 340, 488, 521,
                   952, 985, 571, 869, 287, 660, 495, 899, 556, 880, 511, 533, 112, 183,
                   419,  37, 394, 503, 425,  54, 104, 201, 506, 602, 883, 974, 476, 965,
                   243, 687,  82, 109, 598, 447, 407, 186, 249,  86, 927, 274, 843, 947,
                   671, 196,  36, 380, 968, 811, 821, 481, 756, 450, 894, 508, 523, 357,
                    25, 830, 682, 802, 154, 372, 180, 235, 260,  39, 200, 321, 761, 448,
                   309, 719, 966, 697, 457, 705,   6, 632, 383, 436, 552,  41, 509, 929,
                   842, 348, 891,  18, 563, 933, 253, 238, 206, 867,  66, 418,  48, 972,
                   587, 572, 820, 424, 402, 102, 963, 993, 590, 430,  98,  26,  97, 254,
                   613, 350, 616, 304, 478, 426, 735, 615, 667, 592, 863, 865, 607, 182,
                   751, 904, 311, 412, 414,  94, 695, 329, 172, 606, 499, 445, 167, 906,
                   135, 818, 223, 889, 641,  85, 209, 519,  50, 809, 850, 873, 627, 114,
                   356, 567,  93, 917, 168, 151, 317, 631, 501, 428, 156, 173, 373, 120,
                    76, 858, 813, 603, 781, 703, 384, 119, 903, 413, 437, 992, 266, 132,
                   267, 406, 240, 497, 936, 624, 734, 159, 524,  52, 417, 851, 679, 846,
                   938, 364, 382, 754, 292, 411, 825, 800, 741, 427, 895,  31, 668, 477,
                   588, 174, 684, 635, 967, 987, 399, 583, 193, 531, 515, 342, 970,  78,
                    81, 666, 107,  99, 746, 213, 849, 658, 977, 988, 279, 561, 275, 261,
                   105, 189, 560, 493,  49, 717,  75, 727, 147, 685, 307, 532, 535, 610,
                   956, 605, 381, 939, 379, 617, 855, 804, 123, 730, 376, 122, 636, 452,
                   622,  61, 696, 673, 341,  88,  80, 653, 352, 116, 758, 299, 244, 408,
                     0, 551, 324, 474, 125, 232, 415, 103, 233, 839, 227, 124, 215, 149,
                   797, 971, 339, 128, 451, 991, 486, 331, 423, 852, 944, 460, 881,  83,
                   699, 978, 179, 909, 343, 144, 210, 534, 294, 678, 780, 283, 502, 553,
                   440, 507, 677, 338, 657, 236, 157, 990, 652, 153, 922, 713, 197, 946,
                   812, 328, 164,   1, 542, 698, 247,  46, 890, 285, 256, 896, 897, 640,
                   280, 866, 980, 654, 365, 308, 140, 885, 579, 368, 770, 577, 739, 405,
                   973, 315, 250, 237, 487, 943, 786, 529, 514, 185, 467, 828, 133, 619,
                    65, 878, 810, 995, 578,   8, 113, 845, 158, 898, 520, 642, 480, 693,
                   986, 433,  47, 429,   2, 354, 327, 409, 134,  69, 771, 951, 661, 700,
                   733, 558, 199, 724, 709, 363, 522, 715,  58, 949, 434, 278, 500, 284,
                   170, 162,  62, 525, 184, 648, 443, 131, 259, 718, 625, 783, 918, 864,
                   803, 955, 886, 712, 750, 513,  13, 268, 397, 582,  63, 295, 187, 831,
                   827, 547, 456, 672, 957, 108, 945, 475, 844,  84, 469, 848],
                  dtype=torch.int32), tensor([1, 3, 6, 3, 3, 1, 6, 6, 4, 4, 0, 3, 7, 5, 5, 5, 8, 9, 9, 3, 1, 9, 4, 4,
                   2, 9, 7, 8, 1, 4, 2, 6, 5, 1, 6, 6, 3, 7, 0, 9, 2, 1, 3, 3, 1, 2, 6, 2,
                   4, 5, 7, 3, 7, 4, 3, 5, 8, 6, 5, 0, 7, 2, 0, 7, 7, 6, 0, 5, 0, 0, 4, 4,
                   2, 7, 5, 9, 1, 5, 4, 7, 4, 7, 0, 1, 1, 4, 4, 8, 8, 9, 4, 2, 2, 2, 9, 2,
                   7, 2, 8, 6, 9, 3, 4, 1, 8, 2, 8, 4, 9, 3, 6, 6, 6, 6, 2, 5, 1, 0, 9, 4,
                   9, 4, 1, 8, 2, 8, 9, 0, 5, 4, 8, 0, 8, 9, 0, 5, 9, 5, 7, 1, 5, 9, 3, 1,
                   5, 6, 4, 7, 5, 6, 6, 7, 5, 2, 9, 0, 8, 5, 5, 5, 6, 0, 4, 0, 2, 9, 6, 9,
                   1, 1, 6, 4, 4, 5, 1, 4, 3, 0, 1, 3, 7, 3, 7, 5, 4, 4, 4, 5, 0, 9, 5, 1,
                   0, 7, 0, 4, 8, 1, 4, 7, 4, 8, 4, 4, 0, 1, 8, 1, 3, 8, 9, 3, 2, 6, 2, 9,
                   4, 6, 0, 0, 1, 2, 1, 8, 0, 0, 8, 0, 9, 9, 6, 6, 2, 0, 7, 8, 8, 1, 1, 0,
                   2, 9, 0, 5, 0, 8, 7, 8, 4, 2, 2, 3, 3, 6, 4, 7, 9, 3, 5, 5, 4, 0, 0, 2,
                   0, 2, 8, 3, 2, 4, 5, 0, 6, 9, 0, 4, 0, 4, 8, 1, 9, 8, 3, 1, 9, 1, 6, 8,
                   4, 4, 7, 1, 7, 9, 9, 6, 0, 8, 0, 5, 8, 2, 7, 3, 6, 3, 5, 6, 2, 8, 3, 4,
                   8, 7, 3, 9, 5, 1, 8, 7, 9, 0, 4, 6, 9, 4, 9, 5, 3, 7, 8, 7, 0, 7, 9, 9,
                   8, 4, 2, 8, 6, 5, 4, 1, 3, 6, 1, 0, 0, 1, 2, 8, 3, 0, 3, 0, 1, 3, 2, 2,
                   7, 2, 6, 6, 9, 0, 9, 3, 2, 4, 8, 9, 5, 4, 5, 5, 3, 4, 2, 6, 4, 5, 6, 8,
                   6, 6, 9, 4, 7, 6, 3, 9, 1, 3, 2, 4, 9, 2, 8, 4, 4, 3, 2, 8, 5, 4, 6, 9,
                   1, 9, 5, 2, 1, 9, 3, 2, 8, 3, 7, 1, 5, 4, 3, 3, 6, 1, 3, 3, 9, 5, 7, 7,
                   0, 4, 7, 2, 5, 4, 6, 5, 1, 7, 1, 5, 5, 5, 4, 0, 9, 6, 6, 7, 4, 1, 7, 7,
                   6, 3, 3, 3, 9, 8, 9, 5, 1, 9, 7, 2, 7, 3, 9, 4, 4, 3, 6, 6, 1, 1, 0, 9,
                   5, 4, 0, 0, 4, 9, 6, 8, 5, 6, 0, 6, 5, 6, 9, 6, 2, 2, 7, 1, 8, 3, 4, 5,
                   4, 3, 9, 5, 9, 5, 4, 5, 2, 0, 6, 9, 7, 1, 5, 0, 4, 2, 2, 2, 7, 1, 4, 2,
                   6, 1, 6, 5, 4, 7, 8, 6, 4, 5, 4, 5, 1, 2, 1, 8, 6, 9, 7, 4, 6, 7, 8, 9,
                   7, 9, 2, 5, 1, 8, 9, 4, 2, 7, 2, 6, 6, 4, 2, 6, 7, 7, 5, 1, 5, 9, 0, 9,
                   4, 7, 2, 7, 3, 4, 9, 0, 6, 2, 8, 7, 1, 4, 2, 5, 0, 0, 8, 6, 4, 9, 8, 3])),
               names=('seeds', 'labels'),
           ),
           test_set=ItemSet(
               items=(tensor([701,  67,  16, 288,  64,  68, 824, 473, 854, 876,  90, 662, 228, 510,
                   221, 707, 458, 332, 152, 912, 449,  60, 915,  20, 597, 559, 166, 599,
                   129, 302,  91, 964, 928, 723, 142,  27, 728, 819, 100,  15, 378, 982,
                   137,  89, 230, 289, 704,   4, 763, 281, 214,   9, 505, 932, 491, 838,
                   958, 789, 621, 638, 859, 316, 219, 975, 455,  53, 908,  44, 826, 466,
                   807, 224, 731, 546, 934,  71, 360,  92,  77, 188, 664, 905, 349, 498,
                   793, 796, 330, 121, 959, 611, 554, 351,  22, 623, 766, 853, 165, 548,
                   637, 264,  72, 576, 767, 670, 694, 403, 681, 748,  38, 446, 421, 269,
                   902, 435, 470, 856, 545, 148, 517, 313, 749, 375, 226, 726, 608, 620,
                   432, 633, 207, 601, 143, 400, 714, 861, 463, 969, 764, 753, 462, 925,
                   784, 782, 255, 472, 762, 835, 333, 291,  45, 792, 875, 882, 994, 816,
                    42, 649, 126, 575, 297, 910, 155, 565, 195, 747, 674, 371,  70, 111,
                   976, 814, 273,  11, 877, 305, 211, 318, 482, 888, 454, 901, 650, 138,
                   555,  74, 325, 594,  59, 282, 334, 347, 271, 265, 194, 391, 817, 736,
                   396, 702, 483, 907], dtype=torch.int32), tensor([6, 7, 1, 2, 0, 1, 9, 7, 2, 2, 5, 6, 9, 3, 5, 0, 7, 2, 5, 9, 2, 2, 7, 7,
                   4, 1, 1, 4, 6, 9, 9, 8, 0, 4, 7, 9, 6, 6, 7, 1, 2, 1, 0, 6, 8, 2, 9, 2,
                   5, 3, 8, 9, 4, 8, 4, 2, 8, 0, 3, 1, 8, 7, 8, 2, 1, 4, 9, 2, 1, 6, 1, 2,
                   5, 8, 9, 0, 3, 3, 5, 1, 9, 4, 7, 3, 4, 5, 1, 7, 9, 8, 0, 2, 5, 4, 5, 7,
                   5, 3, 3, 5, 7, 4, 8, 8, 1, 5, 5, 0, 1, 7, 4, 1, 6, 9, 3, 5, 7, 6, 4, 3,
                   0, 2, 7, 8, 9, 1, 5, 4, 5, 3, 7, 6, 5, 1, 2, 3, 5, 3, 5, 6, 4, 8, 2, 4,
                   3, 0, 5, 4, 5, 5, 3, 9, 2, 4, 4, 7, 9, 0, 3, 5, 7, 8, 5, 1, 4, 8, 7, 7,
                   9, 1, 9, 9, 9, 5, 6, 9, 7, 6, 4, 6, 4, 8, 8, 7, 5, 3, 5, 7, 5, 7, 1, 9,
                   7, 9, 4, 7, 9, 5, 1, 4])),
               names=('seeds', 'labels'),
           ),
           metadata={'name': 'node_classification', 'num_classes': 10},)

Loaded link prediction task: OnDiskTask(validation_set=ItemSet(
               items=(tensor([[616, 238],
                   [909, 408],
                   [642, 753],
                   ...,
                   [432, 539],
                   [432, 225],
                   [432, 703]], dtype=torch.int32), tensor([1., 1., 1.,  ..., 0., 0., 0.], dtype=torch.float64), tensor([   0,    1,    2,  ..., 1999, 1999, 1999])),
               names=('seeds', 'labels', 'indexes'),
           ),
           train_set=ItemSet(
               items=(tensor([[427, 810],
                   [482, 156],
                   [739, 383],
                   ...,
                   [898, 150],
                   [ 13,  84],
                   [878, 307]], dtype=torch.int32),),
               names=('seeds',),
           ),
           test_set=ItemSet(
               items=(tensor([[647, 821],
                   [159, 262],
                   [ 43, 294],
                   ...,
                   [183, 119],
                   [183, 117],
                   [183, 553]], dtype=torch.int32), tensor([1., 1., 1.,  ..., 0., 0., 0.], dtype=torch.float64), tensor([   0,    1,    2,  ..., 1999, 1999, 1999])),
               names=('seeds', 'labels', 'indexes'),
           ),
           metadata={'name': 'link_prediction', 'num_classes': 10},)

</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/home/ubuntu/regression_test/dgl/python/dgl/graphbolt/internal/utils.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(path)
/home/ubuntu/regression_test/dgl/python/dgl/graphbolt/impl/ondisk_dataset.py:460: DGLWarning: Edge feature is stored, but edge IDs are not saved.
  dgl_warning("Edge feature is stored, but edge IDs are not saved.")
/home/ubuntu/regression_test/dgl/python/dgl/graphbolt/impl/ondisk_dataset.py:852: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(graph_topology.path)
</pre></div></div>
</div>
</section>
</section>
</div>
</div>
<footer><div aria-label="Footer" class="rst-footer-buttons" role="navigation">
<a accesskey="p" class="btn btn-neutral float-left" href="ondisk-dataset.html" rel="prev" title="Composing OnDiskDataset from raw data"><span aria-hidden="true" class="fa fa-arrow-circle-left"></span> Previous</a>
<a accesskey="n" class="btn btn-neutral float-right" href="ondisk_dataset_heterograph.html" rel="next" title="OnDiskDataset for Heterogeneous Graph">Next <span aria-hidden="true" class="fa fa-arrow-circle-right"></span></a>
</div>
<hr/>
<div role="contentinfo">
<p>© Copyright 2018, DGL Team.</p>
</div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
</div>
</div>
</section>
</div>
<div aria-label="Versions" class="rst-versions" data-toggle="rst-versions" role="note">
<span class="rst-current-version" data-toggle="rst-current-version">
<span class="fa fa-book"> Read the Docs</span>
<span id="version-placeholder">v: latest</span>
<span class="fa fa-caret-down"></span>
</span>
<div class="rst-other-versions">
<dl>
<dt>Versions</dt>
<div id="version-list">
<!-- 动态插入的版本列表将出现在这里 -->
</div>
</dl>
<dl>
<dt>Downloads</dt>
<!-- 下载内容 -->
</dl>
<dl>
<dt>On Read the Docs</dt>
<dd><a href="//doc-build.dgl.ai/projects/dgl/?fromdocs=dgl">Project Home</a></dd>
<dd><a href="//doc-build.dgl.ai/builds/dgl/?fromdocs=dgl">Builds</a></dd>
</dl>
</div>
</div>
<script>
        document.addEventListener("DOMContentLoaded", function() {
            fetch('/dgl_docs/branches.json')
                .then(response => response.json())
                .then(data => {
                    var versionListDiv = document.getElementById('version-list');
                    data.branches.forEach(function(branch) {
                        var dd = document.createElement('dd');
                        var a = document.createElement('a');
                        a.href = branch.url;
                        a.textContent = branch.name;
                        dd.appendChild(a);
                        versionListDiv.appendChild(dd);
                    });
                })
                .catch(error => console.error('Error loading branches:', error));
        });
        document.addEventListener("DOMContentLoaded", function() {
            // 获取当前路径
            var path = window.location.pathname;
            var versionPlaceholder = document.getElementById('version-placeholder');

            // 检查路径中是否包含 'en'
            if (path.includes('/en/')) {
                // 提取 'en' 后的文件夹作为版本号
                var parts = path.split('/en/');
                if (parts[1]) {
                    var folders = parts[1].split('/');
                    if (folders.length > 0 && folders[0]) {
                        versionPlaceholder.textContent = 'v: ' + folders[0];
                    } else {
                        versionPlaceholder.textContent = 'v: latest';
                    }
                } else {
                    versionPlaceholder.textContent = 'v: latest';
                }
            } else {
                versionPlaceholder.textContent = 'v: latest';
            }
        });
    </script>

<script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
</body>
</html>