{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E0DAKDMuWz7I"
   },
   "source": [
    "# Quickstart\n",
    "\n",
    "The tutorial provides a quick walkthrough of the classes and operators provided by the `dgl.sparse` package.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/dmlc/dgl/blob/master/notebooks/sparse/quickstart.ipynb) [![GitHub](https://img.shields.io/badge/-View%20on%20GitHub-181717?logo=github&logoColor=ffffff)](https://github.com/dmlc/dgl/blob/master/notebooks/sparse/quickstart.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T13:15:03.835757Z",
     "iopub.status.busy": "2024-10-08T13:15:03.835346Z",
     "iopub.status.idle": "2024-10-08T13:15:05.744236Z",
     "shell.execute_reply": "2024-10-08T13:15:05.743244Z"
    },
    "id": "19UZd7wyWzpT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DGL installed!\n"
     ]
    }
   ],
   "source": [
    "# Install the required packages.\n",
    "\n",
    "import os\n",
    "# Uncomment following commands to download Pytorch and DGL\n",
    "# !pip install torch==2.0.0+cpu torchvision==0.15.1+cpu torchaudio==2.0.1 --index-url https://download.pytorch.org/whl/cpu > /dev/null\n",
    "# !pip install  dgl==1.1.0 -f https://data.dgl.ai/wheels/repo.html > /dev/null\n",
    "import torch\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "os.environ['DGLBACKEND'] = \"pytorch\"\n",
    "\n",
    "\n",
    "try:\n",
    "    import dgl.sparse as dglsp\n",
    "    installed = True\n",
    "except ImportError:\n",
    "    installed = False\n",
    "print(\"DGL installed!\" if installed else \"DGL not found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GsWoAGC4RpHw"
   },
   "source": [
    "## Sparse Matrix\n",
    "\n",
    "The core abstraction of DGL's sparse package is the `SparseMatrix` class. Compared with other sparse matrix libraries (such as `scipy.sparse` and `torch.sparse`), DGL's `SparseMatrix` is specialized for the deep learning workloads on structure data (e.g., Graph Neural Networks), with the following features:\n",
    "\n",
    "* **Auto sparse format.** Don't bother choosing between different sparse formats. There is only one `SparseMatrix` and it will select the best format for the operation to be performed.\n",
    "* **Non-zero elements can be scalar or vector.** Easy for modeling relations (e.g., edges) by vector representation.\n",
    "* **Fully PyTorch compatible.** The package is built upon PyTorch and is natively compatible with other tools in the PyTorch ecosystem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_q4HYodcWenB"
   },
   "source": [
    "### Creating a DGL Sparse Matrix\n",
    "\n",
    "The simplest way to create a sparse matrix is using the `spmatrix` API by providing the indices of the non-zero elements. The indices are stored in a tensor of shape `(2, nnz)`, where the `i`-th non-zero element is stored at position `(indices[0][i], indices[1][i])`. The code below creates a 3x3 sparse matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T13:15:05.772142Z",
     "iopub.status.busy": "2024-10-08T13:15:05.771689Z",
     "iopub.status.idle": "2024-10-08T13:15:05.781211Z",
     "shell.execute_reply": "2024-10-08T13:15:05.780594Z"
    },
    "id": "h-ryVEs1PuIP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseMatrix(indices=tensor([[1, 1, 2],\n",
      "                             [0, 2, 0]]),\n",
      "             values=tensor([1., 1., 1.]),\n",
      "             shape=(3, 3), nnz=3)\n",
      "\n",
      "In dense format:\n",
      "tensor([[0., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [1., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import dgl.sparse as dglsp\n",
    "\n",
    "i = torch.tensor([[1, 1, 2],\n",
    "                  [0, 2, 0]])\n",
    "A = dglsp.spmatrix(i)  # 1.0 is default value for nnz elements.\n",
    "\n",
    "print(A)\n",
    "print(\"\")\n",
    "print(\"In dense format:\")\n",
    "print(A.to_dense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W1JJg-eZ7K3t"
   },
   "source": [
    "If not specified, the shape is inferred automatically from the indices but you can specify it explicitly too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T13:15:05.782972Z",
     "iopub.status.busy": "2024-10-08T13:15:05.782781Z",
     "iopub.status.idle": "2024-10-08T13:15:05.788302Z",
     "shell.execute_reply": "2024-10-08T13:15:05.787694Z"
    },
    "id": "80NNSQfd7L5V"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Implicit Shape: (2, 3)\n",
      "tensor([[1., 0., 1.],\n",
      "        [1., 0., 0.]])\n",
      "\n",
      "Explicit Shape: (3, 3)\n",
      "tensor([[1., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "i = torch.tensor([[0, 0, 1],\n",
    "                  [0, 2, 0]])\n",
    "\n",
    "A1 = dglsp.spmatrix(i)\n",
    "print(f\"Implicit Shape: {A1.shape}\")\n",
    "print(A1.to_dense())\n",
    "print(\"\")\n",
    "\n",
    "A2 = dglsp.spmatrix(i, shape=(3, 3))\n",
    "print(f\"Explicit Shape: {A2.shape}\")\n",
    "print(A2.to_dense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zdNgUf0ShfCe"
   },
   "source": [
    "Both scalar values and vector values can be set for nnz elements in Sparse Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T13:15:05.790164Z",
     "iopub.status.busy": "2024-10-08T13:15:05.789807Z",
     "iopub.status.idle": "2024-10-08T13:15:05.797239Z",
     "shell.execute_reply": "2024-10-08T13:15:05.796633Z"
    },
    "id": "buE9ZkKvhp1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Scalar Values-----\n",
      "SparseMatrix(indices=tensor([[1, 1, 2],\n",
      "                             [0, 2, 0]]),\n",
      "             values=tensor([1., 2., 3.]),\n",
      "             shape=(3, 3), nnz=3)\n",
      "\n",
      "In dense format:\n",
      "tensor([[0., 0., 0.],\n",
      "        [1., 0., 2.],\n",
      "        [3., 0., 0.]])\n",
      "\n",
      "-----Vector Values-----\n",
      "SparseMatrix(indices=tensor([[1, 1, 2],\n",
      "                             [0, 2, 0]]),\n",
      "             values=tensor([[1., 1.],\n",
      "                            [2., 2.],\n",
      "                            [3., 3.]]),\n",
      "             shape=(3, 3), nnz=3, val_size=(2,))\n",
      "\n",
      "In dense format:\n",
      "tensor([[[0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 1.],\n",
      "         [0., 0.],\n",
      "         [2., 2.]],\n",
      "\n",
      "        [[3., 3.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "i = torch.tensor([[1, 1, 2],\n",
    "                  [0, 2, 0]])\n",
    "# The length of the value should match the nnz elements represented by the\n",
    "# sparse matrix format.\n",
    "scalar_val = torch.tensor([1., 2., 3.])\n",
    "vector_val = torch.tensor([[1., 1.], [2., 2.], [3., 3.]])\n",
    "\n",
    "print(\"-----Scalar Values-----\")\n",
    "A = dglsp.spmatrix(i, scalar_val)\n",
    "print(A)\n",
    "print(\"\")\n",
    "print(\"In dense format:\")\n",
    "print(A.to_dense())\n",
    "print(\"\")\n",
    "\n",
    "print(\"-----Vector Values-----\")\n",
    "A = dglsp.spmatrix(i, vector_val)\n",
    "print(A)\n",
    "print(\"\")\n",
    "print(\"In dense format:\")\n",
    "print(A.to_dense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ufTCDAVsrmP"
   },
   "source": [
    "*Duplicated indices*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T13:15:05.799097Z",
     "iopub.status.busy": "2024-10-08T13:15:05.798742Z",
     "iopub.status.idle": "2024-10-08T13:15:05.804833Z",
     "shell.execute_reply": "2024-10-08T13:15:05.804234Z"
    },
    "id": "ilSAlFLOs0o8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseMatrix(indices=tensor([[0, 0, 0, 1],\n",
      "                             [0, 2, 2, 0]]),\n",
      "             values=tensor([1., 2., 3., 4.]),\n",
      "             shape=(2, 3), nnz=4)\n",
      "Whether A contains duplicate indices: True\n",
      "\n",
      "SparseMatrix(indices=tensor([[0, 0, 1],\n",
      "                             [0, 2, 0]]),\n",
      "             values=tensor([1., 5., 4.]),\n",
      "             shape=(2, 3), nnz=3)\n",
      "Whether B contains duplicate indices: False\n"
     ]
    }
   ],
   "source": [
    "i = torch.tensor([[0, 0, 0, 1],\n",
    "                  [0, 2, 2, 0]])\n",
    "val = torch.tensor([1., 2., 3., 4])\n",
    "A = dglsp.spmatrix(i, val)\n",
    "print(A)\n",
    "print(f\"Whether A contains duplicate indices: {A.has_duplicate()}\")\n",
    "print(\"\")\n",
    "\n",
    "B = A.coalesce()\n",
    "print(B)\n",
    "print(f\"Whether B contains duplicate indices: {B.has_duplicate()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJ09qM5NaxuI"
   },
   "source": [
    "**val_like**\n",
    "\n",
    "You can create a new sparse matrix by retaining the non-zero indices of a given sparse matrix but with different non-zero values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T13:15:05.806640Z",
     "iopub.status.busy": "2024-10-08T13:15:05.806281Z",
     "iopub.status.idle": "2024-10-08T13:15:05.811463Z",
     "shell.execute_reply": "2024-10-08T13:15:05.810830Z"
    },
    "id": "UB3lKJVBbsUD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseMatrix(indices=tensor([[1, 1, 2],\n",
      "                             [0, 2, 0]]),\n",
      "             values=tensor([4., 5., 6.]),\n",
      "             shape=(3, 3), nnz=3)\n"
     ]
    }
   ],
   "source": [
    "i = torch.tensor([[1, 1, 2],\n",
    "                  [0, 2, 0]])\n",
    "val = torch.tensor([1., 2., 3.])\n",
    "A = dglsp.spmatrix(i, val)\n",
    "\n",
    "new_val = torch.tensor([4., 5., 6.])\n",
    "B = dglsp.val_like(A, new_val)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nWjBSFDBXDPJ"
   },
   "source": [
    "**Create a sparse matrix from various sparse formats**\n",
    "\n",
    "*   `from_coo()`: Create a sparse matrix from [COO](https://en.wikipedia.org/wiki/Sparse_matrix#Coordinate_list_(COO)) format.\n",
    "*   `from_csr()`: Create a sparse matrix from [CSR](https://en.wikipedia.org/wiki/Sparse_matrix#Compressed_sparse_row_(CSR,_CRS_or_Yale_format)) format.\n",
    "*   `from_csc()`: Create a sparse matrix from [CSC](https://en.wikipedia.org/wiki/Sparse_matrix#Compressed_sparse_column_(CSC_or_CCS)) format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T13:15:05.813370Z",
     "iopub.status.busy": "2024-10-08T13:15:05.812921Z",
     "iopub.status.idle": "2024-10-08T13:15:05.821607Z",
     "shell.execute_reply": "2024-10-08T13:15:05.821011Z"
    },
    "id": "3puXyMFsvdlj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Create from COO format-----\n",
      "SparseMatrix(indices=tensor([[0, 1, 2, 2, 2],\n",
      "                             [1, 2, 0, 1, 2]]),\n",
      "             values=tensor([1., 1., 1., 1., 1.]),\n",
      "             shape=(3, 3), nnz=5)\n",
      "\n",
      "In dense format:\n",
      "tensor([[0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 1., 1.]])\n",
      "\n",
      "-----Create from CSR format-----\n",
      "SparseMatrix(indices=tensor([[0, 1, 2, 2, 2],\n",
      "                             [1, 2, 0, 1, 2]]),\n",
      "             values=tensor([1., 1., 1., 1., 1.]),\n",
      "             shape=(3, 3), nnz=5)\n",
      "\n",
      "In dense format:\n",
      "tensor([[0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 1., 1.]])\n",
      "\n",
      "-----Create from CSC format-----\n",
      "SparseMatrix(indices=tensor([[1, 2, 0, 1, 2],\n",
      "                             [0, 1, 2, 2, 2]]),\n",
      "             values=tensor([1., 1., 1., 1., 1.]),\n",
      "             shape=(3, 3), nnz=5)\n",
      "\n",
      "In dense format:\n",
      "tensor([[0., 0., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "row = torch.tensor([0, 1, 2, 2, 2])\n",
    "col = torch.tensor([1, 2, 0, 1, 2])\n",
    "\n",
    "print(\"-----Create from COO format-----\")\n",
    "A = dglsp.from_coo(row, col)\n",
    "print(A)\n",
    "print(\"\")\n",
    "print(\"In dense format:\")\n",
    "print(A.to_dense())\n",
    "print(\"\")\n",
    "\n",
    "indptr = torch.tensor([0, 1, 2, 5])\n",
    "indices = torch.tensor([1, 2, 0, 1, 2])\n",
    "\n",
    "print(\"-----Create from CSR format-----\")\n",
    "A = dglsp.from_csr(indptr, indices)\n",
    "print(A)\n",
    "print(\"\")\n",
    "print(\"In dense format:\")\n",
    "print(A.to_dense())\n",
    "print(\"\")\n",
    "\n",
    "print(\"-----Create from CSC format-----\")\n",
    "B = dglsp.from_csc(indptr, indices)\n",
    "print(B)\n",
    "print(\"\")\n",
    "print(\"In dense format:\")\n",
    "print(B.to_dense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nd4hJ9ysd4St"
   },
   "source": [
    "### Attributes and methods of a DGL Sparse Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T13:15:05.823597Z",
     "iopub.status.busy": "2024-10-08T13:15:05.823103Z",
     "iopub.status.idle": "2024-10-08T13:15:05.829663Z",
     "shell.execute_reply": "2024-10-08T13:15:05.829061Z"
    },
    "id": "OKbFiWKIzZVe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of sparse matrix: (3, 3)\n",
      "The number of nonzero elements of sparse matrix: 4\n",
      "Datatype of sparse matrix: torch.float32\n",
      "Device sparse matrix is stored on: cpu\n",
      "Get the values of the nonzero elements: tensor([1., 2., 3., 4.])\n",
      "Get the row indices of the nonzero elements: tensor([0, 1, 1, 2])\n",
      "Get the column indices of the nonzero elements: tensor([1, 0, 2, 0])\n",
      "Get the coordinate (COO) representation: (tensor([0, 1, 1, 2]), tensor([1, 0, 2, 0]))\n",
      "Get the compressed sparse row (CSR) representation: (tensor([0, 1, 3, 4]), tensor([1, 0, 2, 0]), tensor([0, 1, 2, 3]))\n",
      "Get the compressed sparse column (CSC) representation: (tensor([0, 2, 3, 4]), tensor([1, 2, 0, 1]), tensor([1, 3, 0, 2]))\n"
     ]
    }
   ],
   "source": [
    "i = torch.tensor([[0, 1, 1, 2],\n",
    "                  [1, 0, 2, 0]])\n",
    "val = torch.tensor([1., 2., 3., 4.])\n",
    "A = dglsp.spmatrix(i, val)\n",
    "\n",
    "print(f\"Shape of sparse matrix: {A.shape}\")\n",
    "print(f\"The number of nonzero elements of sparse matrix: {A.nnz}\")\n",
    "print(f\"Datatype of sparse matrix: {A.dtype}\")\n",
    "print(f\"Device sparse matrix is stored on: {A.device}\")\n",
    "print(f\"Get the values of the nonzero elements: {A.val}\")\n",
    "print(f\"Get the row indices of the nonzero elements: {A.row}\")\n",
    "print(f\"Get the column indices of the nonzero elements: {A.col}\")\n",
    "print(f\"Get the coordinate (COO) representation: {A.coo()}\")\n",
    "print(f\"Get the compressed sparse row (CSR) representation: {A.csr()}\")\n",
    "print(f\"Get the compressed sparse column (CSC) representation: {A.csc()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VzosM7i3yQPK"
   },
   "source": [
    "**dtype and/or device conversion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T13:15:05.831421Z",
     "iopub.status.busy": "2024-10-08T13:15:05.831150Z",
     "iopub.status.idle": "2024-10-08T13:15:05.835822Z",
     "shell.execute_reply": "2024-10-08T13:15:05.835195Z"
    },
    "id": "y_RJihw-ypXp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device sparse matrix is stored on: cpu\n",
      "Datatype of sparse matrix: torch.int32\n"
     ]
    }
   ],
   "source": [
    "i = torch.tensor([[0, 1, 1, 2],\n",
    "                  [1, 0, 2, 0]])\n",
    "val = torch.tensor([1., 2., 3., 4.])\n",
    "A = dglsp.spmatrix(i, val)\n",
    "\n",
    "B = A.to(device='cpu', dtype=torch.int32)\n",
    "print(f\"Device sparse matrix is stored on: {B.device}\")\n",
    "print(f\"Datatype of sparse matrix: {B.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U26arLlJzfkN"
   },
   "source": [
    "Similar to pytorch, we also provide various fine-grained APIs ([Doc](https://docs.dgl.ai/en/latest/api/python/dgl.sparse_v0.html)) for dtype and/or device conversion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EFe9ABRuWHqf"
   },
   "source": [
    "## Diagonal Matrix\n",
    "\n",
    "Diagonal Matrix is a special type of Sparse Matrix, in which the entries outside the main diagonal are all zero.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1CeCoE2Fgl_x"
   },
   "source": [
    "### Initializing a DGL Diagonal Sparse Matrix\n",
    "A DGL Diagonal Sparse Matrix can be initiate by `dglsp.diag()`.\n",
    "\n",
    "Identity Matrix is a special type of Diagonal Sparse Matrix, in which all the value on the diagonal are 1.0. Use `dglsp.identity()` to initiate a Diagonal Sparse Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T13:15:05.837518Z",
     "iopub.status.busy": "2024-10-08T13:15:05.837332Z",
     "iopub.status.idle": "2024-10-08T13:15:05.842337Z",
     "shell.execute_reply": "2024-10-08T13:15:05.841734Z"
    },
    "id": "9wzJNApahXAR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseMatrix(indices=tensor([[0, 1, 2, 3],\n",
      "                             [0, 1, 2, 3]]),\n",
      "             values=tensor([1., 2., 3., 4.]),\n",
      "             shape=(4, 4), nnz=4)\n",
      "SparseMatrix(indices=tensor([[0, 1, 2],\n",
      "                             [0, 1, 2]]),\n",
      "             values=tensor([1., 1., 1.]),\n",
      "             shape=(3, 3), nnz=3)\n"
     ]
    }
   ],
   "source": [
    "val = torch.tensor([1., 2., 3., 4.])\n",
    "D = dglsp.diag(val)\n",
    "print(D)\n",
    "\n",
    "I = dglsp.identity(shape=(3, 3))\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tjsapqp6zSFR"
   },
   "source": [
    "## Operations on Sparse Matrix\n",
    "*   Elementwise operations\n",
    "    *   `A + B`\n",
    "    *   `A - B`\n",
    "    *   `A * B`\n",
    "    *   `A / B`\n",
    "    *   `A ** scalar`\n",
    "*   Broadcast operations\n",
    "    *   `sp_<op>_v()`\n",
    "*   Reduce operations\n",
    "    *   `reduce()`\n",
    "    *   `sum()`\n",
    "    *   `smax()`\n",
    "    *   `smin()`\n",
    "    *   `smean()`\n",
    "*   Matrix transformations\n",
    "    *   `SparseMatrix.transpose()` or `SparseMatrix.T`\n",
    "    *   `SparseMatrix.neg()`\n",
    "    *   `SparseMatrix.inv()`\n",
    "*   Matrix multiplication\n",
    "    *   `matmul()`\n",
    "    *   `sddmm()`\n",
    "\n",
    "\n",
    "*We are using dense format to print sparse matrix in this tutorial since it is more intuitive to read.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "psvGwcIqYvC2"
   },
   "source": [
    "### *Elementwise operations*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "39YJitpW-K9v"
   },
   "source": [
    "**add(A, B), equivalent to A + B**\n",
    "\n",
    "Element-wise addition on two sparse matrices, returning a sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T13:15:05.844376Z",
     "iopub.status.busy": "2024-10-08T13:15:05.843927Z",
     "iopub.status.idle": "2024-10-08T13:15:05.853627Z",
     "shell.execute_reply": "2024-10-08T13:15:05.853026Z"
    },
    "id": "pj3Ckx41-BSu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1:\n",
      "tensor([[0., 0., 0.],\n",
      "        [1., 0., 2.],\n",
      "        [3., 0., 0.]])\n",
      "A2:\n",
      "tensor([[4., 0., 0.],\n",
      "        [0., 0., 5.],\n",
      "        [0., 6., 0.]])\n",
      "D1:\n",
      "tensor([[-1.,  0.,  0.],\n",
      "        [ 0., -2.,  0.],\n",
      "        [ 0.,  0., -3.]])\n",
      "D2:\n",
      "tensor([[-4.,  0.,  0.],\n",
      "        [ 0., -5.,  0.],\n",
      "        [ 0.,  0., -6.]])\n",
      "A1 + A2:\n",
      "tensor([[4., 0., 0.],\n",
      "        [1., 0., 7.],\n",
      "        [3., 6., 0.]])\n",
      "A1 + D1:\n",
      "tensor([[-1.,  0.,  0.],\n",
      "        [ 1., -2.,  2.],\n",
      "        [ 3.,  0., -3.]])\n",
      "D1 + D2:\n",
      "tensor([[-5.,  0.,  0.],\n",
      "        [ 0., -7.,  0.],\n",
      "        [ 0.,  0., -9.]])\n"
     ]
    }
   ],
   "source": [
    "i = torch.tensor([[1, 1, 2],\n",
    "                  [0, 2, 0]])\n",
    "val = torch.tensor([1., 2., 3.])\n",
    "A1 = dglsp.spmatrix(i, val, shape=(3, 3))\n",
    "print(\"A1:\")\n",
    "print(A1.to_dense())\n",
    "\n",
    "i = torch.tensor([[0, 1, 2],\n",
    "                  [0, 2, 1]])\n",
    "val = torch.tensor([4., 5., 6.])\n",
    "A2 = dglsp.spmatrix(i, val, shape=(3, 3))\n",
    "print(\"A2:\")\n",
    "print(A2.to_dense())\n",
    "\n",
    "val = torch.tensor([-1., -2., -3.])\n",
    "D1 = dglsp.diag(val)\n",
    "print(\"D1:\")\n",
    "print(D1.to_dense())\n",
    "\n",
    "val = torch.tensor([-4., -5., -6.])\n",
    "D2 = dglsp.diag(val)\n",
    "print(\"D2:\")\n",
    "print(D2.to_dense())\n",
    "\n",
    "print(\"A1 + A2:\")\n",
    "print((A1 + A2).to_dense())\n",
    "\n",
    "print(\"A1 + D1:\")\n",
    "print((A1 + D1).to_dense())\n",
    "\n",
    "print(\"D1 + D2:\")\n",
    "print((D1 + D2).to_dense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i25N0JHUTUX9"
   },
   "source": [
    "**sub(A, B), equivalent to A - B**\n",
    "\n",
    "Element-wise substraction on two sparse matrices, returning a sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T13:15:05.855526Z",
     "iopub.status.busy": "2024-10-08T13:15:05.855060Z",
     "iopub.status.idle": "2024-10-08T13:15:05.865530Z",
     "shell.execute_reply": "2024-10-08T13:15:05.864922Z"
    },
    "id": "GMxfz-cyT129"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1:\n",
      "tensor([[0., 0., 0.],\n",
      "        [1., 0., 2.],\n",
      "        [3., 0., 0.]])\n",
      "A2:\n",
      "tensor([[4., 0., 0.],\n",
      "        [0., 0., 5.],\n",
      "        [0., 6., 0.]])\n",
      "D1:\n",
      "tensor([[-1.,  0.,  0.],\n",
      "        [ 0., -2.,  0.],\n",
      "        [ 0.,  0., -3.]])\n",
      "D2:\n",
      "tensor([[-4.,  0.,  0.],\n",
      "        [ 0., -5.,  0.],\n",
      "        [ 0.,  0., -6.]])\n",
      "A1 - A2:\n",
      "tensor([[-4.,  0.,  0.],\n",
      "        [ 1.,  0., -3.],\n",
      "        [ 3., -6.,  0.]])\n",
      "A1 - D1:\n",
      "tensor([[1., 0., 0.],\n",
      "        [1., 2., 2.],\n",
      "        [3., 0., 3.]])\n",
      "D1 - A1:\n",
      "tensor([[-1.,  0.,  0.],\n",
      "        [-1., -2., -2.],\n",
      "        [-3.,  0., -3.]])\n",
      "D1 - D2:\n",
      "tensor([[3., 0., 0.],\n",
      "        [0., 3., 0.],\n",
      "        [0., 0., 3.]])\n"
     ]
    }
   ],
   "source": [
    "i = torch.tensor([[1, 1, 2],\n",
    "                  [0, 2, 0]])\n",
    "val = torch.tensor([1., 2., 3.])\n",
    "A1 = dglsp.spmatrix(i, val, shape=(3, 3))\n",
    "print(\"A1:\")\n",
    "print(A1.to_dense())\n",
    "\n",
    "i = torch.tensor([[0, 1, 2],\n",
    "                  [0, 2, 1]])\n",
    "val = torch.tensor([4., 5., 6.])\n",
    "A2 = dglsp.spmatrix(i, val, shape=(3, 3))\n",
    "print(\"A2:\")\n",
    "print(A2.to_dense())\n",
    "\n",
    "val = torch.tensor([-1., -2., -3.])\n",
    "D1 = dglsp.diag(val)\n",
    "print(\"D1:\")\n",
    "print(D1.to_dense())\n",
    "\n",
    "val = torch.tensor([-4., -5., -6.])\n",
    "D2 = dglsp.diag(val)\n",
    "print(\"D2:\")\n",
    "print(D2.to_dense())\n",
    "\n",
    "print(\"A1 - A2:\")\n",
    "print((A1 - A2).to_dense())\n",
    "\n",
    "print(\"A1 - D1:\")\n",
    "print((A1 - D1).to_dense())\n",
    "\n",
    "print(\"D1 - A1:\")\n",
    "print((D1 - A1).to_dense())\n",
    "\n",
    "print(\"D1 - D2:\")\n",
    "print((D1 - D2).to_dense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bg45jnq8T9EJ"
   },
   "source": [
    "**mul(A, B), equivalent to A * B**\n",
    "\n",
    "Element-wise multiplication on two sparse matrices or on a sparse matrix and a scalar, returning a sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T13:15:05.867507Z",
     "iopub.status.busy": "2024-10-08T13:15:05.867029Z",
     "iopub.status.idle": "2024-10-08T13:15:05.879785Z",
     "shell.execute_reply": "2024-10-08T13:15:05.879156Z"
    },
    "id": "4PAITJqHUB8J"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1:\n",
      "tensor([[0., 0., 0.],\n",
      "        [1., 0., 2.],\n",
      "        [3., 0., 0.]])\n",
      "A2:\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 0., 2.],\n",
      "        [3., 4., 0.]])\n",
      "A1 * 3:\n",
      "tensor([[0., 0., 0.],\n",
      "        [3., 0., 6.],\n",
      "        [9., 0., 0.]])\n",
      "3 * A1:\n",
      "tensor([[0., 0., 0.],\n",
      "        [3., 0., 6.],\n",
      "        [9., 0., 0.]])\n",
      "A1 * A2\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 4.],\n",
      "        [9., 0., 0.]])\n",
      "D1:\n",
      "tensor([[-1.,  0.,  0.],\n",
      "        [ 0., -2.,  0.],\n",
      "        [ 0.,  0., -3.]])\n",
      "D1 * A2\n",
      "tensor([[-1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.]])\n",
      "D2:\n",
      "tensor([[-4.,  0.,  0.],\n",
      "        [ 0., -5.,  0.],\n",
      "        [ 0.,  0., -6.]])\n",
      "D1 * -2:\n",
      "tensor([[2., 0., 0.],\n",
      "        [0., 4., 0.],\n",
      "        [0., 0., 6.]])\n",
      "-2 * D1:\n",
      "tensor([[2., 0., 0.],\n",
      "        [0., 4., 0.],\n",
      "        [0., 0., 6.]])\n",
      "D1 * D2:\n",
      "tensor([[ 4.,  0.,  0.],\n",
      "        [ 0., 10.,  0.],\n",
      "        [ 0.,  0., 18.]])\n"
     ]
    }
   ],
   "source": [
    "i = torch.tensor([[1, 1, 2],\n",
    "                  [0, 2, 0]])\n",
    "val = torch.tensor([1., 2., 3.])\n",
    "A1 = dglsp.spmatrix(i, val, shape=(3, 3))\n",
    "print(\"A1:\")\n",
    "print(A1.to_dense())\n",
    "\n",
    "i = torch.tensor([[0, 1, 2, 2],\n",
    "                  [0, 2, 0, 1]])\n",
    "val = torch.tensor([1., 2., 3., 4.])\n",
    "A2 = dglsp.spmatrix(i, val, shape=(3, 3))\n",
    "\n",
    "print(\"A2:\")\n",
    "print(A2.to_dense())\n",
    "\n",
    "print(\"A1 * 3:\")\n",
    "print((A1 * 3).to_dense())\n",
    "print(\"3 * A1:\")\n",
    "print((3 * A1).to_dense())\n",
    "\n",
    "print(\"A1 * A2\")\n",
    "print((A1 * A2).to_dense())\n",
    "\n",
    "val = torch.tensor([-1., -2., -3.])\n",
    "D1 = dglsp.diag(val)\n",
    "print(\"D1:\")\n",
    "print(D1.to_dense())\n",
    "\n",
    "print(\"D1 * A2\")\n",
    "print((D1 * A2).to_dense())\n",
    "\n",
    "val = torch.tensor([-4., -5., -6.])\n",
    "D2 = dglsp.diag(val)\n",
    "print(\"D2:\")\n",
    "print(D2.to_dense())\n",
    "\n",
    "print(\"D1 * -2:\")\n",
    "print((D1 * -2).to_dense())\n",
    "print(\"-2 * D1:\")\n",
    "print((-2 * D1).to_dense())\n",
    "\n",
    "print(\"D1 * D2:\")\n",
    "print((D1 * D2).to_dense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xb2RU6H4UBCs"
   },
   "source": [
    "**div(A, B), equivalent to A / B**\n",
    "\n",
    "Element-wise multiplication on two sparse matrices or on a sparse matrix and a scalar, returning a sparse matrix. If both `A` and `B` are sparse matrices, both of them must have the same sparsity. And the returned matrix has the same order of non-zero entries as `A`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T13:15:05.881770Z",
     "iopub.status.busy": "2024-10-08T13:15:05.881314Z",
     "iopub.status.idle": "2024-10-08T13:15:05.891015Z",
     "shell.execute_reply": "2024-10-08T13:15:05.890414Z"
    },
    "id": "TFB_UcmEUdr3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1:\n",
      "tensor([[0., 0., 0.],\n",
      "        [1., 0., 2.],\n",
      "        [3., 0., 0.]])\n",
      "A1 / 2:\n",
      "tensor([[0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.0000, 1.0000],\n",
      "        [1.5000, 0.0000, 0.0000]])\n",
      "A1 / A2\n",
      "tensor([[0., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [1., 0., 0.]])\n",
      "D1:\n",
      "tensor([[-1.,  0.,  0.],\n",
      "        [ 0., -2.,  0.],\n",
      "        [ 0.,  0., -3.]])\n",
      "D2:\n",
      "tensor([[-4.,  0.,  0.],\n",
      "        [ 0., -5.,  0.],\n",
      "        [ 0.,  0., -6.]])\n",
      "D1 / D2:\n",
      "tensor([[0.2500, 0.0000, 0.0000],\n",
      "        [0.0000, 0.4000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.5000]])\n",
      "D1 / 2:\n",
      "tensor([[-0.5000,  0.0000,  0.0000],\n",
      "        [ 0.0000, -1.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000, -1.5000]])\n"
     ]
    }
   ],
   "source": [
    "i = torch.tensor([[1, 1, 2],\n",
    "                  [0, 2, 0]])\n",
    "val = torch.tensor([1., 2., 3.])\n",
    "A1 = dglsp.spmatrix(i, val, shape=(3, 3))\n",
    "print(\"A1:\")\n",
    "print(A1.to_dense())\n",
    "\n",
    "i = torch.tensor([[1, 2, 1],\n",
    "                  [0, 0, 2]])\n",
    "val = torch.tensor([1., 3., 2.])\n",
    "A2 = dglsp.spmatrix(i, val, shape=(3, 3))\n",
    "\n",
    "print(\"A1 / 2:\")\n",
    "print((A1 / 2).to_dense())\n",
    "\n",
    "print(\"A1 / A2\")\n",
    "print((A1 / A2).to_dense())\n",
    "\n",
    "val = torch.tensor([-1., -2., -3.])\n",
    "D1 = dglsp.diag(val)\n",
    "print(\"D1:\")\n",
    "print(D1.to_dense())\n",
    "\n",
    "val = torch.tensor([-4., -5., -6.])\n",
    "D2 = dglsp.diag(val)\n",
    "print(\"D2:\")\n",
    "print(D2.to_dense())\n",
    "\n",
    "print(\"D1 / D2:\")\n",
    "print((D1 / D2).to_dense())\n",
    "\n",
    "print(\"D1 / 2:\")\n",
    "print((D1 / 2).to_dense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2lZbyTYUUgSi"
   },
   "source": [
    "**power(A, B), equivalent to A \\*\\* B**\n",
    "\n",
    "Element-wise power of a sparse matrix and a scalar, returning a sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T13:15:05.893150Z",
     "iopub.status.busy": "2024-10-08T13:15:05.892562Z",
     "iopub.status.idle": "2024-10-08T13:15:05.899610Z",
     "shell.execute_reply": "2024-10-08T13:15:05.898971Z"
    },
    "id": "ox-XxCnuUqAy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      "tensor([[0., 0., 0.],\n",
      "        [1., 0., 2.],\n",
      "        [3., 0., 0.]])\n",
      "A ** 3:\n",
      "tensor([[ 0.,  0.,  0.],\n",
      "        [ 1.,  0.,  8.],\n",
      "        [27.,  0.,  0.]])\n",
      "D:\n",
      "tensor([[-1.,  0.,  0.],\n",
      "        [ 0., -2.,  0.],\n",
      "        [ 0.,  0., -3.]])\n",
      "D1 ** 2:\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 4., 0.],\n",
      "        [0., 0., 9.]])\n"
     ]
    }
   ],
   "source": [
    "i = torch.tensor([[1, 1, 2],\n",
    "                  [0, 2, 0]])\n",
    "val = torch.tensor([1., 2., 3.])\n",
    "A = dglsp.spmatrix(i, val, shape=(3, 3))\n",
    "print(\"A:\")\n",
    "print(A.to_dense())\n",
    "\n",
    "print(\"A ** 3:\")\n",
    "print((A ** 3).to_dense())\n",
    "\n",
    "val = torch.tensor([-1., -2., -3.])\n",
    "D = dglsp.diag(val)\n",
    "print(\"D:\")\n",
    "print(D.to_dense())\n",
    "\n",
    "print(\"D1 ** 2:\")\n",
    "print((D1 ** 2).to_dense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VXBz4j5x_wQ4"
   },
   "source": [
    "### *Broadcast operations*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PtnyZdXHAZ6Z"
   },
   "source": [
    "**sp_\\<op\\>_v(A, v)**\n",
    "\n",
    "Broadcast operations on a sparse matrix and a vector, returning a sparse matrix. `v` is broadcasted to the shape of `A` and then the operator is applied on the non-zero values of `A`. `<op>` can be add, sub, mul, and div. \n",
    "\n",
    "There are two cases regarding the shape of `v`:\n",
    "\n",
    "1. `v` is a vector of shape `(1, A.shape[1])` or `(A.shape[1])`. In this case, `v` is broadcasted on the row dimension of `A`.\n",
    "\n",
    "2. `v` is a vector of shape `(A.shape[0], 1)`. In this case, `v` is broadcasted on the column dimension of `A`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T13:15:05.901526Z",
     "iopub.status.busy": "2024-10-08T13:15:05.901136Z",
     "iopub.status.idle": "2024-10-08T13:15:05.909151Z",
     "shell.execute_reply": "2024-10-08T13:15:05.908555Z"
    },
    "id": "xxf3s-uWBRR7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      "tensor([[ 0,  0,  0, 20],\n",
      "        [10,  0,  0,  0],\n",
      "        [ 0,  0, 30,  0]])\n",
      "v1:\n",
      "tensor([1, 2, 3, 4])\n",
      "sp_add_v(A, v1)\n",
      "tensor([[ 0,  0,  0, 24],\n",
      "        [11,  0,  0,  0],\n",
      "        [ 0,  0, 33,  0]])\n",
      "v2:\n",
      "tensor([[1, 2, 3, 4]])\n",
      "sp_add_v(A, v2)\n",
      "tensor([[ 0,  0,  0, 24],\n",
      "        [11,  0,  0,  0],\n",
      "        [ 0,  0, 33,  0]])\n",
      "v3:\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n",
      "sp_add_v(A, v3)\n",
      "tensor([[ 0,  0,  0, 21],\n",
      "        [12,  0,  0,  0],\n",
      "        [ 0,  0, 33,  0]])\n"
     ]
    }
   ],
   "source": [
    "i = torch.tensor([[1, 0, 2], [0, 3, 2]])\n",
    "val = torch.tensor([10, 20, 30])\n",
    "A = dglsp.spmatrix(i, val, shape=(3, 4))\n",
    "\n",
    "v1 = torch.tensor([1, 2, 3, 4])\n",
    "print(\"A:\")\n",
    "print(A.to_dense())\n",
    "\n",
    "print(\"v1:\")\n",
    "print(v1)\n",
    "\n",
    "print(\"sp_add_v(A, v1)\")\n",
    "print(dglsp.sp_add_v(A, v1).to_dense())\n",
    "\n",
    "v2 = v1.reshape(1, -1)\n",
    "print(\"v2:\")\n",
    "print(v2)\n",
    "\n",
    "print(\"sp_add_v(A, v2)\")\n",
    "print(dglsp.sp_add_v(A, v2).to_dense())\n",
    "\n",
    "v3 = torch.tensor([1, 2, 3]).reshape(-1, 1)\n",
    "print(\"v3:\")\n",
    "print(v3)\n",
    "\n",
    "print(\"sp_add_v(A, v3)\")\n",
    "print(dglsp.sp_add_v(A, v3).to_dense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TQJJlctZjYPv"
   },
   "source": [
    "### *Reduce operations*\n",
    "\n",
    "All DGL sparse reduce operations only consider non-zero elements. To distinguish them from dense PyTorch reduce operations that consider zero elements, we use name `smax`, `smin` and `smean` (`s` stands for sparse)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T13:15:05.911083Z",
     "iopub.status.busy": "2024-10-08T13:15:05.910639Z",
     "iopub.status.idle": "2024-10-08T13:15:05.918946Z",
     "shell.execute_reply": "2024-10-08T13:15:05.918339Z"
    },
    "id": "GhS49Js1jW4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 2., 4.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 3., 0.]])\n",
      "\n",
      "Reduce with reducer:sum along dim = 0:\n",
      "tensor([6., 1., 3.])\n",
      "\n",
      "Reduce with reducer:max along dim = 0:\n",
      "tensor([4., 1., 3.])\n",
      "\n",
      "Reduce with reducer:min along dim = 0:\n",
      "tensor([2., 1., 3.])\n",
      "\n",
      "Reduce with reducer:smean along dim = 0:\n",
      "tensor([3., 1., 3.])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = torch.tensor([[0, 1, 1, 2],\n",
    "                  [1, 0, 2, 0]])\n",
    "val = torch.tensor([1., 2., 3., 4.])\n",
    "A = dglsp.spmatrix(i, val)\n",
    "print(A.T.to_dense())\n",
    "print(\"\")\n",
    "\n",
    "# O1, O2 will have the same value.\n",
    "O1 = A.reduce(0, 'sum')\n",
    "O2 = A.sum(0)\n",
    "print(\"Reduce with reducer:sum along dim = 0:\")\n",
    "print(O1)\n",
    "print(\"\")\n",
    "\n",
    "# O3, O4 will have the same value.\n",
    "O3 = A.reduce(0, 'smax')\n",
    "O4 = A.smax(0)\n",
    "print(\"Reduce with reducer:max along dim = 0:\")\n",
    "print(O3)\n",
    "print(\"\")\n",
    "\n",
    "# O5, O6 will have the same value.\n",
    "O5 = A.reduce(0, 'smin')\n",
    "O6 = A.smin(0)\n",
    "print(\"Reduce with reducer:min along dim = 0:\")\n",
    "print(O5)\n",
    "print(\"\")\n",
    "\n",
    "# O7, O8 will have the same value.\n",
    "O7 = A.reduce(0, 'smean')\n",
    "O8 = A.smean(0)\n",
    "print(\"Reduce with reducer:smean along dim = 0:\")\n",
    "print(O7)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kanwnB7LOQui"
   },
   "source": [
    "### *Matrix transformations*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NiiXso9elM2p"
   },
   "source": [
    "*Sparse Matrix*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T13:15:05.920896Z",
     "iopub.status.busy": "2024-10-08T13:15:05.920451Z",
     "iopub.status.idle": "2024-10-08T13:15:05.926483Z",
     "shell.execute_reply": "2024-10-08T13:15:05.925886Z"
    },
    "id": "qJcmZHmf-oTY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 0.],\n",
      "        [2., 0., 3.],\n",
      "        [4., 0., 0.]])\n",
      "\n",
      "Get transpose of sparse matrix.\n",
      "tensor([[0., 2., 4.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 3., 0.]])\n",
      "\n",
      "Get a sparse matrix with the negation of the original nonzero values.\n",
      "tensor([[ 0., -1.,  0.],\n",
      "        [-2.,  0., -3.],\n",
      "        [-4.,  0.,  0.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = torch.tensor([[0, 1, 1, 2],\n",
    "                  [1, 0, 2, 0]])\n",
    "val = torch.tensor([1., 2., 3., 4.])\n",
    "A = dglsp.spmatrix(i, val)\n",
    "print(A.to_dense())\n",
    "print(\"\")\n",
    "\n",
    "print(\"Get transpose of sparse matrix.\")\n",
    "print(A.T.to_dense())\n",
    "# Alias\n",
    "# A.transpose()\n",
    "# A.t()\n",
    "print(\"\")\n",
    "\n",
    "print(\"Get a sparse matrix with the negation of the original nonzero values.\")\n",
    "print(A.neg().to_dense())\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4uQlDFb0Uzto"
   },
   "source": [
    "### *Matrix multiplication*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THWE30v6WpAk"
   },
   "source": [
    "**matmul(A, B), equivalent to A @ B**\n",
    "\n",
    "Matrix multiplication on sparse matrices and/or dense matrix. There are two cases as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VxyykR-vX7lF"
   },
   "source": [
    "**SparseMatrix @ SparseMatrix -> SparseMatrix:**\n",
    "\n",
    "For a $L \\times M$ sparse matrix A and a $M \\times N$ sparse matrix B, the shape of `A @ B` will be $L \\times N$ sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T13:15:05.928474Z",
     "iopub.status.busy": "2024-10-08T13:15:05.928023Z",
     "iopub.status.idle": "2024-10-08T13:15:05.938416Z",
     "shell.execute_reply": "2024-10-08T13:15:05.937816Z"
    },
    "id": "XRDFC2rOYQM4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1:\n",
      "tensor([[0., 0., 0.],\n",
      "        [1., 0., 2.],\n",
      "        [3., 0., 0.]])\n",
      "A2:\n",
      "tensor([[4., 0., 0.],\n",
      "        [0., 0., 5.],\n",
      "        [0., 6., 0.]])\n",
      "D1:\n",
      "tensor([[-1.,  0.,  0.],\n",
      "        [ 0., -2.,  0.],\n",
      "        [ 0.,  0., -3.]])\n",
      "D2:\n",
      "tensor([[-4.,  0.,  0.],\n",
      "        [ 0., -5.,  0.],\n",
      "        [ 0.,  0., -6.]])\n",
      "A1 @ A2:\n",
      "tensor([[ 0.,  0.,  0.],\n",
      "        [ 4., 12.,  0.],\n",
      "        [12.,  0.,  0.]])\n",
      "A1 @ D1:\n",
      "tensor([[ 0.,  0.,  0.],\n",
      "        [-1.,  0., -6.],\n",
      "        [-3.,  0.,  0.]])\n",
      "D1 @ A1:\n",
      "tensor([[ 0.,  0.,  0.],\n",
      "        [-2.,  0., -4.],\n",
      "        [-9.,  0.,  0.]])\n",
      "D1 @ D2:\n",
      "tensor([[ 4.,  0.,  0.],\n",
      "        [ 0., 10.,  0.],\n",
      "        [ 0.,  0., 18.]])\n"
     ]
    }
   ],
   "source": [
    "i = torch.tensor([[1, 1, 2],\n",
    "                  [0, 2, 0]])\n",
    "val = torch.tensor([1., 2., 3.])\n",
    "A1 = dglsp.spmatrix(i, val, shape=(3, 3))\n",
    "print(\"A1:\")\n",
    "print(A1.to_dense())\n",
    "\n",
    "i = torch.tensor([[0, 1, 2],\n",
    "                  [0, 2, 1]])\n",
    "val = torch.tensor([4., 5., 6.])\n",
    "A2 = dglsp.spmatrix(i, val, shape=(3, 3))\n",
    "print(\"A2:\")\n",
    "print(A2.to_dense())\n",
    "\n",
    "val = torch.tensor([-1., -2., -3.])\n",
    "D1 = dglsp.diag(val)\n",
    "print(\"D1:\")\n",
    "print(D1.to_dense())\n",
    "\n",
    "val = torch.tensor([-4., -5., -6.])\n",
    "D2 = dglsp.diag(val)\n",
    "print(\"D2:\")\n",
    "print(D2.to_dense())\n",
    "\n",
    "print(\"A1 @ A2:\")\n",
    "print((A1 @ A2).to_dense())\n",
    "\n",
    "print(\"A1 @ D1:\")\n",
    "print((A1 @ D1).to_dense())\n",
    "\n",
    "print(\"D1 @ A1:\")\n",
    "print((D1 @ A1).to_dense())\n",
    "\n",
    "print(\"D1 @ D2:\")\n",
    "print((D1 @ D2).to_dense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g13fG8nvaVOt"
   },
   "source": [
    "**SparseMatrix @ Tensor -> Tensor:**\n",
    "\n",
    "For a $L \\times M$ sparse matrix A and a $M \\times N$ dense matrix B, the shape of `A @ B` will be $L \\times N$ dense matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T13:15:05.940503Z",
     "iopub.status.busy": "2024-10-08T13:15:05.940051Z",
     "iopub.status.idle": "2024-10-08T13:15:05.948144Z",
     "shell.execute_reply": "2024-10-08T13:15:05.947489Z"
    },
    "id": "FcQ-CnqdlgWF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [1., 0., 2.],\n",
      "        [3., 0., 0.]])\n",
      "D:\n",
      "tensor([[-1.,  0.,  0.],\n",
      "        [ 0., -2.,  0.],\n",
      "        [ 0.,  0., -3.]])\n",
      "X:\n",
      "tensor([[11., 22.],\n",
      "        [33., 44.],\n",
      "        [55., 66.]])\n",
      "A @ X:\n",
      "tensor([[  0.,   0.],\n",
      "        [121., 154.],\n",
      "        [ 33.,  66.]])\n",
      "D @ X:\n",
      "tensor([[ -11.,  -22.],\n",
      "        [ -66.,  -88.],\n",
      "        [-165., -198.]])\n"
     ]
    }
   ],
   "source": [
    "i = torch.tensor([[1, 1, 2],\n",
    "                  [0, 2, 0]])\n",
    "val = torch.tensor([1., 2., 3.])\n",
    "A = dglsp.spmatrix(i, val, shape=(3, 3))\n",
    "print(\"A:\")\n",
    "print(A.to_dense())\n",
    "\n",
    "val = torch.tensor([-1., -2., -3.])\n",
    "D = dglsp.diag(val)\n",
    "print(\"D:\")\n",
    "print(D.to_dense())\n",
    "\n",
    "X = torch.tensor([[11., 22.], [33., 44.], [55., 66.]])\n",
    "print(\"X:\")\n",
    "print(X)\n",
    "\n",
    "print(\"A @ X:\")\n",
    "print(A @ X)\n",
    "\n",
    "print(\"D @ X:\")\n",
    "print(D @ X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_KZiULLbmEZE"
   },
   "source": [
    "This operator also supports batched sparse-dense matrix multiplication. The sparse matrix A should have shape $L \\times M$, where the non-zero values are vectors of length $K$. The dense matrix B should have shape $M \\times N \\times K$. The output is a dense matrix of shape $L \\times N \\times K$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T13:15:05.950120Z",
     "iopub.status.busy": "2024-10-08T13:15:05.949671Z",
     "iopub.status.idle": "2024-10-08T13:15:05.956378Z",
     "shell.execute_reply": "2024-10-08T13:15:05.955733Z"
    },
    "id": "ZUzXQk7Ab2wG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      "tensor([[[0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 1.],\n",
      "         [0., 0.],\n",
      "         [2., 2.]],\n",
      "\n",
      "        [[3., 3.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]]])\n",
      "X:\n",
      "tensor([[[1., 1.],\n",
      "         [1., 2.]],\n",
      "\n",
      "        [[1., 3.],\n",
      "         [1., 4.]],\n",
      "\n",
      "        [[1., 5.],\n",
      "         [1., 6.]]])\n",
      "A @ X:\n",
      "tensor([[[ 0.,  0.],\n",
      "         [ 0.,  0.]],\n",
      "\n",
      "        [[ 3., 11.],\n",
      "         [ 3., 14.]],\n",
      "\n",
      "        [[ 3.,  3.],\n",
      "         [ 3.,  6.]]])\n"
     ]
    }
   ],
   "source": [
    "i = torch.tensor([[1, 1, 2],\n",
    "                  [0, 2, 0]])\n",
    "val = torch.tensor([[1., 1.], [2., 2.], [3., 3.]])\n",
    "A = dglsp.spmatrix(i, val, shape=(3, 3))\n",
    "print(\"A:\")\n",
    "print(A.to_dense())\n",
    "\n",
    "X = torch.tensor([[[1., 1.], [1., 2.]],\n",
    "                  [[1., 3.], [1., 4.]],\n",
    "                  [[1., 5.], [1., 6.]]])\n",
    "print(\"X:\")\n",
    "print(X)\n",
    "\n",
    "print(\"A @ X:\")\n",
    "print(A @ X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qO_8f_vhPKtf"
   },
   "source": [
    "**Sampled-Dense-Dense Matrix Multiplication (SDDMM)**\n",
    "\n",
    "``sddmm`` matrix-multiplies two dense matrices X1 and X2, then elementwise-multiplies the result with sparse matrix A at the nonzero locations. This is designed for sparse matrix with scalar values.\n",
    "\n",
    "$$out = (X_1 @ X_2) * A$$\n",
    "\n",
    "For a $L \\times N$ sparse matrix A, a $L \\times M$ dense matrix X1 and a $M \\times N$ dense matrix X2, `sddmm(A, X1, X2)` will be a $L \\times N$ sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T13:15:05.958136Z",
     "iopub.status.busy": "2024-10-08T13:15:05.957949Z",
     "iopub.status.idle": "2024-10-08T13:15:05.965152Z",
     "shell.execute_reply": "2024-10-08T13:15:05.964507Z"
    },
    "id": "3ZIFV0TgPhwH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 1., 2.],\n",
      "        [0., 0., 0., 3.]])\n",
      "X1:\n",
      "tensor([[-1.1802,  1.4491,  0.4434,  0.2633, -0.1688],\n",
      "        [-0.9709, -1.3405, -0.5105, -0.9303,  0.7782],\n",
      "        [-0.3925, -0.1507, -1.4164, -1.7589, -0.3970]])\n",
      "X2:\n",
      "tensor([[-0.3111, -0.9357,  1.0792, -0.7508],\n",
      "        [ 0.8989,  0.4831, -0.6589, -0.3762],\n",
      "        [ 0.2425, -1.9341, -0.0174, -1.0185],\n",
      "        [-0.2085,  1.0176,  0.1093,  0.1514],\n",
      "        [-2.1031, -0.4933,  0.3713, -0.3895]])\n",
      "dglsp.sddmm(A, X1, X2):\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0316, 2.6184],\n",
      "        [0.0000, 0.0000, 0.0000, 5.0468]])\n"
     ]
    }
   ],
   "source": [
    "i = torch.tensor([[1, 1, 2],\n",
    "                  [2, 3, 3]])\n",
    "val = torch.tensor([1., 2., 3.])\n",
    "A = dglsp.spmatrix(i, val, (3, 4))\n",
    "print(\"A:\")\n",
    "print(A.to_dense())\n",
    "\n",
    "X1 = torch.randn(3, 5)\n",
    "X2 = torch.randn(5, 4)\n",
    "print(\"X1:\")\n",
    "print(X1)\n",
    "print(\"X2:\")\n",
    "print(X2)\n",
    "\n",
    "O = dglsp.sddmm(A, X1, X2)\n",
    "print(\"dglsp.sddmm(A, X1, X2):\")\n",
    "print(O.to_dense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RmNmXU_ZqyF7"
   },
   "source": [
    "This operator also supports batched sampled-dense-dense matrix multiplication. For a $L \\times N$ sparse matrix A with non-zero vector values of length $$, a $L \\times M \\times K$ dense matrix X1 and a $M \\times N \\times K$ dense matrix X2, `sddmm(A, X1, X2)` will be a $L \\times N \\times K$ sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T13:15:05.966899Z",
     "iopub.status.busy": "2024-10-08T13:15:05.966713Z",
     "iopub.status.idle": "2024-10-08T13:15:05.974572Z",
     "shell.execute_reply": "2024-10-08T13:15:05.973917Z"
    },
    "id": "DuSAjamyrIO_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      "tensor([[[0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [0., 0.],\n",
      "         [1., 1.],\n",
      "         [2., 2.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [3., 3.]]])\n",
      "X1:\n",
      "tensor([[[-1.5980,  0.4256],\n",
      "         [-1.1465,  1.8825],\n",
      "         [-0.1017, -0.1517],\n",
      "         [ 0.1348,  1.3148],\n",
      "         [-0.1797, -1.7136]],\n",
      "\n",
      "        [[-0.1827,  0.1200],\n",
      "         [-0.3943, -1.3855],\n",
      "         [ 0.6567,  0.8895],\n",
      "         [-1.2646, -1.1475],\n",
      "         [-0.0398, -0.9652]],\n",
      "\n",
      "        [[ 0.0683, -1.2148],\n",
      "         [-1.2742, -0.1493],\n",
      "         [ 1.4623, -1.2527],\n",
      "         [ 0.8581, -0.1954],\n",
      "         [-0.5923,  0.1823]]])\n",
      "X2:\n",
      "tensor([[[ 0.7133, -0.8855],\n",
      "         [ 0.3943, -0.5239],\n",
      "         [-0.7570, -1.2776],\n",
      "         [-1.2504, -2.1990]],\n",
      "\n",
      "        [[-1.5588,  0.4848],\n",
      "         [-0.4929,  0.4806],\n",
      "         [ 1.0528,  0.4063],\n",
      "         [-0.1608, -1.2989]],\n",
      "\n",
      "        [[ 0.2458, -1.9391],\n",
      "         [-0.3080, -0.8211],\n",
      "         [ 0.2443, -0.3490],\n",
      "         [ 1.5154,  0.8512]],\n",
      "\n",
      "        [[ 1.2495, -0.0454],\n",
      "         [ 2.1838,  0.0499],\n",
      "         [ 1.4704, -0.1122],\n",
      "         [ 0.7509,  1.0959]],\n",
      "\n",
      "        [[-0.3479,  1.0253],\n",
      "         [-0.9607, -0.5508],\n",
      "         [ 0.6610, -1.6401],\n",
      "         [ 0.0368,  0.2212]]])\n",
      "dglsp.sddmm(A, X1, X2):\n",
      "tensor([[[ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [-2.0023,  0.6850],\n",
      "         [ 0.6716,  1.6438]],\n",
      "\n",
      "        [[ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 8.8741,  4.8753]]])\n"
     ]
    }
   ],
   "source": [
    "i = torch.tensor([[1, 1, 2],\n",
    "                  [2, 3, 3]])\n",
    "val = torch.tensor([[1., 1.], [2., 2.], [3., 3.]])\n",
    "A = dglsp.spmatrix(i, val, (3, 4))\n",
    "print(\"A:\")\n",
    "print(A.to_dense())\n",
    "\n",
    "X1 = torch.randn(3, 5, 2)\n",
    "X2 = torch.randn(5, 4, 2)\n",
    "print(\"X1:\")\n",
    "print(X1)\n",
    "print(\"X2:\")\n",
    "print(X2)\n",
    "\n",
    "O = dglsp.sddmm(A, X1, X2)\n",
    "print(\"dglsp.sddmm(A, X1, X2):\")\n",
    "print(O.to_dense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fVkbTT28ZzPr"
   },
   "source": [
    "## Non-linear activation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XuaNdFO7XG2r"
   },
   "source": [
    "### Element-wise functions\n",
    "\n",
    "Most activation functions are element-wise and can be further grouped into two categories:\n",
    "\n",
    "**Sparse-preserving functions** such as `sin()`, `tanh()`, `sigmoid()`, `relu()`, etc. You can directly apply them on the `val` tensor of the sparse matrix and then recreate a new matrix of the same sparsity using `val_like`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T13:15:05.976686Z",
     "iopub.status.busy": "2024-10-08T13:15:05.976231Z",
     "iopub.status.idle": "2024-10-08T13:15:05.981822Z",
     "shell.execute_reply": "2024-10-08T13:15:05.981181Z"
    },
    "id": "GZkCJJ0TX0cI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.4270,  0.0000],\n",
      "        [ 0.8781,  0.0000, -0.1955],\n",
      "        [ 0.0961,  0.0000,  0.0000]])\n",
      "Apply tanh.\n",
      "tensor([[ 0.0000,  0.4028,  0.0000],\n",
      "        [ 0.7055,  0.0000, -0.1931],\n",
      "        [ 0.0958,  0.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "i = torch.tensor([[0, 1, 1, 2],\n",
    "                  [1, 0, 2, 0]])\n",
    "val = torch.randn(4)\n",
    "A = dglsp.spmatrix(i, val)\n",
    "print(A.to_dense())\n",
    "\n",
    "print(\"Apply tanh.\")\n",
    "A_new = dglsp.val_like(A, torch.tanh(A.val))\n",
    "print(A_new.to_dense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i92lhMEnYas3"
   },
   "source": [
    "**Non-sparse-preserving functions** such as `exp()`, `cos()`, etc. You can first convert the sparse matrix to dense before applying the functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T13:15:05.983581Z",
     "iopub.status.busy": "2024-10-08T13:15:05.983386Z",
     "iopub.status.idle": "2024-10-08T13:15:05.988974Z",
     "shell.execute_reply": "2024-10-08T13:15:05.988324Z"
    },
    "id": "sroJpzRNYZq5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000, -1.6387,  0.0000],\n",
      "        [ 1.6194,  0.0000,  0.3916],\n",
      "        [-0.4043,  0.0000,  0.0000]])\n",
      "Apply exp.\n",
      "tensor([[1.0000, 0.1942, 1.0000],\n",
      "        [5.0498, 1.0000, 1.4793],\n",
      "        [0.6675, 1.0000, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "i = torch.tensor([[0, 1, 1, 2],\n",
    "                  [1, 0, 2, 0]])\n",
    "val = torch.randn(4)\n",
    "A = dglsp.spmatrix(i, val)\n",
    "print(A.to_dense())\n",
    "\n",
    "print(\"Apply exp.\")\n",
    "A_new = A.to_dense().exp()\n",
    "print(A_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8OQZReVXpo3"
   },
   "source": [
    "### Softmax\n",
    "\n",
    "Apply row-wise softmax to the nonzero entries of the sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T13:15:05.990783Z",
     "iopub.status.busy": "2024-10-08T13:15:05.990598Z",
     "iopub.status.idle": "2024-10-08T13:15:05.996863Z",
     "shell.execute_reply": "2024-10-08T13:15:05.996215Z"
    },
    "id": "CQaKgzCJULjt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseMatrix(indices=tensor([[0, 1, 1, 2],\n",
      "                             [1, 0, 2, 0]]),\n",
      "             values=tensor([1.0000, 0.2689, 0.7311, 1.0000]),\n",
      "             shape=(3, 3), nnz=4)\n",
      "In dense format:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 1.0000, 0.0000],\n",
      "        [0.2689, 0.0000, 0.7311],\n",
      "        [1.0000, 0.0000, 0.0000]])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = torch.tensor([[0, 1, 1, 2],\n",
    "                  [1, 0, 2, 0]])\n",
    "val = torch.tensor([1., 2., 3., 4.])\n",
    "A = dglsp.spmatrix(i, val)\n",
    "\n",
    "print(A.softmax())\n",
    "print(\"In dense format:\")\n",
    "print(A.softmax().to_dense())\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1iBNlJVYz3zi"
   },
   "source": [
    "## Exercise \\#1\n",
    "\n",
    "*Let's test what you've learned. Feel free to [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/dmlc/dgl/blob/master/notebooks/sparse/quickstart.ipynb).*\n",
    "\n",
    "Given a sparse symmetrical adjacency matrix $A$, calculate its symmetrically normalized adjacency matrix: $$norm = \\bar{D}^{-\\frac{1}{2}}\\bar{A}\\bar{D}^{-\\frac{1}{2}}$$\n",
    "\n",
    "Where $\\bar{A} = A + I$, $I$ is the identity matrix, and $\\bar{D}$ is the diagonal node degree matrix of $\\bar{A}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T13:15:05.998655Z",
     "iopub.status.busy": "2024-10-08T13:15:05.998469Z",
     "iopub.status.idle": "2024-10-08T13:15:06.002458Z",
     "shell.execute_reply": "2024-10-08T13:15:06.001838Z"
    },
    "id": "0dDhfbJo0ByV"
   },
   "outputs": [],
   "source": [
    "i = torch.tensor([[0, 0, 1, 1, 2, 2, 3],\n",
    "                  [1, 3, 2, 5, 3, 5, 4]])\n",
    "asym_A = dglsp.spmatrix(i, shape=(6, 6))\n",
    "# Step 1: create symmetrical adjacency matrix A from asym_A.\n",
    "# A =\n",
    "\n",
    "# Step 2: calculate A_hat from A.\n",
    "# A_hat =\n",
    "\n",
    "# Step 3: diagonal node degree matrix of A_hat\n",
    "# D_hat =\n",
    "\n",
    "# Step 4: calculate the norm from D_hat and A_hat.\n",
    "# norm = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yfEVQBUuI-cE"
   },
   "source": [
    "## Exercise \\#2\n",
    "\n",
    "Let's implement a simplified version of the Graph Attention Network (GAT) layer.\n",
    "\n",
    "A GAT layer has two inputs: the adjacency matrix $A$ and the node input features $X$.  The idea of GAT layer is to update each node's representation with a weighted average of the node's own representation and its neighbors' representations.  In particular, when computing the output for node $i$, the GAT layer does the following:\n",
    "1. Compute the scores $S_{ij}$ representing the attention logit from neighbor $j$ to node $i$.  $S_{ij}$ is a function of $i$ and $j$'s input features $X_i$ and $X_j$: $$S_{ij} = LeakyReLU(X_i^\\top v_1 + X_j^\\top v_2)$$, where $v_1$ and $v_2$ are trainable vectors.\n",
    "2. Compute a softmax attention $R_{ij} = \\exp S_{ij} / \\left( \\sum_{j' \\in \\mathcal{N}_i} s_{ij'} \\right)$, where $\\mathcal{N}_j$ means the neighbors of $j$.  This means that $R$ is a row-wise softmax attention of $S$.\n",
    "3. Compute the weighted average $H_i = \\sum_{j' : j' \\in \\mathcal{N}_i} R_{j'} X_{j'} W$, where $W$ is a trainable matrix.\n",
    "\n",
    "The following code defined all the parameters you need but only completes step 1.  Could you implement step 2 and step 3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T13:15:06.004234Z",
     "iopub.status.busy": "2024-10-08T13:15:06.004048Z",
     "iopub.status.idle": "2024-10-08T13:15:06.009280Z",
     "shell.execute_reply": "2024-10-08T13:15:06.008657Z"
    },
    "id": "pYrgSxq6La5c"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimplifiedGAT(nn.Module):\n",
    "    def __init__(self, in_size, out_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.W = nn.Parameter(torch.randn(in_size, out_size))\n",
    "        self.v1 = nn.Parameter(torch.randn(in_size))\n",
    "        self.v2 = nn.Parameter(torch.randn(in_size))\n",
    "\n",
    "    def forward(self, A, X):\n",
    "        # A: A sparse matrix with size (N, N).  A[i, j] represent the edge from j to i.\n",
    "        # X: A dense matrix with size (N, D)\n",
    "        # Step 1: compute S[i, j]\n",
    "        Xv1 = X @ self.v1\n",
    "        Xv2 = X @ self.v2\n",
    "        s = F.leaky_relu(Xv1[A.col] + Xv2[A.row])\n",
    "        S = dglsp.val_like(A, s)\n",
    "\n",
    "        # Step 2: compute R[i, j] which is the row-wise attention of $S$.\n",
    "        # EXERCISE: replace the statement below.\n",
    "        R = S\n",
    "\n",
    "        # Step 3: compute H.\n",
    "        # EXERCISE: replace the statement below.\n",
    "        H = X\n",
    "\n",
    "        return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T13:15:06.010963Z",
     "iopub.status.busy": "2024-10-08T13:15:06.010777Z",
     "iopub.status.idle": "2024-10-08T13:15:06.014748Z",
     "shell.execute_reply": "2024-10-08T13:15:06.014143Z"
    },
    "id": "qjcXiidYCqGK"
   },
   "outputs": [],
   "source": [
    "# Test:\n",
    "# Let's use the symmetric A created above.\n",
    "X = torch.randn(6, 20)\n",
    "module = SimplifiedGAT(20, 10)\n",
    "Y = module(A, X)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
