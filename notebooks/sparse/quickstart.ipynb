{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E0DAKDMuWz7I"
   },
   "source": [
    "# Quickstart\n",
    "\n",
    "The tutorial provides a quick walkthrough of the classes and operators provided by the `dgl.sparse` package.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/dmlc/dgl/blob/master/notebooks/sparse/quickstart.ipynb) [![GitHub](https://img.shields.io/badge/-View%20on%20GitHub-181717?logo=github&logoColor=ffffff)](https://github.com/dmlc/dgl/blob/master/notebooks/sparse/quickstart.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T13:25:28.511726Z",
     "iopub.status.busy": "2024-11-03T13:25:28.511443Z",
     "iopub.status.idle": "2024-11-03T13:25:30.423119Z",
     "shell.execute_reply": "2024-11-03T13:25:30.422166Z"
    },
    "id": "19UZd7wyWzpT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DGL installed!\n"
     ]
    }
   ],
   "source": [
    "# Install the required packages.\n",
    "\n",
    "import os\n",
    "# Uncomment following commands to download Pytorch and DGL\n",
    "# !pip install torch==2.0.0+cpu torchvision==0.15.1+cpu torchaudio==2.0.1 --index-url https://download.pytorch.org/whl/cpu > /dev/null\n",
    "# !pip install  dgl==1.1.0 -f https://data.dgl.ai/wheels/repo.html > /dev/null\n",
    "import torch\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "os.environ['DGLBACKEND'] = \"pytorch\"\n",
    "\n",
    "\n",
    "try:\n",
    "    import dgl.sparse as dglsp\n",
    "    installed = True\n",
    "except ImportError:\n",
    "    installed = False\n",
    "print(\"DGL installed!\" if installed else \"DGL not found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GsWoAGC4RpHw"
   },
   "source": [
    "## Sparse Matrix\n",
    "\n",
    "The core abstraction of DGL's sparse package is the `SparseMatrix` class. Compared with other sparse matrix libraries (such as `scipy.sparse` and `torch.sparse`), DGL's `SparseMatrix` is specialized for the deep learning workloads on structure data (e.g., Graph Neural Networks), with the following features:\n",
    "\n",
    "* **Auto sparse format.** Don't bother choosing between different sparse formats. There is only one `SparseMatrix` and it will select the best format for the operation to be performed.\n",
    "* **Non-zero elements can be scalar or vector.** Easy for modeling relations (e.g., edges) by vector representation.\n",
    "* **Fully PyTorch compatible.** The package is built upon PyTorch and is natively compatible with other tools in the PyTorch ecosystem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_q4HYodcWenB"
   },
   "source": [
    "### Creating a DGL Sparse Matrix\n",
    "\n",
    "The simplest way to create a sparse matrix is using the `spmatrix` API by providing the indices of the non-zero elements. The indices are stored in a tensor of shape `(2, nnz)`, where the `i`-th non-zero element is stored at position `(indices[0][i], indices[1][i])`. The code below creates a 3x3 sparse matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T13:25:30.451885Z",
     "iopub.status.busy": "2024-11-03T13:25:30.450906Z",
     "iopub.status.idle": "2024-11-03T13:25:30.461214Z",
     "shell.execute_reply": "2024-11-03T13:25:30.460383Z"
    },
    "id": "h-ryVEs1PuIP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseMatrix(indices=tensor([[1, 1, 2],\n",
      "                             [0, 2, 0]]),\n",
      "             values=tensor([1., 1., 1.]),\n",
      "             shape=(3, 3), nnz=3)\n",
      "\n",
      "In dense format:\n",
      "tensor([[0., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [1., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import dgl.sparse as dglsp\n",
    "\n",
    "i = torch.tensor([[1, 1, 2],\n",
    "                  [0, 2, 0]])\n",
    "A = dglsp.spmatrix(i)  # 1.0 is default value for nnz elements.\n",
    "\n",
    "print(A)\n",
    "print(\"\")\n",
    "print(\"In dense format:\")\n",
    "print(A.to_dense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W1JJg-eZ7K3t"
   },
   "source": [
    "If not specified, the shape is inferred automatically from the indices but you can specify it explicitly too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T13:25:30.463528Z",
     "iopub.status.busy": "2024-11-03T13:25:30.463229Z",
     "iopub.status.idle": "2024-11-03T13:25:30.468716Z",
     "shell.execute_reply": "2024-11-03T13:25:30.468190Z"
    },
    "id": "80NNSQfd7L5V"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Implicit Shape: (2, 3)\n",
      "tensor([[1., 0., 1.],\n",
      "        [1., 0., 0.]])\n",
      "\n",
      "Explicit Shape: (3, 3)\n",
      "tensor([[1., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "i = torch.tensor([[0, 0, 1],\n",
    "                  [0, 2, 0]])\n",
    "\n",
    "A1 = dglsp.spmatrix(i)\n",
    "print(f\"Implicit Shape: {A1.shape}\")\n",
    "print(A1.to_dense())\n",
    "print(\"\")\n",
    "\n",
    "A2 = dglsp.spmatrix(i, shape=(3, 3))\n",
    "print(f\"Explicit Shape: {A2.shape}\")\n",
    "print(A2.to_dense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zdNgUf0ShfCe"
   },
   "source": [
    "Both scalar values and vector values can be set for nnz elements in Sparse Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T13:25:30.470387Z",
     "iopub.status.busy": "2024-11-03T13:25:30.470101Z",
     "iopub.status.idle": "2024-11-03T13:25:30.476965Z",
     "shell.execute_reply": "2024-11-03T13:25:30.476454Z"
    },
    "id": "buE9ZkKvhp1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Scalar Values-----\n",
      "SparseMatrix(indices=tensor([[1, 1, 2],\n",
      "                             [0, 2, 0]]),\n",
      "             values=tensor([1., 2., 3.]),\n",
      "             shape=(3, 3), nnz=3)\n",
      "\n",
      "In dense format:\n",
      "tensor([[0., 0., 0.],\n",
      "        [1., 0., 2.],\n",
      "        [3., 0., 0.]])\n",
      "\n",
      "-----Vector Values-----\n",
      "SparseMatrix(indices=tensor([[1, 1, 2],\n",
      "                             [0, 2, 0]]),\n",
      "             values=tensor([[1., 1.],\n",
      "                            [2., 2.],\n",
      "                            [3., 3.]]),\n",
      "             shape=(3, 3), nnz=3, val_size=(2,))\n",
      "\n",
      "In dense format:\n",
      "tensor([[[0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 1.],\n",
      "         [0., 0.],\n",
      "         [2., 2.]],\n",
      "\n",
      "        [[3., 3.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "i = torch.tensor([[1, 1, 2],\n",
    "                  [0, 2, 0]])\n",
    "# The length of the value should match the nnz elements represented by the\n",
    "# sparse matrix format.\n",
    "scalar_val = torch.tensor([1., 2., 3.])\n",
    "vector_val = torch.tensor([[1., 1.], [2., 2.], [3., 3.]])\n",
    "\n",
    "print(\"-----Scalar Values-----\")\n",
    "A = dglsp.spmatrix(i, scalar_val)\n",
    "print(A)\n",
    "print(\"\")\n",
    "print(\"In dense format:\")\n",
    "print(A.to_dense())\n",
    "print(\"\")\n",
    "\n",
    "print(\"-----Vector Values-----\")\n",
    "A = dglsp.spmatrix(i, vector_val)\n",
    "print(A)\n",
    "print(\"\")\n",
    "print(\"In dense format:\")\n",
    "print(A.to_dense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ufTCDAVsrmP"
   },
   "source": [
    "*Duplicated indices*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T13:25:30.478676Z",
     "iopub.status.busy": "2024-11-03T13:25:30.478394Z",
     "iopub.status.idle": "2024-11-03T13:25:30.483787Z",
     "shell.execute_reply": "2024-11-03T13:25:30.483265Z"
    },
    "id": "ilSAlFLOs0o8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseMatrix(indices=tensor([[0, 0, 0, 1],\n",
      "                             [0, 2, 2, 0]]),\n",
      "             values=tensor([1., 2., 3., 4.]),\n",
      "             shape=(2, 3), nnz=4)\n",
      "Whether A contains duplicate indices: True\n",
      "\n",
      "SparseMatrix(indices=tensor([[0, 0, 1],\n",
      "                             [0, 2, 0]]),\n",
      "             values=tensor([1., 5., 4.]),\n",
      "             shape=(2, 3), nnz=3)\n",
      "Whether B contains duplicate indices: False\n"
     ]
    }
   ],
   "source": [
    "i = torch.tensor([[0, 0, 0, 1],\n",
    "                  [0, 2, 2, 0]])\n",
    "val = torch.tensor([1., 2., 3., 4])\n",
    "A = dglsp.spmatrix(i, val)\n",
    "print(A)\n",
    "print(f\"Whether A contains duplicate indices: {A.has_duplicate()}\")\n",
    "print(\"\")\n",
    "\n",
    "B = A.coalesce()\n",
    "print(B)\n",
    "print(f\"Whether B contains duplicate indices: {B.has_duplicate()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJ09qM5NaxuI"
   },
   "source": [
    "**val_like**\n",
    "\n",
    "You can create a new sparse matrix by retaining the non-zero indices of a given sparse matrix but with different non-zero values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T13:25:30.485491Z",
     "iopub.status.busy": "2024-11-03T13:25:30.485209Z",
     "iopub.status.idle": "2024-11-03T13:25:30.489828Z",
     "shell.execute_reply": "2024-11-03T13:25:30.489313Z"
    },
    "id": "UB3lKJVBbsUD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseMatrix(indices=tensor([[1, 1, 2],\n",
      "                             [0, 2, 0]]),\n",
      "             values=tensor([4., 5., 6.]),\n",
      "             shape=(3, 3), nnz=3)\n"
     ]
    }
   ],
   "source": [
    "i = torch.tensor([[1, 1, 2],\n",
    "                  [0, 2, 0]])\n",
    "val = torch.tensor([1., 2., 3.])\n",
    "A = dglsp.spmatrix(i, val)\n",
    "\n",
    "new_val = torch.tensor([4., 5., 6.])\n",
    "B = dglsp.val_like(A, new_val)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nWjBSFDBXDPJ"
   },
   "source": [
    "**Create a sparse matrix from various sparse formats**\n",
    "\n",
    "*   `from_coo()`: Create a sparse matrix from [COO](https://en.wikipedia.org/wiki/Sparse_matrix#Coordinate_list_(COO)) format.\n",
    "*   `from_csr()`: Create a sparse matrix from [CSR](https://en.wikipedia.org/wiki/Sparse_matrix#Compressed_sparse_row_(CSR,_CRS_or_Yale_format)) format.\n",
    "*   `from_csc()`: Create a sparse matrix from [CSC](https://en.wikipedia.org/wiki/Sparse_matrix#Compressed_sparse_column_(CSC_or_CCS)) format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T13:25:30.491545Z",
     "iopub.status.busy": "2024-11-03T13:25:30.491269Z",
     "iopub.status.idle": "2024-11-03T13:25:30.499750Z",
     "shell.execute_reply": "2024-11-03T13:25:30.499211Z"
    },
    "id": "3puXyMFsvdlj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Create from COO format-----\n",
      "SparseMatrix(indices=tensor([[0, 1, 2, 2, 2],\n",
      "                             [1, 2, 0, 1, 2]]),\n",
      "             values=tensor([1., 1., 1., 1., 1.]),\n",
      "             shape=(3, 3), nnz=5)\n",
      "\n",
      "In dense format:\n",
      "tensor([[0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 1., 1.]])\n",
      "\n",
      "-----Create from CSR format-----\n",
      "SparseMatrix(indices=tensor([[0, 1, 2, 2, 2],\n",
      "                             [1, 2, 0, 1, 2]]),\n",
      "             values=tensor([1., 1., 1., 1., 1.]),\n",
      "             shape=(3, 3), nnz=5)\n",
      "\n",
      "In dense format:\n",
      "tensor([[0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 1., 1.]])\n",
      "\n",
      "-----Create from CSC format-----\n",
      "SparseMatrix(indices=tensor([[1, 2, 0, 1, 2],\n",
      "                             [0, 1, 2, 2, 2]]),\n",
      "             values=tensor([1., 1., 1., 1., 1.]),\n",
      "             shape=(3, 3), nnz=5)\n",
      "\n",
      "In dense format:\n",
      "tensor([[0., 0., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "row = torch.tensor([0, 1, 2, 2, 2])\n",
    "col = torch.tensor([1, 2, 0, 1, 2])\n",
    "\n",
    "print(\"-----Create from COO format-----\")\n",
    "A = dglsp.from_coo(row, col)\n",
    "print(A)\n",
    "print(\"\")\n",
    "print(\"In dense format:\")\n",
    "print(A.to_dense())\n",
    "print(\"\")\n",
    "\n",
    "indptr = torch.tensor([0, 1, 2, 5])\n",
    "indices = torch.tensor([1, 2, 0, 1, 2])\n",
    "\n",
    "print(\"-----Create from CSR format-----\")\n",
    "A = dglsp.from_csr(indptr, indices)\n",
    "print(A)\n",
    "print(\"\")\n",
    "print(\"In dense format:\")\n",
    "print(A.to_dense())\n",
    "print(\"\")\n",
    "\n",
    "print(\"-----Create from CSC format-----\")\n",
    "B = dglsp.from_csc(indptr, indices)\n",
    "print(B)\n",
    "print(\"\")\n",
    "print(\"In dense format:\")\n",
    "print(B.to_dense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nd4hJ9ysd4St"
   },
   "source": [
    "### Attributes and methods of a DGL Sparse Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T13:25:30.501479Z",
     "iopub.status.busy": "2024-11-03T13:25:30.501196Z",
     "iopub.status.idle": "2024-11-03T13:25:30.507361Z",
     "shell.execute_reply": "2024-11-03T13:25:30.506823Z"
    },
    "id": "OKbFiWKIzZVe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of sparse matrix: (3, 3)\n",
      "The number of nonzero elements of sparse matrix: 4\n",
      "Datatype of sparse matrix: torch.float32\n",
      "Device sparse matrix is stored on: cpu\n",
      "Get the values of the nonzero elements: tensor([1., 2., 3., 4.])\n",
      "Get the row indices of the nonzero elements: tensor([0, 1, 1, 2])\n",
      "Get the column indices of the nonzero elements: tensor([1, 0, 2, 0])\n",
      "Get the coordinate (COO) representation: (tensor([0, 1, 1, 2]), tensor([1, 0, 2, 0]))\n",
      "Get the compressed sparse row (CSR) representation: (tensor([0, 1, 3, 4]), tensor([1, 0, 2, 0]), tensor([0, 1, 2, 3]))\n",
      "Get the compressed sparse column (CSC) representation: (tensor([0, 2, 3, 4]), tensor([1, 2, 0, 1]), tensor([1, 3, 0, 2]))\n"
     ]
    }
   ],
   "source": [
    "i = torch.tensor([[0, 1, 1, 2],\n",
    "                  [1, 0, 2, 0]])\n",
    "val = torch.tensor([1., 2., 3., 4.])\n",
    "A = dglsp.spmatrix(i, val)\n",
    "\n",
    "print(f\"Shape of sparse matrix: {A.shape}\")\n",
    "print(f\"The number of nonzero elements of sparse matrix: {A.nnz}\")\n",
    "print(f\"Datatype of sparse matrix: {A.dtype}\")\n",
    "print(f\"Device sparse matrix is stored on: {A.device}\")\n",
    "print(f\"Get the values of the nonzero elements: {A.val}\")\n",
    "print(f\"Get the row indices of the nonzero elements: {A.row}\")\n",
    "print(f\"Get the column indices of the nonzero elements: {A.col}\")\n",
    "print(f\"Get the coordinate (COO) representation: {A.coo()}\")\n",
    "print(f\"Get the compressed sparse row (CSR) representation: {A.csr()}\")\n",
    "print(f\"Get the compressed sparse column (CSC) representation: {A.csc()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VzosM7i3yQPK"
   },
   "source": [
    "**dtype and/or device conversion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T13:25:30.509065Z",
     "iopub.status.busy": "2024-11-03T13:25:30.508790Z",
     "iopub.status.idle": "2024-11-03T13:25:30.512944Z",
     "shell.execute_reply": "2024-11-03T13:25:30.512438Z"
    },
    "id": "y_RJihw-ypXp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device sparse matrix is stored on: cpu\n",
      "Datatype of sparse matrix: torch.int32\n"
     ]
    }
   ],
   "source": [
    "i = torch.tensor([[0, 1, 1, 2],\n",
    "                  [1, 0, 2, 0]])\n",
    "val = torch.tensor([1., 2., 3., 4.])\n",
    "A = dglsp.spmatrix(i, val)\n",
    "\n",
    "B = A.to(device='cpu', dtype=torch.int32)\n",
    "print(f\"Device sparse matrix is stored on: {B.device}\")\n",
    "print(f\"Datatype of sparse matrix: {B.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U26arLlJzfkN"
   },
   "source": [
    "Similar to pytorch, we also provide various fine-grained APIs ([Doc](https://docs.dgl.ai/en/latest/api/python/dgl.sparse_v0.html)) for dtype and/or device conversion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EFe9ABRuWHqf"
   },
   "source": [
    "## Diagonal Matrix\n",
    "\n",
    "Diagonal Matrix is a special type of Sparse Matrix, in which the entries outside the main diagonal are all zero.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1CeCoE2Fgl_x"
   },
   "source": [
    "### Initializing a DGL Diagonal Sparse Matrix\n",
    "A DGL Diagonal Sparse Matrix can be initiate by `dglsp.diag()`.\n",
    "\n",
    "Identity Matrix is a special type of Diagonal Sparse Matrix, in which all the value on the diagonal are 1.0. Use `dglsp.identity()` to initiate a Diagonal Sparse Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T13:25:30.514705Z",
     "iopub.status.busy": "2024-11-03T13:25:30.514431Z",
     "iopub.status.idle": "2024-11-03T13:25:30.519045Z",
     "shell.execute_reply": "2024-11-03T13:25:30.518507Z"
    },
    "id": "9wzJNApahXAR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseMatrix(indices=tensor([[0, 1, 2, 3],\n",
      "                             [0, 1, 2, 3]]),\n",
      "             values=tensor([1., 2., 3., 4.]),\n",
      "             shape=(4, 4), nnz=4)\n",
      "SparseMatrix(indices=tensor([[0, 1, 2],\n",
      "                             [0, 1, 2]]),\n",
      "             values=tensor([1., 1., 1.]),\n",
      "             shape=(3, 3), nnz=3)\n"
     ]
    }
   ],
   "source": [
    "val = torch.tensor([1., 2., 3., 4.])\n",
    "D = dglsp.diag(val)\n",
    "print(D)\n",
    "\n",
    "I = dglsp.identity(shape=(3, 3))\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tjsapqp6zSFR"
   },
   "source": [
    "## Operations on Sparse Matrix\n",
    "*   Elementwise operations\n",
    "    *   `A + B`\n",
    "    *   `A - B`\n",
    "    *   `A * B`\n",
    "    *   `A / B`\n",
    "    *   `A ** scalar`\n",
    "*   Broadcast operations\n",
    "    *   `sp_<op>_v()`\n",
    "*   Reduce operations\n",
    "    *   `reduce()`\n",
    "    *   `sum()`\n",
    "    *   `smax()`\n",
    "    *   `smin()`\n",
    "    *   `smean()`\n",
    "*   Matrix transformations\n",
    "    *   `SparseMatrix.transpose()` or `SparseMatrix.T`\n",
    "    *   `SparseMatrix.neg()`\n",
    "    *   `SparseMatrix.inv()`\n",
    "*   Matrix multiplication\n",
    "    *   `matmul()`\n",
    "    *   `sddmm()`\n",
    "\n",
    "\n",
    "*We are using dense format to print sparse matrix in this tutorial since it is more intuitive to read.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "psvGwcIqYvC2"
   },
   "source": [
    "### *Elementwise operations*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "39YJitpW-K9v"
   },
   "source": [
    "**add(A, B), equivalent to A + B**\n",
    "\n",
    "Element-wise addition on two sparse matrices, returning a sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T13:25:30.520821Z",
     "iopub.status.busy": "2024-11-03T13:25:30.520545Z",
     "iopub.status.idle": "2024-11-03T13:25:30.529780Z",
     "shell.execute_reply": "2024-11-03T13:25:30.529251Z"
    },
    "id": "pj3Ckx41-BSu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1:\n",
      "tensor([[0., 0., 0.],\n",
      "        [1., 0., 2.],\n",
      "        [3., 0., 0.]])\n",
      "A2:\n",
      "tensor([[4., 0., 0.],\n",
      "        [0., 0., 5.],\n",
      "        [0., 6., 0.]])\n",
      "D1:\n",
      "tensor([[-1.,  0.,  0.],\n",
      "        [ 0., -2.,  0.],\n",
      "        [ 0.,  0., -3.]])\n",
      "D2:\n",
      "tensor([[-4.,  0.,  0.],\n",
      "        [ 0., -5.,  0.],\n",
      "        [ 0.,  0., -6.]])\n",
      "A1 + A2:\n",
      "tensor([[4., 0., 0.],\n",
      "        [1., 0., 7.],\n",
      "        [3., 6., 0.]])\n",
      "A1 + D1:\n",
      "tensor([[-1.,  0.,  0.],\n",
      "        [ 1., -2.,  2.],\n",
      "        [ 3.,  0., -3.]])\n",
      "D1 + D2:\n",
      "tensor([[-5.,  0.,  0.],\n",
      "        [ 0., -7.,  0.],\n",
      "        [ 0.,  0., -9.]])\n"
     ]
    }
   ],
   "source": [
    "i = torch.tensor([[1, 1, 2],\n",
    "                  [0, 2, 0]])\n",
    "val = torch.tensor([1., 2., 3.])\n",
    "A1 = dglsp.spmatrix(i, val, shape=(3, 3))\n",
    "print(\"A1:\")\n",
    "print(A1.to_dense())\n",
    "\n",
    "i = torch.tensor([[0, 1, 2],\n",
    "                  [0, 2, 1]])\n",
    "val = torch.tensor([4., 5., 6.])\n",
    "A2 = dglsp.spmatrix(i, val, shape=(3, 3))\n",
    "print(\"A2:\")\n",
    "print(A2.to_dense())\n",
    "\n",
    "val = torch.tensor([-1., -2., -3.])\n",
    "D1 = dglsp.diag(val)\n",
    "print(\"D1:\")\n",
    "print(D1.to_dense())\n",
    "\n",
    "val = torch.tensor([-4., -5., -6.])\n",
    "D2 = dglsp.diag(val)\n",
    "print(\"D2:\")\n",
    "print(D2.to_dense())\n",
    "\n",
    "print(\"A1 + A2:\")\n",
    "print((A1 + A2).to_dense())\n",
    "\n",
    "print(\"A1 + D1:\")\n",
    "print((A1 + D1).to_dense())\n",
    "\n",
    "print(\"D1 + D2:\")\n",
    "print((D1 + D2).to_dense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i25N0JHUTUX9"
   },
   "source": [
    "**sub(A, B), equivalent to A - B**\n",
    "\n",
    "Element-wise substraction on two sparse matrices, returning a sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T13:25:30.531464Z",
     "iopub.status.busy": "2024-11-03T13:25:30.531189Z",
     "iopub.status.idle": "2024-11-03T13:25:30.541375Z",
     "shell.execute_reply": "2024-11-03T13:25:30.540841Z"
    },
    "id": "GMxfz-cyT129"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1:\n",
      "tensor([[0., 0., 0.],\n",
      "        [1., 0., 2.],\n",
      "        [3., 0., 0.]])\n",
      "A2:\n",
      "tensor([[4., 0., 0.],\n",
      "        [0., 0., 5.],\n",
      "        [0., 6., 0.]])\n",
      "D1:\n",
      "tensor([[-1.,  0.,  0.],\n",
      "        [ 0., -2.,  0.],\n",
      "        [ 0.,  0., -3.]])\n",
      "D2:\n",
      "tensor([[-4.,  0.,  0.],\n",
      "        [ 0., -5.,  0.],\n",
      "        [ 0.,  0., -6.]])\n",
      "A1 - A2:\n",
      "tensor([[-4.,  0.,  0.],\n",
      "        [ 1.,  0., -3.],\n",
      "        [ 3., -6.,  0.]])\n",
      "A1 - D1:\n",
      "tensor([[1., 0., 0.],\n",
      "        [1., 2., 2.],\n",
      "        [3., 0., 3.]])\n",
      "D1 - A1:\n",
      "tensor([[-1.,  0.,  0.],\n",
      "        [-1., -2., -2.],\n",
      "        [-3.,  0., -3.]])\n",
      "D1 - D2:\n",
      "tensor([[3., 0., 0.],\n",
      "        [0., 3., 0.],\n",
      "        [0., 0., 3.]])\n"
     ]
    }
   ],
   "source": [
    "i = torch.tensor([[1, 1, 2],\n",
    "                  [0, 2, 0]])\n",
    "val = torch.tensor([1., 2., 3.])\n",
    "A1 = dglsp.spmatrix(i, val, shape=(3, 3))\n",
    "print(\"A1:\")\n",
    "print(A1.to_dense())\n",
    "\n",
    "i = torch.tensor([[0, 1, 2],\n",
    "                  [0, 2, 1]])\n",
    "val = torch.tensor([4., 5., 6.])\n",
    "A2 = dglsp.spmatrix(i, val, shape=(3, 3))\n",
    "print(\"A2:\")\n",
    "print(A2.to_dense())\n",
    "\n",
    "val = torch.tensor([-1., -2., -3.])\n",
    "D1 = dglsp.diag(val)\n",
    "print(\"D1:\")\n",
    "print(D1.to_dense())\n",
    "\n",
    "val = torch.tensor([-4., -5., -6.])\n",
    "D2 = dglsp.diag(val)\n",
    "print(\"D2:\")\n",
    "print(D2.to_dense())\n",
    "\n",
    "print(\"A1 - A2:\")\n",
    "print((A1 - A2).to_dense())\n",
    "\n",
    "print(\"A1 - D1:\")\n",
    "print((A1 - D1).to_dense())\n",
    "\n",
    "print(\"D1 - A1:\")\n",
    "print((D1 - A1).to_dense())\n",
    "\n",
    "print(\"D1 - D2:\")\n",
    "print((D1 - D2).to_dense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bg45jnq8T9EJ"
   },
   "source": [
    "**mul(A, B), equivalent to A * B**\n",
    "\n",
    "Element-wise multiplication on two sparse matrices or on a sparse matrix and a scalar, returning a sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T13:25:30.543110Z",
     "iopub.status.busy": "2024-11-03T13:25:30.542806Z",
     "iopub.status.idle": "2024-11-03T13:25:30.554975Z",
     "shell.execute_reply": "2024-11-03T13:25:30.554422Z"
    },
    "id": "4PAITJqHUB8J"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1:\n",
      "tensor([[0., 0., 0.],\n",
      "        [1., 0., 2.],\n",
      "        [3., 0., 0.]])\n",
      "A2:\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 0., 2.],\n",
      "        [3., 4., 0.]])\n",
      "A1 * 3:\n",
      "tensor([[0., 0., 0.],\n",
      "        [3., 0., 6.],\n",
      "        [9., 0., 0.]])\n",
      "3 * A1:\n",
      "tensor([[0., 0., 0.],\n",
      "        [3., 0., 6.],\n",
      "        [9., 0., 0.]])\n",
      "A1 * A2\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 4.],\n",
      "        [9., 0., 0.]])\n",
      "D1:\n",
      "tensor([[-1.,  0.,  0.],\n",
      "        [ 0., -2.,  0.],\n",
      "        [ 0.,  0., -3.]])\n",
      "D1 * A2\n",
      "tensor([[-1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.]])\n",
      "D2:\n",
      "tensor([[-4.,  0.,  0.],\n",
      "        [ 0., -5.,  0.],\n",
      "        [ 0.,  0., -6.]])\n",
      "D1 * -2:\n",
      "tensor([[2., 0., 0.],\n",
      "        [0., 4., 0.],\n",
      "        [0., 0., 6.]])\n",
      "-2 * D1:\n",
      "tensor([[2., 0., 0.],\n",
      "        [0., 4., 0.],\n",
      "        [0., 0., 6.]])\n",
      "D1 * D2:\n",
      "tensor([[ 4.,  0.,  0.],\n",
      "        [ 0., 10.,  0.],\n",
      "        [ 0.,  0., 18.]])\n"
     ]
    }
   ],
   "source": [
    "i = torch.tensor([[1, 1, 2],\n",
    "                  [0, 2, 0]])\n",
    "val = torch.tensor([1., 2., 3.])\n",
    "A1 = dglsp.spmatrix(i, val, shape=(3, 3))\n",
    "print(\"A1:\")\n",
    "print(A1.to_dense())\n",
    "\n",
    "i = torch.tensor([[0, 1, 2, 2],\n",
    "                  [0, 2, 0, 1]])\n",
    "val = torch.tensor([1., 2., 3., 4.])\n",
    "A2 = dglsp.spmatrix(i, val, shape=(3, 3))\n",
    "\n",
    "print(\"A2:\")\n",
    "print(A2.to_dense())\n",
    "\n",
    "print(\"A1 * 3:\")\n",
    "print((A1 * 3).to_dense())\n",
    "print(\"3 * A1:\")\n",
    "print((3 * A1).to_dense())\n",
    "\n",
    "print(\"A1 * A2\")\n",
    "print((A1 * A2).to_dense())\n",
    "\n",
    "val = torch.tensor([-1., -2., -3.])\n",
    "D1 = dglsp.diag(val)\n",
    "print(\"D1:\")\n",
    "print(D1.to_dense())\n",
    "\n",
    "print(\"D1 * A2\")\n",
    "print((D1 * A2).to_dense())\n",
    "\n",
    "val = torch.tensor([-4., -5., -6.])\n",
    "D2 = dglsp.diag(val)\n",
    "print(\"D2:\")\n",
    "print(D2.to_dense())\n",
    "\n",
    "print(\"D1 * -2:\")\n",
    "print((D1 * -2).to_dense())\n",
    "print(\"-2 * D1:\")\n",
    "print((-2 * D1).to_dense())\n",
    "\n",
    "print(\"D1 * D2:\")\n",
    "print((D1 * D2).to_dense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xb2RU6H4UBCs"
   },
   "source": [
    "**div(A, B), equivalent to A / B**\n",
    "\n",
    "Element-wise multiplication on two sparse matrices or on a sparse matrix and a scalar, returning a sparse matrix. If both `A` and `B` are sparse matrices, both of them must have the same sparsity. And the returned matrix has the same order of non-zero entries as `A`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T13:25:30.556686Z",
     "iopub.status.busy": "2024-11-03T13:25:30.556403Z",
     "iopub.status.idle": "2024-11-03T13:25:30.565784Z",
     "shell.execute_reply": "2024-11-03T13:25:30.565257Z"
    },
    "id": "TFB_UcmEUdr3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1:\n",
      "tensor([[0., 0., 0.],\n",
      "        [1., 0., 2.],\n",
      "        [3., 0., 0.]])\n",
      "A1 / 2:\n",
      "tensor([[0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.0000, 1.0000],\n",
      "        [1.5000, 0.0000, 0.0000]])\n",
      "A1 / A2\n",
      "tensor([[0., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [1., 0., 0.]])\n",
      "D1:\n",
      "tensor([[-1.,  0.,  0.],\n",
      "        [ 0., -2.,  0.],\n",
      "        [ 0.,  0., -3.]])\n",
      "D2:\n",
      "tensor([[-4.,  0.,  0.],\n",
      "        [ 0., -5.,  0.],\n",
      "        [ 0.,  0., -6.]])\n",
      "D1 / D2:\n",
      "tensor([[0.2500, 0.0000, 0.0000],\n",
      "        [0.0000, 0.4000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.5000]])\n",
      "D1 / 2:\n",
      "tensor([[-0.5000,  0.0000,  0.0000],\n",
      "        [ 0.0000, -1.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000, -1.5000]])\n"
     ]
    }
   ],
   "source": [
    "i = torch.tensor([[1, 1, 2],\n",
    "                  [0, 2, 0]])\n",
    "val = torch.tensor([1., 2., 3.])\n",
    "A1 = dglsp.spmatrix(i, val, shape=(3, 3))\n",
    "print(\"A1:\")\n",
    "print(A1.to_dense())\n",
    "\n",
    "i = torch.tensor([[1, 2, 1],\n",
    "                  [0, 0, 2]])\n",
    "val = torch.tensor([1., 3., 2.])\n",
    "A2 = dglsp.spmatrix(i, val, shape=(3, 3))\n",
    "\n",
    "print(\"A1 / 2:\")\n",
    "print((A1 / 2).to_dense())\n",
    "\n",
    "print(\"A1 / A2\")\n",
    "print((A1 / A2).to_dense())\n",
    "\n",
    "val = torch.tensor([-1., -2., -3.])\n",
    "D1 = dglsp.diag(val)\n",
    "print(\"D1:\")\n",
    "print(D1.to_dense())\n",
    "\n",
    "val = torch.tensor([-4., -5., -6.])\n",
    "D2 = dglsp.diag(val)\n",
    "print(\"D2:\")\n",
    "print(D2.to_dense())\n",
    "\n",
    "print(\"D1 / D2:\")\n",
    "print((D1 / D2).to_dense())\n",
    "\n",
    "print(\"D1 / 2:\")\n",
    "print((D1 / 2).to_dense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2lZbyTYUUgSi"
   },
   "source": [
    "**power(A, B), equivalent to A \\*\\* B**\n",
    "\n",
    "Element-wise power of a sparse matrix and a scalar, returning a sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T13:25:30.567494Z",
     "iopub.status.busy": "2024-11-03T13:25:30.567212Z",
     "iopub.status.idle": "2024-11-03T13:25:30.573578Z",
     "shell.execute_reply": "2024-11-03T13:25:30.573068Z"
    },
    "id": "ox-XxCnuUqAy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      "tensor([[0., 0., 0.],\n",
      "        [1., 0., 2.],\n",
      "        [3., 0., 0.]])\n",
      "A ** 3:\n",
      "tensor([[ 0.,  0.,  0.],\n",
      "        [ 1.,  0.,  8.],\n",
      "        [27.,  0.,  0.]])\n",
      "D:\n",
      "tensor([[-1.,  0.,  0.],\n",
      "        [ 0., -2.,  0.],\n",
      "        [ 0.,  0., -3.]])\n",
      "D1 ** 2:\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 4., 0.],\n",
      "        [0., 0., 9.]])\n"
     ]
    }
   ],
   "source": [
    "i = torch.tensor([[1, 1, 2],\n",
    "                  [0, 2, 0]])\n",
    "val = torch.tensor([1., 2., 3.])\n",
    "A = dglsp.spmatrix(i, val, shape=(3, 3))\n",
    "print(\"A:\")\n",
    "print(A.to_dense())\n",
    "\n",
    "print(\"A ** 3:\")\n",
    "print((A ** 3).to_dense())\n",
    "\n",
    "val = torch.tensor([-1., -2., -3.])\n",
    "D = dglsp.diag(val)\n",
    "print(\"D:\")\n",
    "print(D.to_dense())\n",
    "\n",
    "print(\"D1 ** 2:\")\n",
    "print((D1 ** 2).to_dense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VXBz4j5x_wQ4"
   },
   "source": [
    "### *Broadcast operations*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PtnyZdXHAZ6Z"
   },
   "source": [
    "**sp_\\<op\\>_v(A, v)**\n",
    "\n",
    "Broadcast operations on a sparse matrix and a vector, returning a sparse matrix. `v` is broadcasted to the shape of `A` and then the operator is applied on the non-zero values of `A`. `<op>` can be add, sub, mul, and div. \n",
    "\n",
    "There are two cases regarding the shape of `v`:\n",
    "\n",
    "1. `v` is a vector of shape `(1, A.shape[1])` or `(A.shape[1])`. In this case, `v` is broadcasted on the row dimension of `A`.\n",
    "\n",
    "2. `v` is a vector of shape `(A.shape[0], 1)`. In this case, `v` is broadcasted on the column dimension of `A`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T13:25:30.575307Z",
     "iopub.status.busy": "2024-11-03T13:25:30.575034Z",
     "iopub.status.idle": "2024-11-03T13:25:30.582385Z",
     "shell.execute_reply": "2024-11-03T13:25:30.581868Z"
    },
    "id": "xxf3s-uWBRR7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      "tensor([[ 0,  0,  0, 20],\n",
      "        [10,  0,  0,  0],\n",
      "        [ 0,  0, 30,  0]])\n",
      "v1:\n",
      "tensor([1, 2, 3, 4])\n",
      "sp_add_v(A, v1)\n",
      "tensor([[ 0,  0,  0, 24],\n",
      "        [11,  0,  0,  0],\n",
      "        [ 0,  0, 33,  0]])\n",
      "v2:\n",
      "tensor([[1, 2, 3, 4]])\n",
      "sp_add_v(A, v2)\n",
      "tensor([[ 0,  0,  0, 24],\n",
      "        [11,  0,  0,  0],\n",
      "        [ 0,  0, 33,  0]])\n",
      "v3:\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n",
      "sp_add_v(A, v3)\n",
      "tensor([[ 0,  0,  0, 21],\n",
      "        [12,  0,  0,  0],\n",
      "        [ 0,  0, 33,  0]])\n"
     ]
    }
   ],
   "source": [
    "i = torch.tensor([[1, 0, 2], [0, 3, 2]])\n",
    "val = torch.tensor([10, 20, 30])\n",
    "A = dglsp.spmatrix(i, val, shape=(3, 4))\n",
    "\n",
    "v1 = torch.tensor([1, 2, 3, 4])\n",
    "print(\"A:\")\n",
    "print(A.to_dense())\n",
    "\n",
    "print(\"v1:\")\n",
    "print(v1)\n",
    "\n",
    "print(\"sp_add_v(A, v1)\")\n",
    "print(dglsp.sp_add_v(A, v1).to_dense())\n",
    "\n",
    "v2 = v1.reshape(1, -1)\n",
    "print(\"v2:\")\n",
    "print(v2)\n",
    "\n",
    "print(\"sp_add_v(A, v2)\")\n",
    "print(dglsp.sp_add_v(A, v2).to_dense())\n",
    "\n",
    "v3 = torch.tensor([1, 2, 3]).reshape(-1, 1)\n",
    "print(\"v3:\")\n",
    "print(v3)\n",
    "\n",
    "print(\"sp_add_v(A, v3)\")\n",
    "print(dglsp.sp_add_v(A, v3).to_dense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TQJJlctZjYPv"
   },
   "source": [
    "### *Reduce operations*\n",
    "\n",
    "All DGL sparse reduce operations only consider non-zero elements. To distinguish them from dense PyTorch reduce operations that consider zero elements, we use name `smax`, `smin` and `smean` (`s` stands for sparse)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T13:25:30.584021Z",
     "iopub.status.busy": "2024-11-03T13:25:30.583749Z",
     "iopub.status.idle": "2024-11-03T13:25:30.591626Z",
     "shell.execute_reply": "2024-11-03T13:25:30.591101Z"
    },
    "id": "GhS49Js1jW4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 2., 4.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 3., 0.]])\n",
      "\n",
      "Reduce with reducer:sum along dim = 0:\n",
      "tensor([6., 1., 3.])\n",
      "\n",
      "Reduce with reducer:max along dim = 0:\n",
      "tensor([4., 1., 3.])\n",
      "\n",
      "Reduce with reducer:min along dim = 0:\n",
      "tensor([2., 1., 3.])\n",
      "\n",
      "Reduce with reducer:smean along dim = 0:\n",
      "tensor([3., 1., 3.])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = torch.tensor([[0, 1, 1, 2],\n",
    "                  [1, 0, 2, 0]])\n",
    "val = torch.tensor([1., 2., 3., 4.])\n",
    "A = dglsp.spmatrix(i, val)\n",
    "print(A.T.to_dense())\n",
    "print(\"\")\n",
    "\n",
    "# O1, O2 will have the same value.\n",
    "O1 = A.reduce(0, 'sum')\n",
    "O2 = A.sum(0)\n",
    "print(\"Reduce with reducer:sum along dim = 0:\")\n",
    "print(O1)\n",
    "print(\"\")\n",
    "\n",
    "# O3, O4 will have the same value.\n",
    "O3 = A.reduce(0, 'smax')\n",
    "O4 = A.smax(0)\n",
    "print(\"Reduce with reducer:max along dim = 0:\")\n",
    "print(O3)\n",
    "print(\"\")\n",
    "\n",
    "# O5, O6 will have the same value.\n",
    "O5 = A.reduce(0, 'smin')\n",
    "O6 = A.smin(0)\n",
    "print(\"Reduce with reducer:min along dim = 0:\")\n",
    "print(O5)\n",
    "print(\"\")\n",
    "\n",
    "# O7, O8 will have the same value.\n",
    "O7 = A.reduce(0, 'smean')\n",
    "O8 = A.smean(0)\n",
    "print(\"Reduce with reducer:smean along dim = 0:\")\n",
    "print(O7)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kanwnB7LOQui"
   },
   "source": [
    "### *Matrix transformations*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NiiXso9elM2p"
   },
   "source": [
    "*Sparse Matrix*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T13:25:30.593357Z",
     "iopub.status.busy": "2024-11-03T13:25:30.593084Z",
     "iopub.status.idle": "2024-11-03T13:25:30.598769Z",
     "shell.execute_reply": "2024-11-03T13:25:30.598244Z"
    },
    "id": "qJcmZHmf-oTY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 0.],\n",
      "        [2., 0., 3.],\n",
      "        [4., 0., 0.]])\n",
      "\n",
      "Get transpose of sparse matrix.\n",
      "tensor([[0., 2., 4.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 3., 0.]])\n",
      "\n",
      "Get a sparse matrix with the negation of the original nonzero values.\n",
      "tensor([[ 0., -1.,  0.],\n",
      "        [-2.,  0., -3.],\n",
      "        [-4.,  0.,  0.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = torch.tensor([[0, 1, 1, 2],\n",
    "                  [1, 0, 2, 0]])\n",
    "val = torch.tensor([1., 2., 3., 4.])\n",
    "A = dglsp.spmatrix(i, val)\n",
    "print(A.to_dense())\n",
    "print(\"\")\n",
    "\n",
    "print(\"Get transpose of sparse matrix.\")\n",
    "print(A.T.to_dense())\n",
    "# Alias\n",
    "# A.transpose()\n",
    "# A.t()\n",
    "print(\"\")\n",
    "\n",
    "print(\"Get a sparse matrix with the negation of the original nonzero values.\")\n",
    "print(A.neg().to_dense())\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4uQlDFb0Uzto"
   },
   "source": [
    "### *Matrix multiplication*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THWE30v6WpAk"
   },
   "source": [
    "**matmul(A, B), equivalent to A @ B**\n",
    "\n",
    "Matrix multiplication on sparse matrices and/or dense matrix. There are two cases as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VxyykR-vX7lF"
   },
   "source": [
    "**SparseMatrix @ SparseMatrix -> SparseMatrix:**\n",
    "\n",
    "For a $L \\times M$ sparse matrix A and a $M \\times N$ sparse matrix B, the shape of `A @ B` will be $L \\times N$ sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T13:25:30.600537Z",
     "iopub.status.busy": "2024-11-03T13:25:30.600265Z",
     "iopub.status.idle": "2024-11-03T13:25:30.610355Z",
     "shell.execute_reply": "2024-11-03T13:25:30.609823Z"
    },
    "id": "XRDFC2rOYQM4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1:\n",
      "tensor([[0., 0., 0.],\n",
      "        [1., 0., 2.],\n",
      "        [3., 0., 0.]])\n",
      "A2:\n",
      "tensor([[4., 0., 0.],\n",
      "        [0., 0., 5.],\n",
      "        [0., 6., 0.]])\n",
      "D1:\n",
      "tensor([[-1.,  0.,  0.],\n",
      "        [ 0., -2.,  0.],\n",
      "        [ 0.,  0., -3.]])\n",
      "D2:\n",
      "tensor([[-4.,  0.,  0.],\n",
      "        [ 0., -5.,  0.],\n",
      "        [ 0.,  0., -6.]])\n",
      "A1 @ A2:\n",
      "tensor([[ 0.,  0.,  0.],\n",
      "        [ 4., 12.,  0.],\n",
      "        [12.,  0.,  0.]])\n",
      "A1 @ D1:\n",
      "tensor([[ 0.,  0.,  0.],\n",
      "        [-1.,  0., -6.],\n",
      "        [-3.,  0.,  0.]])\n",
      "D1 @ A1:\n",
      "tensor([[ 0.,  0.,  0.],\n",
      "        [-2.,  0., -4.],\n",
      "        [-9.,  0.,  0.]])\n",
      "D1 @ D2:\n",
      "tensor([[ 4.,  0.,  0.],\n",
      "        [ 0., 10.,  0.],\n",
      "        [ 0.,  0., 18.]])\n"
     ]
    }
   ],
   "source": [
    "i = torch.tensor([[1, 1, 2],\n",
    "                  [0, 2, 0]])\n",
    "val = torch.tensor([1., 2., 3.])\n",
    "A1 = dglsp.spmatrix(i, val, shape=(3, 3))\n",
    "print(\"A1:\")\n",
    "print(A1.to_dense())\n",
    "\n",
    "i = torch.tensor([[0, 1, 2],\n",
    "                  [0, 2, 1]])\n",
    "val = torch.tensor([4., 5., 6.])\n",
    "A2 = dglsp.spmatrix(i, val, shape=(3, 3))\n",
    "print(\"A2:\")\n",
    "print(A2.to_dense())\n",
    "\n",
    "val = torch.tensor([-1., -2., -3.])\n",
    "D1 = dglsp.diag(val)\n",
    "print(\"D1:\")\n",
    "print(D1.to_dense())\n",
    "\n",
    "val = torch.tensor([-4., -5., -6.])\n",
    "D2 = dglsp.diag(val)\n",
    "print(\"D2:\")\n",
    "print(D2.to_dense())\n",
    "\n",
    "print(\"A1 @ A2:\")\n",
    "print((A1 @ A2).to_dense())\n",
    "\n",
    "print(\"A1 @ D1:\")\n",
    "print((A1 @ D1).to_dense())\n",
    "\n",
    "print(\"D1 @ A1:\")\n",
    "print((D1 @ A1).to_dense())\n",
    "\n",
    "print(\"D1 @ D2:\")\n",
    "print((D1 @ D2).to_dense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g13fG8nvaVOt"
   },
   "source": [
    "**SparseMatrix @ Tensor -> Tensor:**\n",
    "\n",
    "For a $L \\times M$ sparse matrix A and a $M \\times N$ dense matrix B, the shape of `A @ B` will be $L \\times N$ dense matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T13:25:30.612097Z",
     "iopub.status.busy": "2024-11-03T13:25:30.611800Z",
     "iopub.status.idle": "2024-11-03T13:25:30.619019Z",
     "shell.execute_reply": "2024-11-03T13:25:30.618493Z"
    },
    "id": "FcQ-CnqdlgWF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      "tensor([[0., 0., 0.],\n",
      "        [1., 0., 2.],\n",
      "        [3., 0., 0.]])\n",
      "D:\n",
      "tensor([[-1.,  0.,  0.],\n",
      "        [ 0., -2.,  0.],\n",
      "        [ 0.,  0., -3.]])\n",
      "X:\n",
      "tensor([[11., 22.],\n",
      "        [33., 44.],\n",
      "        [55., 66.]])\n",
      "A @ X:\n",
      "tensor([[  0.,   0.],\n",
      "        [121., 154.],\n",
      "        [ 33.,  66.]])\n",
      "D @ X:\n",
      "tensor([[ -11.,  -22.],\n",
      "        [ -66.,  -88.],\n",
      "        [-165., -198.]])\n"
     ]
    }
   ],
   "source": [
    "i = torch.tensor([[1, 1, 2],\n",
    "                  [0, 2, 0]])\n",
    "val = torch.tensor([1., 2., 3.])\n",
    "A = dglsp.spmatrix(i, val, shape=(3, 3))\n",
    "print(\"A:\")\n",
    "print(A.to_dense())\n",
    "\n",
    "val = torch.tensor([-1., -2., -3.])\n",
    "D = dglsp.diag(val)\n",
    "print(\"D:\")\n",
    "print(D.to_dense())\n",
    "\n",
    "X = torch.tensor([[11., 22.], [33., 44.], [55., 66.]])\n",
    "print(\"X:\")\n",
    "print(X)\n",
    "\n",
    "print(\"A @ X:\")\n",
    "print(A @ X)\n",
    "\n",
    "print(\"D @ X:\")\n",
    "print(D @ X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_KZiULLbmEZE"
   },
   "source": [
    "This operator also supports batched sparse-dense matrix multiplication. The sparse matrix A should have shape $L \\times M$, where the non-zero values are vectors of length $K$. The dense matrix B should have shape $M \\times N \\times K$. The output is a dense matrix of shape $L \\times N \\times K$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T13:25:30.620857Z",
     "iopub.status.busy": "2024-11-03T13:25:30.620562Z",
     "iopub.status.idle": "2024-11-03T13:25:30.627127Z",
     "shell.execute_reply": "2024-11-03T13:25:30.626590Z"
    },
    "id": "ZUzXQk7Ab2wG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 1.],\n",
      "         [0., 0.],\n",
      "         [2., 2.]],\n",
      "\n",
      "        [[3., 3.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]]])\n",
      "X:\n",
      "tensor([[[1., 1.],\n",
      "         [1., 2.]],\n",
      "\n",
      "        [[1., 3.],\n",
      "         [1., 4.]],\n",
      "\n",
      "        [[1., 5.],\n",
      "         [1., 6.]]])\n",
      "A @ X:\n",
      "tensor([[[ 0.,  0.],\n",
      "         [ 0.,  0.]],\n",
      "\n",
      "        [[ 3., 11.],\n",
      "         [ 3., 14.]],\n",
      "\n",
      "        [[ 3.,  3.],\n",
      "         [ 3.,  6.]]])\n"
     ]
    }
   ],
   "source": [
    "i = torch.tensor([[1, 1, 2],\n",
    "                  [0, 2, 0]])\n",
    "val = torch.tensor([[1., 1.], [2., 2.], [3., 3.]])\n",
    "A = dglsp.spmatrix(i, val, shape=(3, 3))\n",
    "print(\"A:\")\n",
    "print(A.to_dense())\n",
    "\n",
    "X = torch.tensor([[[1., 1.], [1., 2.]],\n",
    "                  [[1., 3.], [1., 4.]],\n",
    "                  [[1., 5.], [1., 6.]]])\n",
    "print(\"X:\")\n",
    "print(X)\n",
    "\n",
    "print(\"A @ X:\")\n",
    "print(A @ X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qO_8f_vhPKtf"
   },
   "source": [
    "**Sampled-Dense-Dense Matrix Multiplication (SDDMM)**\n",
    "\n",
    "``sddmm`` matrix-multiplies two dense matrices X1 and X2, then elementwise-multiplies the result with sparse matrix A at the nonzero locations. This is designed for sparse matrix with scalar values.\n",
    "\n",
    "$$out = (X_1 @ X_2) * A$$\n",
    "\n",
    "For a $L \\times N$ sparse matrix A, a $L \\times M$ dense matrix X1 and a $M \\times N$ dense matrix X2, `sddmm(A, X1, X2)` will be a $L \\times N$ sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T13:25:30.628937Z",
     "iopub.status.busy": "2024-11-03T13:25:30.628661Z",
     "iopub.status.idle": "2024-11-03T13:25:30.635068Z",
     "shell.execute_reply": "2024-11-03T13:25:30.634517Z"
    },
    "id": "3ZIFV0TgPhwH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 1., 2.],\n",
      "        [0., 0., 0., 3.]])\n",
      "X1:\n",
      "tensor([[ 0.0484, -1.5266,  1.1366, -0.8318, -0.6150],\n",
      "        [ 3.1324, -0.5624, -1.3767,  1.1596,  0.5167],\n",
      "        [-1.7818,  0.4365, -1.1810,  2.5656, -0.5180]])\n",
      "X2:\n",
      "tensor([[-2.0175e+00, -2.1656e-01,  9.1631e-01, -9.5077e-01],\n",
      "        [ 1.3085e+00,  2.3575e-01, -9.7387e-02, -1.1884e-01],\n",
      "        [-2.1378e+00, -3.7163e-01, -2.2789e+00,  1.5864e-01],\n",
      "        [ 3.6455e-01,  1.5680e-03, -2.1718e+00,  1.4481e+00],\n",
      "        [-1.6069e+00, -2.2999e+00,  1.5949e+00,  1.5981e+00]])\n",
      "dglsp.sddmm(A, X1, X2):\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  4.3680, -1.2493],\n",
      "        [ 0.0000,  0.0000,  0.0000, 13.0275]])\n"
     ]
    }
   ],
   "source": [
    "i = torch.tensor([[1, 1, 2],\n",
    "                  [2, 3, 3]])\n",
    "val = torch.tensor([1., 2., 3.])\n",
    "A = dglsp.spmatrix(i, val, (3, 4))\n",
    "print(\"A:\")\n",
    "print(A.to_dense())\n",
    "\n",
    "X1 = torch.randn(3, 5)\n",
    "X2 = torch.randn(5, 4)\n",
    "print(\"X1:\")\n",
    "print(X1)\n",
    "print(\"X2:\")\n",
    "print(X2)\n",
    "\n",
    "O = dglsp.sddmm(A, X1, X2)\n",
    "print(\"dglsp.sddmm(A, X1, X2):\")\n",
    "print(O.to_dense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RmNmXU_ZqyF7"
   },
   "source": [
    "This operator also supports batched sampled-dense-dense matrix multiplication. For a $L \\times N$ sparse matrix A with non-zero vector values of length $𝐾$, a $L \\times M \\times K$ dense matrix X1 and a $M \\times N \\times K$ dense matrix X2, `sddmm(A, X1, X2)` will be a $L \\times N \\times K$ sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T13:25:30.636879Z",
     "iopub.status.busy": "2024-11-03T13:25:30.636593Z",
     "iopub.status.idle": "2024-11-03T13:25:30.643543Z",
     "shell.execute_reply": "2024-11-03T13:25:30.643020Z"
    },
    "id": "DuSAjamyrIO_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      "tensor([[[0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [0., 0.],\n",
      "         [1., 1.],\n",
      "         [2., 2.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [3., 3.]]])\n",
      "X1:\n",
      "tensor([[[-0.2960,  0.9855],\n",
      "         [ 0.0339, -0.1258],\n",
      "         [-0.8344, -0.1373],\n",
      "         [ 0.7076, -0.5708],\n",
      "         [ 0.5786, -0.7368]],\n",
      "\n",
      "        [[ 0.6203,  0.1708],\n",
      "         [-0.4422,  0.7654],\n",
      "         [-0.0293, -0.4368],\n",
      "         [ 0.6996, -1.6403],\n",
      "         [-0.5875,  0.8983]],\n",
      "\n",
      "        [[-0.6294, -1.4993],\n",
      "         [ 1.1393,  0.0723],\n",
      "         [-1.1075,  0.2379],\n",
      "         [ 0.8131, -1.3527],\n",
      "         [-2.1155,  0.6518]]])\n",
      "X2:\n",
      "tensor([[[-0.0697,  1.8751],\n",
      "         [-0.5200, -1.4429],\n",
      "         [-0.3471, -1.2435],\n",
      "         [-2.1393, -1.4808]],\n",
      "\n",
      "        [[-0.9820,  0.1927],\n",
      "         [ 1.1151,  0.1746],\n",
      "         [ 0.1930,  0.2057],\n",
      "         [-1.5913, -1.8893]],\n",
      "\n",
      "        [[-0.4226, -0.4567],\n",
      "         [ 0.5258,  0.2984],\n",
      "         [-0.9724, -0.6209],\n",
      "         [-0.8252,  0.3300]],\n",
      "\n",
      "        [[ 0.7503, -0.4183],\n",
      "         [-0.5273,  0.9611],\n",
      "         [-0.9842,  0.5509],\n",
      "         [ 1.6781,  0.0843]],\n",
      "\n",
      "        [[ 2.0414,  0.7043],\n",
      "         [-1.5072, -0.6657],\n",
      "         [-0.4325,  1.4137],\n",
      "         [-0.6163, -1.2256]]])\n",
      "dglsp.sddmm(A, X1, X2):\n",
      "tensor([[[ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [-0.7066,  0.5826],\n",
      "         [ 1.8737, -6.1646]],\n",
      "\n",
      "        [[ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 9.3474,  3.7478]]])\n"
     ]
    }
   ],
   "source": [
    "i = torch.tensor([[1, 1, 2],\n",
    "                  [2, 3, 3]])\n",
    "val = torch.tensor([[1., 1.], [2., 2.], [3., 3.]])\n",
    "A = dglsp.spmatrix(i, val, (3, 4))\n",
    "print(\"A:\")\n",
    "print(A.to_dense())\n",
    "\n",
    "X1 = torch.randn(3, 5, 2)\n",
    "X2 = torch.randn(5, 4, 2)\n",
    "print(\"X1:\")\n",
    "print(X1)\n",
    "print(\"X2:\")\n",
    "print(X2)\n",
    "\n",
    "O = dglsp.sddmm(A, X1, X2)\n",
    "print(\"dglsp.sddmm(A, X1, X2):\")\n",
    "print(O.to_dense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fVkbTT28ZzPr"
   },
   "source": [
    "## Non-linear activation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XuaNdFO7XG2r"
   },
   "source": [
    "### Element-wise functions\n",
    "\n",
    "Most activation functions are element-wise and can be further grouped into two categories:\n",
    "\n",
    "**Sparse-preserving functions** such as `sin()`, `tanh()`, `sigmoid()`, `relu()`, etc. You can directly apply them on the `val` tensor of the sparse matrix and then recreate a new matrix of the same sparsity using `val_like`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T13:25:30.645267Z",
     "iopub.status.busy": "2024-11-03T13:25:30.644984Z",
     "iopub.status.idle": "2024-11-03T13:25:30.649891Z",
     "shell.execute_reply": "2024-11-03T13:25:30.649377Z"
    },
    "id": "GZkCJJ0TX0cI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0361,  0.0000],\n",
      "        [ 1.6200,  0.0000, -0.9527],\n",
      "        [ 0.0060,  0.0000,  0.0000]])\n",
      "Apply tanh.\n",
      "tensor([[ 0.0000,  0.0361,  0.0000],\n",
      "        [ 0.9246,  0.0000, -0.7410],\n",
      "        [ 0.0060,  0.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "i = torch.tensor([[0, 1, 1, 2],\n",
    "                  [1, 0, 2, 0]])\n",
    "val = torch.randn(4)\n",
    "A = dglsp.spmatrix(i, val)\n",
    "print(A.to_dense())\n",
    "\n",
    "print(\"Apply tanh.\")\n",
    "A_new = dglsp.val_like(A, torch.tanh(A.val))\n",
    "print(A_new.to_dense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i92lhMEnYas3"
   },
   "source": [
    "**Non-sparse-preserving functions** such as `exp()`, `cos()`, etc. You can first convert the sparse matrix to dense before applying the functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T13:25:30.651614Z",
     "iopub.status.busy": "2024-11-03T13:25:30.651327Z",
     "iopub.status.idle": "2024-11-03T13:25:30.656063Z",
     "shell.execute_reply": "2024-11-03T13:25:30.655540Z"
    },
    "id": "sroJpzRNYZq5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.3108,  0.0000],\n",
      "        [ 0.4239,  0.0000, -1.0309],\n",
      "        [-0.3722,  0.0000,  0.0000]])\n",
      "Apply exp.\n",
      "tensor([[1.0000, 1.3645, 1.0000],\n",
      "        [1.5279, 1.0000, 0.3567],\n",
      "        [0.6892, 1.0000, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "i = torch.tensor([[0, 1, 1, 2],\n",
    "                  [1, 0, 2, 0]])\n",
    "val = torch.randn(4)\n",
    "A = dglsp.spmatrix(i, val)\n",
    "print(A.to_dense())\n",
    "\n",
    "print(\"Apply exp.\")\n",
    "A_new = A.to_dense().exp()\n",
    "print(A_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8OQZReVXpo3"
   },
   "source": [
    "### Softmax\n",
    "\n",
    "Apply row-wise softmax to the nonzero entries of the sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T13:25:30.657716Z",
     "iopub.status.busy": "2024-11-03T13:25:30.657436Z",
     "iopub.status.idle": "2024-11-03T13:25:30.662541Z",
     "shell.execute_reply": "2024-11-03T13:25:30.662015Z"
    },
    "id": "CQaKgzCJULjt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseMatrix(indices=tensor([[0, 1, 1, 2],\n",
      "                             [1, 0, 2, 0]]),\n",
      "             values=tensor([1.0000, 0.2689, 0.7311, 1.0000]),\n",
      "             shape=(3, 3), nnz=4)\n",
      "In dense format:\n",
      "tensor([[0.0000, 1.0000, 0.0000],\n",
      "        [0.2689, 0.0000, 0.7311],\n",
      "        [1.0000, 0.0000, 0.0000]])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = torch.tensor([[0, 1, 1, 2],\n",
    "                  [1, 0, 2, 0]])\n",
    "val = torch.tensor([1., 2., 3., 4.])\n",
    "A = dglsp.spmatrix(i, val)\n",
    "\n",
    "print(A.softmax())\n",
    "print(\"In dense format:\")\n",
    "print(A.softmax().to_dense())\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1iBNlJVYz3zi"
   },
   "source": [
    "## Exercise \\#1\n",
    "\n",
    "*Let's test what you've learned. Feel free to [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/dmlc/dgl/blob/master/notebooks/sparse/quickstart.ipynb).*\n",
    "\n",
    "Given a sparse symmetrical adjacency matrix $A$, calculate its symmetrically normalized adjacency matrix: $$norm = \\bar{D}^{-\\frac{1}{2}}\\bar{A}\\bar{D}^{-\\frac{1}{2}}$$\n",
    "\n",
    "Where $\\bar{A} = A + I$, $I$ is the identity matrix, and $\\bar{D}$ is the diagonal node degree matrix of $\\bar{A}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T13:25:30.664320Z",
     "iopub.status.busy": "2024-11-03T13:25:30.664036Z",
     "iopub.status.idle": "2024-11-03T13:25:30.667425Z",
     "shell.execute_reply": "2024-11-03T13:25:30.666881Z"
    },
    "id": "0dDhfbJo0ByV"
   },
   "outputs": [],
   "source": [
    "i = torch.tensor([[0, 0, 1, 1, 2, 2, 3],\n",
    "                  [1, 3, 2, 5, 3, 5, 4]])\n",
    "asym_A = dglsp.spmatrix(i, shape=(6, 6))\n",
    "# Step 1: create symmetrical adjacency matrix A from asym_A.\n",
    "# A =\n",
    "\n",
    "# Step 2: calculate A_hat from A.\n",
    "# A_hat =\n",
    "\n",
    "# Step 3: diagonal node degree matrix of A_hat\n",
    "# D_hat =\n",
    "\n",
    "# Step 4: calculate the norm from D_hat and A_hat.\n",
    "# norm = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yfEVQBUuI-cE"
   },
   "source": [
    "## Exercise \\#2\n",
    "\n",
    "Let's implement a simplified version of the Graph Attention Network (GAT) layer.\n",
    "\n",
    "A GAT layer has two inputs: the adjacency matrix $A$ and the node input features $X$.  The idea of GAT layer is to update each node's representation with a weighted average of the node's own representation and its neighbors' representations.  In particular, when computing the output for node $i$, the GAT layer does the following:\n",
    "1. Compute the scores $S_{ij}$ representing the attention logit from neighbor $j$ to node $i$.  $S_{ij}$ is a function of $i$ and $j$'s input features $X_i$ and $X_j$: $$S_{ij} = LeakyReLU(X_i^\\top v_1 + X_j^\\top v_2)$$, where $v_1$ and $v_2$ are trainable vectors.\n",
    "2. Compute a softmax attention $R_{ij} = \\exp S_{ij} / \\left( \\sum_{j' \\in \\mathcal{N}_i} s_{ij'} \\right)$, where $\\mathcal{N}_j$ means the neighbors of $j$.  This means that $R$ is a row-wise softmax attention of $S$.\n",
    "3. Compute the weighted average $H_i = \\sum_{j' : j' \\in \\mathcal{N}_i} R_{j'} X_{j'} W$, where $W$ is a trainable matrix.\n",
    "\n",
    "The following code defined all the parameters you need but only completes step 1.  Could you implement step 2 and step 3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T13:25:30.669085Z",
     "iopub.status.busy": "2024-11-03T13:25:30.668804Z",
     "iopub.status.idle": "2024-11-03T13:25:30.673529Z",
     "shell.execute_reply": "2024-11-03T13:25:30.673001Z"
    },
    "id": "pYrgSxq6La5c"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimplifiedGAT(nn.Module):\n",
    "    def __init__(self, in_size, out_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.W = nn.Parameter(torch.randn(in_size, out_size))\n",
    "        self.v1 = nn.Parameter(torch.randn(in_size))\n",
    "        self.v2 = nn.Parameter(torch.randn(in_size))\n",
    "\n",
    "    def forward(self, A, X):\n",
    "        # A: A sparse matrix with size (N, N).  A[i, j] represent the edge from j to i.\n",
    "        # X: A dense matrix with size (N, D)\n",
    "        # Step 1: compute S[i, j]\n",
    "        Xv1 = X @ self.v1\n",
    "        Xv2 = X @ self.v2\n",
    "        s = F.leaky_relu(Xv1[A.col] + Xv2[A.row])\n",
    "        S = dglsp.val_like(A, s)\n",
    "\n",
    "        # Step 2: compute R[i, j] which is the row-wise attention of $S$.\n",
    "        # EXERCISE: replace the statement below.\n",
    "        R = S\n",
    "\n",
    "        # Step 3: compute H.\n",
    "        # EXERCISE: replace the statement below.\n",
    "        H = X\n",
    "\n",
    "        return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T13:25:30.675187Z",
     "iopub.status.busy": "2024-11-03T13:25:30.674874Z",
     "iopub.status.idle": "2024-11-03T13:25:30.678247Z",
     "shell.execute_reply": "2024-11-03T13:25:30.677728Z"
    },
    "id": "qjcXiidYCqGK"
   },
   "outputs": [],
   "source": [
    "# Test:\n",
    "# Let's use the symmetric A created above.\n",
    "X = torch.randn(6, 20)\n",
    "module = SimplifiedGAT(20, 10)\n",
    "Y = module(A, X)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
