<!DOCTYPE html>

<html class="writer-html5" data-content_root="../../../" lang="en">
<head>
<meta charset="utf-8"/><meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Transformer as a Graph Neural Network ‚Äî DGL 2.4 documentation</title>
<link href="../../../_static/pygments.css?v=80d5e7a1" rel="stylesheet" type="text/css"/>
<link href="../../../_static/css/theme.css?v=19f00094" rel="stylesheet" type="text/css"/>
<link href="../../../_static/graphviz.css?v=fd3f3429" rel="stylesheet" type="text/css"/>
<link href="../../../_static/copybutton.css?v=76b2166b" rel="stylesheet" type="text/css"/>
<link href="../../../_static/sg_gallery.css?v=d2d258e8" rel="stylesheet" type="text/css"/>
<link href="../../../_static/sg_gallery-binder.css?v=f4aeca0c" rel="stylesheet" type="text/css"/>
<link href="../../../_static/sg_gallery-dataframe.css?v=2082cf3c" rel="stylesheet" type="text/css"/>
<link href="../../../_static/sg_gallery-rendered-html.css?v=1277b6f3" rel="stylesheet" type="text/css"/>
<link href="../../../_static/css/custom.css?v=0bf289b5" rel="stylesheet" type="text/css"/>
<!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
<script src="../../../_static/jquery.js?v=5d32c60e"></script>
<script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
<script src="../../../_static/documentation_options.js?v=9caaf7ed"></script>
<script src="../../../_static/doctools.js?v=9a2dae69"></script>
<script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
<script src="../../../_static/clipboard.min.js?v=a7894cd8"></script>
<script src="../../../_static/copybutton.js?v=ccdb6887"></script>
<script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
<script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
<script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script src="../../../_static/js/theme.js"></script>
<link href="../../../genindex.html" rel="index" title="Index"/>
<link href="../../../search.html" rel="search" title="Search"/>
<link href="../../../api/python/dgl.html" rel="next" title="dgl"/>
<link href="2_capsule.html" rel="prev" title="Capsule Network"/>
</head>
<body class="wy-body-for-nav">
<div class="wy-grid-for-nav">
<nav class="wy-nav-side" data-toggle="wy-nav-shift">
<div class="wy-side-scroll">
<div class="wy-side-nav-search">
<a class="icon icon-home" href="../../../index.html">
            DGL
          </a>
<div class="version">
                2.4
              </div>
<div role="search">
<form action="../../../search.html" class="wy-form" id="rtd-search-form" method="get">
<input aria-label="Search docs" name="q" placeholder="Search docs" type="text"/>
<input name="check_keywords" type="hidden" value="yes"/>
<input name="area" type="hidden" value="default"/>
</form>
</div>
</div><div aria-label="Navigation menu" class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation">
<p class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../install/index.html">Install and Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blitz/index.html">A Blitz Introduction to DGL</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Materials</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../stochastic_training/index.html">üÜï Stochastic Training of GNNs with GraphBolt</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../guide/index.html">User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../guide_cn/index.html">Áî®Êà∑ÊåáÂçó„ÄêÂåÖÂê´ËøáÊó∂‰ø°ÊÅØ„Äë</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../guide_ko/index.html">ÏÇ¨Ïö©Ïûê Í∞ÄÏù¥Îìú[ÏãúÎåÄÏóê Îí§Ï≥êÏßÑ]</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../graphtransformer/index.html">üÜï Tutorial: Graph Transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notebooks/sparse/index.html">Tutorials: dgl.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cpu/index.html">Training on CPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../multi/index.html">Training on Multiple GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dist/index.html">Distributed training</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Paper Study with DGL</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../1_gnn/index.html">Graph neural networks and its variants</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2_small_graph/index.html">Batching many small graphs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../3_generative_model/index.html">Generative models</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="index.html">Revisit classic models from a graph perspective</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="2_capsule.html">Capsule Network</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Transformer as a Graph Neural Network</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.html">dgl</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.data.html">dgl.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.dataloading.html">dgl.dataloading</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.DGLGraph.html">dgl.DGLGraph</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.distributed.html">dgl.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.function.html">dgl.function</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.geometry.html">dgl.geometry</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.graphbolt.html">üÜï dgl.graphbolt</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/nn-pytorch.html">dgl.nn (PyTorch)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/nn.functional.html">dgl.nn.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.ops.html">dgl.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.optim.html">dgl.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.sampling.html">dgl.sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.sparse_v0.html">dgl.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.multiprocessing.html">dgl.multiprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/transforms.html">dgl.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/udf.html">User-defined Functions</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../contribute.html">Contribute to DGL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../developer/ffi.html">DGL Foreign Function Interface (FFI)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../performance.html">Performance Benchmarks</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Misc</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../faq.html">Frequently Asked Questions (FAQ)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../env_var.html">Environment Variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../resources.html">Resources</a></li>
</ul>
</div>
</div>
</nav>
<section class="wy-nav-content-wrap" data-toggle="wy-nav-shift"><nav aria-label="Mobile navigation menu" class="wy-nav-top">
<i class="fa fa-bars" data-toggle="wy-nav-top"></i>
<a href="../../../index.html">DGL</a>
</nav>
<div class="wy-nav-content">
<div class="rst-content">
<div aria-label="Page navigation" role="navigation">
<ul class="wy-breadcrumbs">
<li><a aria-label="Home" class="icon icon-home" href="../../../index.html"></a></li>
<li class="breadcrumb-item"><a href="../index.html">Paper Study with DGL</a></li>
<li class="breadcrumb-item"><a href="index.html">Revisit classic models from a graph perspective</a></li>
<li class="breadcrumb-item active">Transformer as a Graph Neural Network</li>
<li class="wy-breadcrumbs-aside">
<a href="../../../_sources/tutorials/models/4_old_wines/7_transformer.rst.txt" rel="nofollow"> View page source</a>
</li>
</ul>
<hr/>
</div>
<div class="document" itemscope="itemscope" itemtype="http://schema.org/Article" role="main">
<div itemprop="articleBody">
<div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-tutorials-models-4-old-wines-7-transformer-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code.</p>
</div>
<section class="sphx-glr-example-title" id="transformer-as-a-graph-neural-network">
<span id="model-transformer"></span><span id="sphx-glr-tutorials-models-4-old-wines-7-transformer-py"></span><h1>Transformer as a Graph Neural Network<a class="headerlink" href="#transformer-as-a-graph-neural-network" title="Link to this heading">ÔÉÅ</a></h1>
<p><strong>Author</strong>: Zihao Ye, Jinjing Zhou, Qipeng Guo, Quan Gan, Zheng Zhang</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The tutorial aims at gaining insights into the paper, with code as a mean
of explanation. The implementation thus is NOT optimized for running
efficiency. For recommended implementation, please refer to the <a class="reference external" href="https://github.com/dmlc/dgl/tree/master/examples">official
examples</a>.</p>
</div>
<p>In this tutorial, you learn about a simplified implementation of the Transformer model.
You can see highlights of the most important design points. For instance, there is
only single-head attention. The complete code can be found
<a class="reference external" href="https://github.com/dmlc/dgl/tree/master/examples/pytorch/transformer">here</a>.</p>
<p>The overall structure is similar to the one from the research papaer <a class="reference external" href="http://nlp.seas.harvard.edu/2018/04/03/attention.html">Annotated
Transformer</a>.</p>
<p>The Transformer model, as a replacement of CNN/RNN architecture for
sequence modeling, was introduced in the research paper: <a class="reference external" href="https://arxiv.org/pdf/1706.03762.pdf">Attention is All
You Need</a>. It improved the
state of the art for machine translation as well as natural language
inference task
(<a class="reference external" href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf">GPT</a>).
Recent work on pre-training Transformer with large scale corpus
(<a class="reference external" href="https://arxiv.org/pdf/1810.04805.pdf">BERT</a>) supports that it is
capable of learning high-quality semantic representation.</p>
<p>The interesting part of Transformer is its extensive employment of
attention. The classic use of attention comes from machine translation
model, where the output token attends to all input tokens.</p>
<p>Transformer additionally applies <em>self-attention</em> in both decoder and
encoder. This process forces words relate to each other to combine
together, irrespective of their positions in the sequence. This is
different from RNN-based model, where words (in the source sentence) are
combined along the chain, which is thought to be too constrained.</p>
<section id="attention-layer-of-transformer">
<h2>Attention layer of Transformer<a class="headerlink" href="#attention-layer-of-transformer" title="Link to this heading">ÔÉÅ</a></h2>
<p>In the attention layer of Transformer, for each node the module learns to
assign weights on its in-coming edges. For node pair <span class="math notranslate nohighlight">\((i, j)\)</span>
(from <span class="math notranslate nohighlight">\(i\)</span> to <span class="math notranslate nohighlight">\(j\)</span>) with node
<span class="math notranslate nohighlight">\(x_i, x_j \in \mathbb{R}^n\)</span>, the score of their connection is
defined as follows:</p>
<div class="math notranslate nohighlight">
\[\begin{split}q_j = W_q\cdot x_j \\
k_i = W_k\cdot x_i\\
v_i = W_v\cdot x_i\\
\textrm{score} = q_j^T k_i\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(W_q, W_k, W_v \in \mathbb{R}^{n\times d_k}\)</span> map the
representations <span class="math notranslate nohighlight">\(x\)</span> to ‚Äúquery‚Äù, ‚Äúkey‚Äù, and ‚Äúvalue‚Äù space
respectively.</p>
<p>There are other possibilities to implement the score function. The dot
product measures the similarity of a given query <span class="math notranslate nohighlight">\(q_j\)</span> and a key
<span class="math notranslate nohighlight">\(k_i\)</span>: if <span class="math notranslate nohighlight">\(j\)</span> needs the information stored in <span class="math notranslate nohighlight">\(i\)</span>, the
query vector at position <span class="math notranslate nohighlight">\(j\)</span> (<span class="math notranslate nohighlight">\(q_j\)</span>) is supposed to be close
to key vector at position <span class="math notranslate nohighlight">\(i\)</span> (<span class="math notranslate nohighlight">\(k_i\)</span>).</p>
<p>The score is then used to compute the sum of the incoming values,
normalized over the weights of edges, stored in <span class="math notranslate nohighlight">\(\textrm{wv}\)</span>.
Then apply an affine layer to <span class="math notranslate nohighlight">\(\textrm{wv}\)</span> to get the output
<span class="math notranslate nohighlight">\(o\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}w_{ji} = \frac{\exp\{\textrm{score}_{ji} \}}{\sum\limits_{(k, i)\in E}\exp\{\textrm{score}_{ki} \}} \\
\textrm{wv}_i = \sum_{(k, i)\in E} w_{ki} v_k \\
o = W_o\cdot \textrm{wv} \\\end{split}\]</div>
<section id="multi-head-attention-layer">
<h3>Multi-head attention layer<a class="headerlink" href="#multi-head-attention-layer" title="Link to this heading">ÔÉÅ</a></h3>
<p>In Transformer, attention is <em>multi-headed</em>. A head is very much like a
channel in a convolutional network. The multi-head attention consists of
multiple attention heads, in which each head refers to a single
attention module. <span class="math notranslate nohighlight">\(\textrm{wv}^{(i)}\)</span> for all the heads are
concatenated and mapped to output <span class="math notranslate nohighlight">\(o\)</span> with an affine layer:</p>
<div class="math notranslate nohighlight">
\[o = W_o \cdot \textrm{concat}\left(\left[\textrm{wv}^{(0)}, \textrm{wv}^{(1)}, \cdots, \textrm{wv}^{(h)}\right]\right)\]</div>
<p>The code below wraps necessary components for multi-head attention, and
provides two interfaces.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">get</span></code> maps state ‚Äòx‚Äô, to query, key and value, which is required by
following steps(<code class="docutils literal notranslate"><span class="pre">propagate_attention</span></code>).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_o</span></code> maps the updated value after attention to the output
<span class="math notranslate nohighlight">\(o\)</span> for post-processing.</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MultiHeadAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="s2">"Multi-Head Attention"</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">dim_model</span><span class="p">):</span>
        <span class="s2">"h: number of heads; dim_model: hidden dimension"</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MultiHeadAttention</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d_k</span> <span class="o">=</span> <span class="n">dim_model</span> <span class="o">//</span> <span class="n">h</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h</span> <span class="o">=</span> <span class="n">h</span>
        <span class="c1"># W_q, W_k, W_v, W_o</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linears</span> <span class="o">=</span> <span class="n">clones</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dim_model</span><span class="p">,</span> <span class="n">dim_model</span><span class="p">),</span> <span class="mi">4</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">fields</span><span class="o">=</span><span class="s1">'qkv'</span><span class="p">):</span>
        <span class="s2">"Return a dict of queries / keys / values."</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="s1">'q'</span> <span class="ow">in</span> <span class="n">fields</span><span class="p">:</span>
            <span class="n">ret</span><span class="p">[</span><span class="s1">'q'</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linears</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_k</span><span class="p">)</span>
        <span class="k">if</span> <span class="s1">'k'</span> <span class="ow">in</span> <span class="n">fields</span><span class="p">:</span>
            <span class="n">ret</span><span class="p">[</span><span class="s1">'k'</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linears</span><span class="p">[</span><span class="mi">1</span><span class="p">](</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_k</span><span class="p">)</span>
        <span class="k">if</span> <span class="s1">'v'</span> <span class="ow">in</span> <span class="n">fields</span><span class="p">:</span>
            <span class="n">ret</span><span class="p">[</span><span class="s1">'v'</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linears</span><span class="p">[</span><span class="mi">2</span><span class="p">](</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_k</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ret</span>

    <span class="k">def</span> <span class="nf">get_o</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="s2">"get output of the multi-head attention"</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">linears</span><span class="p">[</span><span class="mi">3</span><span class="p">](</span><span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
</section>
</section>
<section id="how-dgl-implements-transformer-with-a-graph-neural-network">
<h2>How DGL implements Transformer with a graph neural network<a class="headerlink" href="#how-dgl-implements-transformer-with-a-graph-neural-network" title="Link to this heading">ÔÉÅ</a></h2>
<p>You get a different perspective of Transformer by treating the
attention as edges in a graph and adopt message passing on the edges to
induce the appropriate processing.</p>
<section id="graph-structure">
<h3>Graph structure<a class="headerlink" href="#graph-structure" title="Link to this heading">ÔÉÅ</a></h3>
<p>Construct the graph by mapping tokens of the source and target
sentence to nodes. The complete Transformer graph is made up of three
subgraphs:</p>
<p><strong>Source language graph</strong>. This is a complete graph, each
token <span class="math notranslate nohighlight">\(s_i\)</span> can attend to any other token <span class="math notranslate nohighlight">\(s_j\)</span> (including
self-loops). <img alt="image0" src="https://i.imgur.com/zV5LmTX.png"/>
<strong>Target language graph</strong>. The graph is
half-complete, in that <span class="math notranslate nohighlight">\(t_i\)</span> attends only to <span class="math notranslate nohighlight">\(t_j\)</span> if
<span class="math notranslate nohighlight">\(i &gt; j\)</span> (an output token can not depend on future words). <img alt="image1" src="https://i.imgur.com/dETQMMx.png"/>
<strong>Cross-language graph</strong>. This is a bi-partitie graph, where there is
an edge from every source token <span class="math notranslate nohighlight">\(s_i\)</span> to every target token
<span class="math notranslate nohighlight">\(t_j\)</span>, meaning every target token can attend on source tokens.
<img alt="image2" src="https://i.imgur.com/hnGP229.png"/></p>
<p>The full picture looks like this: <img alt="image3" src="https://i.imgur.com/Hj2rRGT.png"/></p>
<p>Pre-build the graphs in dataset preparation stage.</p>
</section>
<section id="message-passing">
<h3>Message passing<a class="headerlink" href="#message-passing" title="Link to this heading">ÔÉÅ</a></h3>
<p>Once you define the graph structure, move on to defining the
computation for message passing.</p>
<p>Assuming that you have already computed all the queries <span class="math notranslate nohighlight">\(q_i\)</span>, keys
<span class="math notranslate nohighlight">\(k_i\)</span> and values <span class="math notranslate nohighlight">\(v_i\)</span>. For each node <span class="math notranslate nohighlight">\(i\)</span> (no matter
whether it is a source token or target token), you can decompose the
attention computation into two steps:</p>
<ol class="arabic simple">
<li><p><strong>Message computation:</strong> Compute attention score
<span class="math notranslate nohighlight">\(\mathrm{score}_{ij}\)</span> between <span class="math notranslate nohighlight">\(i\)</span> and all nodes <span class="math notranslate nohighlight">\(j\)</span>
to be attended over, by taking the scaled-dot product between
<span class="math notranslate nohighlight">\(q_i\)</span> and <span class="math notranslate nohighlight">\(k_j\)</span>. The message sent from <span class="math notranslate nohighlight">\(j\)</span> to
<span class="math notranslate nohighlight">\(i\)</span> will consist of the score <span class="math notranslate nohighlight">\(\mathrm{score}_{ij}\)</span> and
the value <span class="math notranslate nohighlight">\(v_j\)</span>.</p></li>
<li><p><strong>Message aggregation:</strong> Aggregate the values <span class="math notranslate nohighlight">\(v_j\)</span> from all
<span class="math notranslate nohighlight">\(j\)</span> according to the scores <span class="math notranslate nohighlight">\(\mathrm{score}_{ij}\)</span>.</p></li>
</ol>
<section id="simple-implementation">
<h4>Simple implementation<a class="headerlink" href="#simple-implementation" title="Link to this heading">ÔÉÅ</a></h4>
<section id="message-computation">
<h5>Message computation<a class="headerlink" href="#message-computation" title="Link to this heading">ÔÉÅ</a></h5>
<p>Compute <code class="docutils literal notranslate"><span class="pre">score</span></code> and send source node‚Äôs <code class="docutils literal notranslate"><span class="pre">v</span></code> to destination‚Äôs mailbox</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">message_func</span><span class="p">(</span><span class="n">edges</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">{</span><span class="s1">'score'</span><span class="p">:</span> <span class="p">((</span><span class="n">edges</span><span class="o">.</span><span class="n">src</span><span class="p">[</span><span class="s1">'k'</span><span class="p">]</span> <span class="o">*</span> <span class="n">edges</span><span class="o">.</span><span class="n">dst</span><span class="p">[</span><span class="s1">'q'</span><span class="p">])</span>
                      <span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)),</span>
            <span class="s1">'v'</span><span class="p">:</span> <span class="n">edges</span><span class="o">.</span><span class="n">src</span><span class="p">[</span><span class="s1">'v'</span><span class="p">]}</span>
</pre></div>
</div>
</section>
<section id="message-aggregation">
<h5>Message aggregation<a class="headerlink" href="#message-aggregation" title="Link to this heading">ÔÉÅ</a></h5>
<p>Normalize over all in-edges and weighted sum to get output</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>

<span class="k">def</span> <span class="nf">reduce_func</span><span class="p">(</span><span class="n">nodes</span><span class="p">,</span> <span class="n">d_k</span><span class="o">=</span><span class="mi">64</span><span class="p">):</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">mailbox</span><span class="p">[</span><span class="s1">'v'</span><span class="p">]</span>
    <span class="n">att</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">mailbox</span><span class="p">[</span><span class="s1">'score'</span><span class="p">]</span> <span class="o">/</span> <span class="n">th</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">d_k</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">{</span><span class="s1">'dx'</span><span class="p">:</span> <span class="p">(</span><span class="n">att</span> <span class="o">*</span> <span class="n">v</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">)}</span>
</pre></div>
</div>
</section>
<section id="execute-on-specific-edges">
<h5>Execute on specific edges<a class="headerlink" href="#execute-on-specific-edges" title="Link to this heading">ÔÉÅ</a></h5>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">functools.partial</span> <span class="k">as</span> <span class="nn">partial</span>
<span class="k">def</span> <span class="nf">naive_propagate_attention</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">eids</span><span class="p">):</span>
    <span class="n">g</span><span class="o">.</span><span class="n">send_and_recv</span><span class="p">(</span><span class="n">eids</span><span class="p">,</span> <span class="n">message_func</span><span class="p">,</span> <span class="n">partial</span><span class="p">(</span><span class="n">reduce_func</span><span class="p">,</span> <span class="n">d_k</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d_k</span><span class="p">))</span>
</pre></div>
</div>
</section>
</section>
<section id="speeding-up-with-built-in-functions">
<h4>Speeding up with built-in functions<a class="headerlink" href="#speeding-up-with-built-in-functions" title="Link to this heading">ÔÉÅ</a></h4>
<p>To speed up the message passing process, use DGL‚Äôs built-in
functions, including:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">fn.src_mul_egdes(src_field,</span> <span class="pre">edges_field,</span> <span class="pre">out_field)</span></code> multiplies
source‚Äôs attribute and edges attribute, and send the result to the
destination node‚Äôs mailbox keyed by <code class="docutils literal notranslate"><span class="pre">out_field</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">fn.copy_e(edges_field,</span> <span class="pre">out_field)</span></code> copies edge‚Äôs attribute to
destination node‚Äôs mailbox.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">fn.sum(edges_field,</span> <span class="pre">out_field)</span></code> sums up
edge‚Äôs attribute and sends aggregation to destination node‚Äôs mailbox.</p></li>
</ul>
<p>Here, you assemble those built-in functions into <code class="docutils literal notranslate"><span class="pre">propagate_attention</span></code>,
which is also the main graph operation function in the final
implementation. To accelerate it, break the <code class="docutils literal notranslate"><span class="pre">softmax</span></code> operation into
the following steps. Recall that for each head there are two phases.</p>
<ol class="arabic">
<li><p>Compute attention score by multiply src node‚Äôs <code class="docutils literal notranslate"><span class="pre">k</span></code> and dst node‚Äôs
<code class="docutils literal notranslate"><span class="pre">q</span></code></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">g.apply_edges(src_dot_dst('k',</span> <span class="pre">'q',</span> <span class="pre">'score'),</span> <span class="pre">eids)</span></code></p></li>
</ul>
</li>
<li><p>Scaled Softmax over all dst nodes‚Äô in-coming edges</p>
<ul>
<li><p>Step 1: Exponentialize score with scale normalize constant</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">g.apply_edges(scaled_exp('score',</span> <span class="pre">np.sqrt(self.d_k)))</span></code></p>
<div class="math notranslate nohighlight">
\[\textrm{score}_{ij}\leftarrow\exp{\left(\frac{\textrm{score}_{ij}}{ \sqrt{d_k}}\right)}\]</div>
</li>
</ul>
</li>
<li><p>Step 2: Get the ‚Äúvalues‚Äù on associated nodes weighted by ‚Äúscores‚Äù
on in-coming edges of each node; get the sum of ‚Äúscores‚Äù on
in-coming edges of each node for normalization. Note that here
<span class="math notranslate nohighlight">\(\textrm{wv}\)</span> is not normalized.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">msg:</span> <span class="pre">fn.u_mul_e('v',</span> <span class="pre">'score',</span> <span class="pre">'v'),</span> <span class="pre">reduce:</span> <span class="pre">fn.sum('v',</span> <span class="pre">'wv')</span></code></p>
<div class="math notranslate nohighlight">
\[\textrm{wv}_j=\sum_{i=1}^{N} \textrm{score}_{ij} \cdot v_i\]</div>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">msg:</span> <span class="pre">fn.copy_e('score',</span> <span class="pre">'score'),</span> <span class="pre">reduce:</span> <span class="pre">fn.sum('score',</span> <span class="pre">'z')</span></code></p>
<div class="math notranslate nohighlight">
\[\textrm{z}_j=\sum_{i=1}^{N} \textrm{score}_{ij}\]</div>
</li>
</ul>
</li>
</ul>
</li>
</ol>
<p>The normalization of <span class="math notranslate nohighlight">\(\textrm{wv}\)</span> is left to post processing.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">src_dot_dst</span><span class="p">(</span><span class="n">src_field</span><span class="p">,</span> <span class="n">dst_field</span><span class="p">,</span> <span class="n">out_field</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">func</span><span class="p">(</span><span class="n">edges</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span><span class="n">out_field</span><span class="p">:</span> <span class="p">(</span><span class="n">edges</span><span class="o">.</span><span class="n">src</span><span class="p">[</span><span class="n">src_field</span><span class="p">]</span> <span class="o">*</span> <span class="n">edges</span><span class="o">.</span><span class="n">dst</span><span class="p">[</span><span class="n">dst_field</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)}</span>

    <span class="k">return</span> <span class="n">func</span>

<span class="k">def</span> <span class="nf">scaled_exp</span><span class="p">(</span><span class="n">field</span><span class="p">,</span> <span class="n">scale_constant</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">func</span><span class="p">(</span><span class="n">edges</span><span class="p">):</span>
        <span class="c1"># clamp for softmax numerical stability</span>
        <span class="k">return</span> <span class="p">{</span><span class="n">field</span><span class="p">:</span> <span class="n">th</span><span class="o">.</span><span class="n">exp</span><span class="p">((</span><span class="n">edges</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">field</span><span class="p">]</span> <span class="o">/</span> <span class="n">scale_constant</span><span class="p">)</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))}</span>

    <span class="k">return</span> <span class="n">func</span>


<span class="k">def</span> <span class="nf">propagate_attention</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">eids</span><span class="p">):</span>
    <span class="c1"># Compute attention score</span>
    <span class="n">g</span><span class="o">.</span><span class="n">apply_edges</span><span class="p">(</span><span class="n">src_dot_dst</span><span class="p">(</span><span class="s1">'k'</span><span class="p">,</span> <span class="s1">'q'</span><span class="p">,</span> <span class="s1">'score'</span><span class="p">),</span> <span class="n">eids</span><span class="p">)</span>
    <span class="n">g</span><span class="o">.</span><span class="n">apply_edges</span><span class="p">(</span><span class="n">scaled_exp</span><span class="p">(</span><span class="s1">'score'</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">d_k</span><span class="p">)))</span>
    <span class="c1"># Update node state</span>
    <span class="n">g</span><span class="o">.</span><span class="n">send_and_recv</span><span class="p">(</span><span class="n">eids</span><span class="p">,</span>
                    <span class="p">[</span><span class="n">fn</span><span class="o">.</span><span class="n">u_mul_e</span><span class="p">(</span><span class="s1">'v'</span><span class="p">,</span> <span class="s1">'score'</span><span class="p">,</span> <span class="s1">'v'</span><span class="p">),</span> <span class="n">fn</span><span class="o">.</span><span class="n">copy_e</span><span class="p">(</span><span class="s1">'score'</span><span class="p">,</span> <span class="s1">'score'</span><span class="p">)],</span>
                    <span class="p">[</span><span class="n">fn</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="s1">'v'</span><span class="p">,</span> <span class="s1">'wv'</span><span class="p">),</span> <span class="n">fn</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="s1">'score'</span><span class="p">,</span> <span class="s1">'z'</span><span class="p">)])</span>
</pre></div>
</div>
</section>
</section>
<section id="preprocessing-and-postprocessing">
<h3>Preprocessing and postprocessing<a class="headerlink" href="#preprocessing-and-postprocessing" title="Link to this heading">ÔÉÅ</a></h3>
<p>In Transformer, data needs to be pre- and post-processed before and
after the <code class="docutils literal notranslate"><span class="pre">propagate_attention</span></code> function.</p>
<p><strong>Preprocessing</strong> The preprocessing function <code class="docutils literal notranslate"><span class="pre">pre_func</span></code> first
normalizes the node representations and then map them to a set of
queries, keys and values, using self-attention as an example:</p>
<div class="math notranslate nohighlight">
\[\begin{split}x \leftarrow \textrm{LayerNorm}(x) \\
[q, k, v] \leftarrow [W_q, W_k, W_v ]\cdot x\end{split}\]</div>
<p><strong>Postprocessing</strong> The postprocessing function <code class="docutils literal notranslate"><span class="pre">post_funcs</span></code> completes
the whole computation correspond to one layer of the transformer: 1.
Normalize <span class="math notranslate nohighlight">\(\textrm{wv}\)</span> and get the output of Multi-Head Attention
Layer <span class="math notranslate nohighlight">\(o\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\textrm{wv} \leftarrow \frac{\textrm{wv}}{z} \\
o \leftarrow W_o\cdot \textrm{wv} + b_o\end{split}\]</div>
<p>add residual connection:</p>
<div class="math notranslate nohighlight">
\[x \leftarrow x + o\]</div>
<ol class="arabic" start="2">
<li><p>Applying a two layer position-wise feed forward layer on <span class="math notranslate nohighlight">\(x\)</span>
then add residual connection:</p>
<div class="math notranslate nohighlight">
\[x \leftarrow x + \textrm{LayerNorm}(\textrm{FFN}(x))\]</div>
<p>where <span class="math notranslate nohighlight">\(\textrm{FFN}\)</span> refers to the feed forward function.</p>
</li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Encoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Encoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">N</span> <span class="o">=</span> <span class="n">N</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">clones</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">LayerNorm</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">pre_func</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">fields</span><span class="o">=</span><span class="s1">'qkv'</span><span class="p">):</span>
        <span class="n">layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="k">def</span> <span class="nf">func</span><span class="p">(</span><span class="n">nodes</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">'x'</span><span class="p">]</span>
            <span class="n">norm_x</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">sublayer</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">layer</span><span class="o">.</span><span class="n">self_attn</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">norm_x</span><span class="p">,</span> <span class="n">fields</span><span class="o">=</span><span class="n">fields</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">func</span>

    <span class="k">def</span> <span class="nf">post_func</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>
        <span class="n">layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="k">def</span> <span class="nf">func</span><span class="p">(</span><span class="n">nodes</span><span class="p">):</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">wv</span><span class="p">,</span> <span class="n">z</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">'x'</span><span class="p">],</span> <span class="n">nodes</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">'wv'</span><span class="p">],</span> <span class="n">nodes</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">'z'</span><span class="p">]</span>
            <span class="n">o</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">self_attn</span><span class="o">.</span><span class="n">get_o</span><span class="p">(</span><span class="n">wv</span> <span class="o">/</span> <span class="n">z</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">layer</span><span class="o">.</span><span class="n">sublayer</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">o</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">sublayer</span><span class="p">[</span><span class="mi">1</span><span class="p">](</span><span class="n">x</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">feed_forward</span><span class="p">)</span>
            <span class="k">return</span> <span class="p">{</span><span class="s1">'x'</span><span class="p">:</span> <span class="n">x</span> <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">N</span> <span class="o">-</span> <span class="mi">1</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">)}</span>
        <span class="k">return</span> <span class="n">func</span>

<span class="k">class</span> <span class="nc">Decoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Decoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">N</span> <span class="o">=</span> <span class="n">N</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">clones</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">LayerNorm</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">pre_func</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">fields</span><span class="o">=</span><span class="s1">'qkv'</span><span class="p">,</span> <span class="n">l</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="n">layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="k">def</span> <span class="nf">func</span><span class="p">(</span><span class="n">nodes</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">'x'</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">fields</span> <span class="o">==</span> <span class="s1">'kv'</span><span class="p">:</span>
                <span class="n">norm_x</span> <span class="o">=</span> <span class="n">x</span> <span class="c1"># In enc-dec attention, x has already been normalized.</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">norm_x</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">sublayer</span><span class="p">[</span><span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">layer</span><span class="o">.</span><span class="n">self_attn</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">norm_x</span><span class="p">,</span> <span class="n">fields</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">func</span>

    <span class="k">def</span> <span class="nf">post_func</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">l</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="n">layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="k">def</span> <span class="nf">func</span><span class="p">(</span><span class="n">nodes</span><span class="p">):</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">wv</span><span class="p">,</span> <span class="n">z</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">'x'</span><span class="p">],</span> <span class="n">nodes</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">'wv'</span><span class="p">],</span> <span class="n">nodes</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">'z'</span><span class="p">]</span>
            <span class="n">o</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">self_attn</span><span class="o">.</span><span class="n">get_o</span><span class="p">(</span><span class="n">wv</span> <span class="o">/</span> <span class="n">z</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">layer</span><span class="o">.</span><span class="n">sublayer</span><span class="p">[</span><span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">o</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">l</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">sublayer</span><span class="p">[</span><span class="mi">2</span><span class="p">](</span><span class="n">x</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">feed_forward</span><span class="p">)</span>
            <span class="k">return</span> <span class="p">{</span><span class="s1">'x'</span><span class="p">:</span> <span class="n">x</span> <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">N</span> <span class="o">-</span> <span class="mi">1</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">)}</span>
        <span class="k">return</span> <span class="n">func</span>
</pre></div>
</div>
<p>This completes all procedures of one layer of encoder and decoder in
Transformer.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The sublayer connection part is little bit different from the
original paper. However, this implementation is the same as <a class="reference external" href="http://nlp.seas.harvard.edu/2018/04/03/attention.html">The Annotated
Transformer</a>
and
<a class="reference external" href="https://github.com/OpenNMT/OpenNMT-py/blob/cd29c1dbfb35f4a2701ff52a1bf4e5bdcf02802e/onmt/encoders/transformer.py">OpenNMT</a>.</p>
</div>
</section>
</section>
<section id="main-class-of-transformer-graph">
<h2>Main class of Transformer graph<a class="headerlink" href="#main-class-of-transformer-graph" title="Link to this heading">ÔÉÅ</a></h2>
<p>The processing flow of Transformer can be seen as a 2-stage
message-passing within the complete graph (adding pre- and post-
processing appropriately): 1) self-attention in encoder, 2)
self-attention in decoder followed by cross-attention between encoder
and decoder, as shown below. <img alt="image4" src="https://i.imgur.com/zlUpJ41.png"/></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Transformer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">src_embed</span><span class="p">,</span> <span class="n">tgt_embed</span><span class="p">,</span> <span class="n">pos_enc</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">d_k</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Transformer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">src_embed</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tgt_embed</span> <span class="o">=</span> <span class="n">src_embed</span><span class="p">,</span> <span class="n">tgt_embed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pos_enc</span> <span class="o">=</span> <span class="n">pos_enc</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span> <span class="o">=</span> <span class="n">generator</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_k</span> <span class="o">=</span> <span class="n">h</span><span class="p">,</span> <span class="n">d_k</span>

    <span class="k">def</span> <span class="nf">propagate_attention</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">eids</span><span class="p">):</span>
        <span class="c1"># Compute attention score</span>
        <span class="n">g</span><span class="o">.</span><span class="n">apply_edges</span><span class="p">(</span><span class="n">src_dot_dst</span><span class="p">(</span><span class="s1">'k'</span><span class="p">,</span> <span class="s1">'q'</span><span class="p">,</span> <span class="s1">'score'</span><span class="p">),</span> <span class="n">eids</span><span class="p">)</span>
        <span class="n">g</span><span class="o">.</span><span class="n">apply_edges</span><span class="p">(</span><span class="n">scaled_exp</span><span class="p">(</span><span class="s1">'score'</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">d_k</span><span class="p">)))</span>
        <span class="c1"># Send weighted values to target nodes</span>
        <span class="n">g</span><span class="o">.</span><span class="n">send_and_recv</span><span class="p">(</span><span class="n">eids</span><span class="p">,</span>
                        <span class="p">[</span><span class="n">fn</span><span class="o">.</span><span class="n">u_mul_e</span><span class="p">(</span><span class="s1">'v'</span><span class="p">,</span> <span class="s1">'score'</span><span class="p">,</span> <span class="s1">'v'</span><span class="p">),</span> <span class="n">fn</span><span class="o">.</span><span class="n">copy_e</span><span class="p">(</span><span class="s1">'score'</span><span class="p">,</span> <span class="s1">'score'</span><span class="p">)],</span>
                        <span class="p">[</span><span class="n">fn</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="s1">'v'</span><span class="p">,</span> <span class="s1">'wv'</span><span class="p">),</span> <span class="n">fn</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="s1">'score'</span><span class="p">,</span> <span class="s1">'z'</span><span class="p">)])</span>

    <span class="k">def</span> <span class="nf">update_graph</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">eids</span><span class="p">,</span> <span class="n">pre_pairs</span><span class="p">,</span> <span class="n">post_pairs</span><span class="p">):</span>
        <span class="s2">"Update the node states and edge states of the graph."</span>

        <span class="c1"># Pre-compute queries and key-value pairs.</span>
        <span class="k">for</span> <span class="n">pre_func</span><span class="p">,</span> <span class="n">nids</span> <span class="ow">in</span> <span class="n">pre_pairs</span><span class="p">:</span>
            <span class="n">g</span><span class="o">.</span><span class="n">apply_nodes</span><span class="p">(</span><span class="n">pre_func</span><span class="p">,</span> <span class="n">nids</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">propagate_attention</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">eids</span><span class="p">)</span>
        <span class="c1"># Further calculation after attention mechanism</span>
        <span class="k">for</span> <span class="n">post_func</span><span class="p">,</span> <span class="n">nids</span> <span class="ow">in</span> <span class="n">post_pairs</span><span class="p">:</span>
            <span class="n">g</span><span class="o">.</span><span class="n">apply_nodes</span><span class="p">(</span><span class="n">post_func</span><span class="p">,</span> <span class="n">nids</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">graph</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">g</span>
        <span class="n">nids</span><span class="p">,</span> <span class="n">eids</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">nids</span><span class="p">,</span> <span class="n">graph</span><span class="o">.</span><span class="n">eids</span>

        <span class="c1"># Word Embedding and Position Embedding</span>
        <span class="n">src_embed</span><span class="p">,</span> <span class="n">src_pos</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">src_embed</span><span class="p">(</span><span class="n">graph</span><span class="o">.</span><span class="n">src</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_enc</span><span class="p">(</span><span class="n">graph</span><span class="o">.</span><span class="n">src</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">tgt_embed</span><span class="p">,</span> <span class="n">tgt_pos</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tgt_embed</span><span class="p">(</span><span class="n">graph</span><span class="o">.</span><span class="n">tgt</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_enc</span><span class="p">(</span><span class="n">graph</span><span class="o">.</span><span class="n">tgt</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">g</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">nids</span><span class="p">[</span><span class="s1">'enc'</span><span class="p">]]</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">'x'</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_enc</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">src_embed</span> <span class="o">+</span> <span class="n">src_pos</span><span class="p">)</span>
        <span class="n">g</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">nids</span><span class="p">[</span><span class="s1">'dec'</span><span class="p">]]</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">'x'</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_enc</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">tgt_embed</span> <span class="o">+</span> <span class="n">tgt_pos</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">N</span><span class="p">):</span>
            <span class="c1"># Step 1: Encoder Self-attention</span>
            <span class="n">pre_func</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">pre_func</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="s1">'qkv'</span><span class="p">)</span>
            <span class="n">post_func</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">post_func</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
            <span class="n">nodes</span><span class="p">,</span> <span class="n">edges</span> <span class="o">=</span> <span class="n">nids</span><span class="p">[</span><span class="s1">'enc'</span><span class="p">],</span> <span class="n">eids</span><span class="p">[</span><span class="s1">'ee'</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">update_graph</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">edges</span><span class="p">,</span> <span class="p">[(</span><span class="n">pre_func</span><span class="p">,</span> <span class="n">nodes</span><span class="p">)],</span> <span class="p">[(</span><span class="n">post_func</span><span class="p">,</span> <span class="n">nodes</span><span class="p">)])</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">N</span><span class="p">):</span>
            <span class="c1"># Step 2: Dncoder Self-attention</span>
            <span class="n">pre_func</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">pre_func</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="s1">'qkv'</span><span class="p">)</span>
            <span class="n">post_func</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">post_func</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
            <span class="n">nodes</span><span class="p">,</span> <span class="n">edges</span> <span class="o">=</span> <span class="n">nids</span><span class="p">[</span><span class="s1">'dec'</span><span class="p">],</span> <span class="n">eids</span><span class="p">[</span><span class="s1">'dd'</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">update_graph</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">edges</span><span class="p">,</span> <span class="p">[(</span><span class="n">pre_func</span><span class="p">,</span> <span class="n">nodes</span><span class="p">)],</span> <span class="p">[(</span><span class="n">post_func</span><span class="p">,</span> <span class="n">nodes</span><span class="p">)])</span>
            <span class="c1"># Step 3: Encoder-Decoder attention</span>
            <span class="n">pre_q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">pre_func</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="s1">'q'</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">pre_kv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">pre_func</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="s1">'kv'</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">post_func</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">post_func</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">nodes_e</span><span class="p">,</span> <span class="n">nodes_d</span><span class="p">,</span> <span class="n">edges</span> <span class="o">=</span> <span class="n">nids</span><span class="p">[</span><span class="s1">'enc'</span><span class="p">],</span> <span class="n">nids</span><span class="p">[</span><span class="s1">'dec'</span><span class="p">],</span> <span class="n">eids</span><span class="p">[</span><span class="s1">'ed'</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">update_graph</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">edges</span><span class="p">,</span> <span class="p">[(</span><span class="n">pre_q</span><span class="p">,</span> <span class="n">nodes_d</span><span class="p">),</span> <span class="p">(</span><span class="n">pre_kv</span><span class="p">,</span> <span class="n">nodes_e</span><span class="p">)],</span> <span class="p">[(</span><span class="n">post_func</span><span class="p">,</span> <span class="n">nodes_d</span><span class="p">)])</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="s1">'x'</span><span class="p">][</span><span class="n">nids</span><span class="p">[</span><span class="s1">'dec'</span><span class="p">]])</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>By calling <code class="docutils literal notranslate"><span class="pre">update_graph</span></code> function, you can create your own
Transformer on any subgraphs with nearly the same code. This
flexibility enables us to discover new, sparse structures (c.f. local attention
mentioned <a class="reference external" href="https://arxiv.org/pdf/1508.04025.pdf">here</a>). Note in this
implementation you don‚Äôt use mask or padding, which makes the logic
more clear and saves memory. The trade-off is that the implementation is
slower.</p>
</div>
</section>
<section id="training">
<h2>Training<a class="headerlink" href="#training" title="Link to this heading">ÔÉÅ</a></h2>
<p>This tutorial does not cover several other techniques such as Label
Smoothing and Noam Optimizations mentioned in the original paper. For
detailed description about these modules, read <a class="reference external" href="http://nlp.seas.harvard.edu/2018/04/03/attention.html">The
Annotated
Transformer</a>
written by Harvard NLP team.</p>
<section id="task-and-the-dataset">
<h3>Task and the dataset<a class="headerlink" href="#task-and-the-dataset" title="Link to this heading">ÔÉÅ</a></h3>
<p>The Transformer is a general framework for a variety of NLP tasks. This tutorial focuses
on the sequence to sequence learning: it‚Äôs a typical case to illustrate how it works.</p>
<p>As for the dataset, there are two example tasks: copy and sort, together
with two real-world translation tasks: multi30k en-de task and wmt14
en-de task.</p>
<ul class="simple">
<li><p><strong>copy dataset</strong>: copy input sequences to output. (train/valid/test:
9000, 1000, 1000)</p></li>
<li><p><strong>sort dataset</strong>: sort input sequences as output. (train/valid/test:
9000, 1000, 1000)</p></li>
<li><p><strong>Multi30k en-de</strong>, translate sentences from En to De.
(train/valid/test: 29000, 1000, 1000)</p></li>
<li><p><strong>WMT14 en-de</strong>, translate sentences from En to De.
(Train/Valid/Test: 4500966/3000/3003)</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Training with wmt14 requires multi-GPU support and is not available. Contributions are welcome!</p>
</div>
</section>
<section id="graph-building">
<h3>Graph building<a class="headerlink" href="#graph-building" title="Link to this heading">ÔÉÅ</a></h3>
<p><strong>Batching</strong> This is similar to the way you handle Tree-LSTM. Build a graph pool in
advance, including all possible combination of input lengths and output
lengths. Then for each sample in a batch, call <code class="docutils literal notranslate"><span class="pre">dgl.batch</span></code> to batch
graphs of their sizes together in to a single large graph.</p>
<p>You can wrap the process of creating graph pool and building
BatchedGraph in <code class="docutils literal notranslate"><span class="pre">dataset.GraphPool</span></code> and
<code class="docutils literal notranslate"><span class="pre">dataset.TranslationDataset</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">graph_pool</span> <span class="o">=</span> <span class="n">GraphPool</span><span class="p">()</span>

<span class="n">data_iter</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">(</span><span class="n">graph_pool</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">'train'</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">devices</span><span class="o">=</span><span class="n">devices</span><span class="p">)</span>
<span class="k">for</span> <span class="n">graph</span> <span class="ow">in</span> <span class="n">data_iter</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">graph</span><span class="o">.</span><span class="n">nids</span><span class="p">[</span><span class="s1">'enc'</span><span class="p">])</span> <span class="c1"># encoder node ids</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">graph</span><span class="o">.</span><span class="n">nids</span><span class="p">[</span><span class="s1">'dec'</span><span class="p">])</span> <span class="c1"># decoder node ids</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">graph</span><span class="o">.</span><span class="n">eids</span><span class="p">[</span><span class="s1">'ee'</span><span class="p">])</span> <span class="c1"># encoder-encoder edge ids</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">graph</span><span class="o">.</span><span class="n">eids</span><span class="p">[</span><span class="s1">'ed'</span><span class="p">])</span> <span class="c1"># encoder-decoder edge ids</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">graph</span><span class="o">.</span><span class="n">eids</span><span class="p">[</span><span class="s1">'dd'</span><span class="p">])</span> <span class="c1"># decoder-decoder edge ids</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">graph</span><span class="o">.</span><span class="n">src</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="c1"># Input word index list</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">graph</span><span class="o">.</span><span class="n">src</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="c1"># Input positions</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">graph</span><span class="o">.</span><span class="n">tgt</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="c1"># Output word index list</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">graph</span><span class="o">.</span><span class="n">tgt</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="c1"># Ouptut positions</span>
    <span class="k">break</span>
</pre></div>
</div>
<p>Output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="s1">'cuda:0'</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="mi">18</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="s1">'cuda:0'</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">,</span>  <span class="mi">4</span><span class="p">,</span>  <span class="mi">5</span><span class="p">,</span>  <span class="mi">6</span><span class="p">,</span>  <span class="mi">7</span><span class="p">,</span>  <span class="mi">8</span><span class="p">,</span>  <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span>
        <span class="mi">18</span><span class="p">,</span> <span class="mi">19</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">21</span><span class="p">,</span> <span class="mi">22</span><span class="p">,</span> <span class="mi">23</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">26</span><span class="p">,</span> <span class="mi">27</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">29</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">33</span><span class="p">,</span> <span class="mi">34</span><span class="p">,</span> <span class="mi">35</span><span class="p">,</span>
        <span class="mi">36</span><span class="p">,</span> <span class="mi">37</span><span class="p">,</span> <span class="mi">38</span><span class="p">,</span> <span class="mi">39</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">41</span><span class="p">,</span> <span class="mi">42</span><span class="p">,</span> <span class="mi">43</span><span class="p">,</span> <span class="mi">44</span><span class="p">,</span> <span class="mi">45</span><span class="p">,</span> <span class="mi">46</span><span class="p">,</span> <span class="mi">47</span><span class="p">,</span> <span class="mi">48</span><span class="p">,</span> <span class="mi">49</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">51</span><span class="p">,</span> <span class="mi">52</span><span class="p">,</span> <span class="mi">53</span><span class="p">,</span>
        <span class="mi">54</span><span class="p">,</span> <span class="mi">55</span><span class="p">,</span> <span class="mi">56</span><span class="p">,</span> <span class="mi">57</span><span class="p">,</span> <span class="mi">58</span><span class="p">,</span> <span class="mi">59</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">61</span><span class="p">,</span> <span class="mi">62</span><span class="p">,</span> <span class="mi">63</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">65</span><span class="p">,</span> <span class="mi">66</span><span class="p">,</span> <span class="mi">67</span><span class="p">,</span> <span class="mi">68</span><span class="p">,</span> <span class="mi">69</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="mi">71</span><span class="p">,</span>
        <span class="mi">72</span><span class="p">,</span> <span class="mi">73</span><span class="p">,</span> <span class="mi">74</span><span class="p">,</span> <span class="mi">75</span><span class="p">,</span> <span class="mi">76</span><span class="p">,</span> <span class="mi">77</span><span class="p">,</span> <span class="mi">78</span><span class="p">,</span> <span class="mi">79</span><span class="p">,</span> <span class="mi">80</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="s1">'cuda:0'</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mi">81</span><span class="p">,</span>  <span class="mi">82</span><span class="p">,</span>  <span class="mi">83</span><span class="p">,</span>  <span class="mi">84</span><span class="p">,</span>  <span class="mi">85</span><span class="p">,</span>  <span class="mi">86</span><span class="p">,</span>  <span class="mi">87</span><span class="p">,</span>  <span class="mi">88</span><span class="p">,</span>  <span class="mi">89</span><span class="p">,</span>  <span class="mi">90</span><span class="p">,</span>  <span class="mi">91</span><span class="p">,</span>  <span class="mi">92</span><span class="p">,</span>  <span class="mi">93</span><span class="p">,</span>  <span class="mi">94</span><span class="p">,</span>
         <span class="mi">95</span><span class="p">,</span>  <span class="mi">96</span><span class="p">,</span>  <span class="mi">97</span><span class="p">,</span>  <span class="mi">98</span><span class="p">,</span>  <span class="mi">99</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">101</span><span class="p">,</span> <span class="mi">102</span><span class="p">,</span> <span class="mi">103</span><span class="p">,</span> <span class="mi">104</span><span class="p">,</span> <span class="mi">105</span><span class="p">,</span> <span class="mi">106</span><span class="p">,</span> <span class="mi">107</span><span class="p">,</span> <span class="mi">108</span><span class="p">,</span>
        <span class="mi">109</span><span class="p">,</span> <span class="mi">110</span><span class="p">,</span> <span class="mi">111</span><span class="p">,</span> <span class="mi">112</span><span class="p">,</span> <span class="mi">113</span><span class="p">,</span> <span class="mi">114</span><span class="p">,</span> <span class="mi">115</span><span class="p">,</span> <span class="mi">116</span><span class="p">,</span> <span class="mi">117</span><span class="p">,</span> <span class="mi">118</span><span class="p">,</span> <span class="mi">119</span><span class="p">,</span> <span class="mi">120</span><span class="p">,</span> <span class="mi">121</span><span class="p">,</span> <span class="mi">122</span><span class="p">,</span>
        <span class="mi">123</span><span class="p">,</span> <span class="mi">124</span><span class="p">,</span> <span class="mi">125</span><span class="p">,</span> <span class="mi">126</span><span class="p">,</span> <span class="mi">127</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">129</span><span class="p">,</span> <span class="mi">130</span><span class="p">,</span> <span class="mi">131</span><span class="p">,</span> <span class="mi">132</span><span class="p">,</span> <span class="mi">133</span><span class="p">,</span> <span class="mi">134</span><span class="p">,</span> <span class="mi">135</span><span class="p">,</span> <span class="mi">136</span><span class="p">,</span>
        <span class="mi">137</span><span class="p">,</span> <span class="mi">138</span><span class="p">,</span> <span class="mi">139</span><span class="p">,</span> <span class="mi">140</span><span class="p">,</span> <span class="mi">141</span><span class="p">,</span> <span class="mi">142</span><span class="p">,</span> <span class="mi">143</span><span class="p">,</span> <span class="mi">144</span><span class="p">,</span> <span class="mi">145</span><span class="p">,</span> <span class="mi">146</span><span class="p">,</span> <span class="mi">147</span><span class="p">,</span> <span class="mi">148</span><span class="p">,</span> <span class="mi">149</span><span class="p">,</span> <span class="mi">150</span><span class="p">,</span>
        <span class="mi">151</span><span class="p">,</span> <span class="mi">152</span><span class="p">,</span> <span class="mi">153</span><span class="p">,</span> <span class="mi">154</span><span class="p">,</span> <span class="mi">155</span><span class="p">,</span> <span class="mi">156</span><span class="p">,</span> <span class="mi">157</span><span class="p">,</span> <span class="mi">158</span><span class="p">,</span> <span class="mi">159</span><span class="p">,</span> <span class="mi">160</span><span class="p">,</span> <span class="mi">161</span><span class="p">,</span> <span class="mi">162</span><span class="p">,</span> <span class="mi">163</span><span class="p">,</span> <span class="mi">164</span><span class="p">,</span>
        <span class="mi">165</span><span class="p">,</span> <span class="mi">166</span><span class="p">,</span> <span class="mi">167</span><span class="p">,</span> <span class="mi">168</span><span class="p">,</span> <span class="mi">169</span><span class="p">,</span> <span class="mi">170</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="s1">'cuda:0'</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="mi">171</span><span class="p">,</span> <span class="mi">172</span><span class="p">,</span> <span class="mi">173</span><span class="p">,</span> <span class="mi">174</span><span class="p">,</span> <span class="mi">175</span><span class="p">,</span> <span class="mi">176</span><span class="p">,</span> <span class="mi">177</span><span class="p">,</span> <span class="mi">178</span><span class="p">,</span> <span class="mi">179</span><span class="p">,</span> <span class="mi">180</span><span class="p">,</span> <span class="mi">181</span><span class="p">,</span> <span class="mi">182</span><span class="p">,</span> <span class="mi">183</span><span class="p">,</span> <span class="mi">184</span><span class="p">,</span>
        <span class="mi">185</span><span class="p">,</span> <span class="mi">186</span><span class="p">,</span> <span class="mi">187</span><span class="p">,</span> <span class="mi">188</span><span class="p">,</span> <span class="mi">189</span><span class="p">,</span> <span class="mi">190</span><span class="p">,</span> <span class="mi">191</span><span class="p">,</span> <span class="mi">192</span><span class="p">,</span> <span class="mi">193</span><span class="p">,</span> <span class="mi">194</span><span class="p">,</span> <span class="mi">195</span><span class="p">,</span> <span class="mi">196</span><span class="p">,</span> <span class="mi">197</span><span class="p">,</span> <span class="mi">198</span><span class="p">,</span>
        <span class="mi">199</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">201</span><span class="p">,</span> <span class="mi">202</span><span class="p">,</span> <span class="mi">203</span><span class="p">,</span> <span class="mi">204</span><span class="p">,</span> <span class="mi">205</span><span class="p">,</span> <span class="mi">206</span><span class="p">,</span> <span class="mi">207</span><span class="p">,</span> <span class="mi">208</span><span class="p">,</span> <span class="mi">209</span><span class="p">,</span> <span class="mi">210</span><span class="p">,</span> <span class="mi">211</span><span class="p">,</span> <span class="mi">212</span><span class="p">,</span>
        <span class="mi">213</span><span class="p">,</span> <span class="mi">214</span><span class="p">,</span> <span class="mi">215</span><span class="p">,</span> <span class="mi">216</span><span class="p">,</span> <span class="mi">217</span><span class="p">,</span> <span class="mi">218</span><span class="p">,</span> <span class="mi">219</span><span class="p">,</span> <span class="mi">220</span><span class="p">,</span> <span class="mi">221</span><span class="p">,</span> <span class="mi">222</span><span class="p">,</span> <span class="mi">223</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">225</span><span class="p">],</span>
       <span class="n">device</span><span class="o">=</span><span class="s1">'cuda:0'</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="mi">28</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span>  <span class="mi">7</span><span class="p">,</span> <span class="mi">26</span><span class="p">,</span>  <span class="mi">6</span><span class="p">,</span>  <span class="mi">4</span><span class="p">,</span>  <span class="mi">5</span><span class="p">,</span>  <span class="mi">9</span><span class="p">,</span> <span class="mi">18</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="s1">'cuda:0'</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="s1">'cuda:0'</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span>  <span class="mi">7</span><span class="p">,</span> <span class="mi">26</span><span class="p">,</span>  <span class="mi">6</span><span class="p">,</span>  <span class="mi">4</span><span class="p">,</span>  <span class="mi">5</span><span class="p">,</span>  <span class="mi">9</span><span class="p">,</span> <span class="mi">18</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="s1">'cuda:0'</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="s1">'cuda:0'</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="put-it-all-together">
<h2>Put it all together<a class="headerlink" href="#put-it-all-together" title="Link to this heading">ÔÉÅ</a></h2>
<p>Train a one-head transformer with one layer, 128 dimension on copy
task. Set other parameters to the default.</p>
<p>Inference module is not included in this tutorial. It
requires beam search. For a full implementation, see the <a class="reference external" href="https://github.com/dmlc/dgl/tree/master/examples/pytorch/transformer">GitHub
repo</a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tqdm.auto</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">loss</span> <span class="kn">import</span> <span class="n">LabelSmoothing</span><span class="p">,</span> <span class="n">SimpleLossCompute</span>
<span class="kn">from</span> <span class="nn">modules</span> <span class="kn">import</span> <span class="n">make_model</span>
<span class="kn">from</span> <span class="nn">optims</span> <span class="kn">import</span> <span class="n">NoamOpt</span>
<span class="kn">from</span> <span class="nn">dgl.contrib.transformer</span> <span class="kn">import</span> <span class="n">get_dataset</span><span class="p">,</span> <span class="n">GraphPool</span>

<span class="k">def</span> <span class="nf">run_epoch</span><span class="p">(</span><span class="n">data_iter</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_compute</span><span class="p">,</span> <span class="n">is_train</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">g</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">data_iter</span><span class="p">)):</span>
        <span class="k">with</span> <span class="n">th</span><span class="o">.</span><span class="n">set_grad_enabled</span><span class="p">(</span><span class="n">is_train</span><span class="p">):</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_compute</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">tgt_y</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">n_tokens</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'average loss: </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">loss_compute</span><span class="o">.</span><span class="n">avg_loss</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'accuracy: </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">loss_compute</span><span class="o">.</span><span class="n">accuracy</span><span class="p">))</span>

<span class="n">N</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">devices</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'cuda'</span> <span class="k">if</span> <span class="n">th</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">'cpu'</span><span class="p">]</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">get_dataset</span><span class="p">(</span><span class="s2">"copy"</span><span class="p">)</span>
<span class="n">V</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">vocab_size</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">LabelSmoothing</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="n">padding_idx</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">pad_id</span><span class="p">,</span> <span class="n">smoothing</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">dim_model</span> <span class="o">=</span> <span class="mi">128</span>

<span class="c1"># Create model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">make_model</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="n">V</span><span class="p">,</span> <span class="n">N</span><span class="o">=</span><span class="n">N</span><span class="p">,</span> <span class="n">dim_model</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">dim_ff</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">h</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Sharing weights between Encoder &amp; Decoder</span>
<span class="n">model</span><span class="o">.</span><span class="n">src_embed</span><span class="o">.</span><span class="n">lut</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">tgt_embed</span><span class="o">.</span><span class="n">lut</span><span class="o">.</span><span class="n">weight</span>
<span class="n">model</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">proj</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">tgt_embed</span><span class="o">.</span><span class="n">lut</span><span class="o">.</span><span class="n">weight</span>

<span class="n">model</span><span class="p">,</span> <span class="n">criterion</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">devices</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">criterion</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">devices</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">model_opt</span> <span class="o">=</span> <span class="n">NoamOpt</span><span class="p">(</span><span class="n">dim_model</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">400</span><span class="p">,</span>
                    <span class="n">th</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.98</span><span class="p">),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-9</span><span class="p">))</span>
<span class="n">loss_compute</span> <span class="o">=</span> <span class="n">SimpleLossCompute</span>

<span class="n">att_maps</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
    <span class="n">train_iter</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">(</span><span class="n">graph_pool</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">'train'</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">devices</span><span class="o">=</span><span class="n">devices</span><span class="p">)</span>
    <span class="n">valid_iter</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">(</span><span class="n">graph_pool</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">'valid'</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">devices</span><span class="o">=</span><span class="n">devices</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'Epoch: </span><span class="si">{}</span><span class="s1"> Training...'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">run_epoch</span><span class="p">(</span><span class="n">train_iter</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span>
              <span class="n">loss_compute</span><span class="p">(</span><span class="n">criterion</span><span class="p">,</span> <span class="n">model_opt</span><span class="p">),</span> <span class="n">is_train</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'Epoch: </span><span class="si">{}</span><span class="s1"> Evaluating...'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">att_weight_map</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">run_epoch</span><span class="p">(</span><span class="n">valid_iter</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span>
              <span class="n">loss_compute</span><span class="p">(</span><span class="n">criterion</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span> <span class="n">is_train</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">att_maps</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">att_weight_map</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="visualization">
<h2>Visualization<a class="headerlink" href="#visualization" title="Link to this heading">ÔÉÅ</a></h2>
<p>After training, you can visualize the attention that the Transformer generates
on copy task.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">src_seq</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">get_seq_by_id</span><span class="p">(</span><span class="n">VIZ_IDX</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">'valid'</span><span class="p">,</span> <span class="n">field</span><span class="o">=</span><span class="s1">'src'</span><span class="p">)</span>
<span class="n">tgt_seq</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">get_seq_by_id</span><span class="p">(</span><span class="n">VIZ_IDX</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">'valid'</span><span class="p">,</span> <span class="n">field</span><span class="o">=</span><span class="s1">'tgt'</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="c1"># visualize head 0 of encoder-decoder attention</span>
<span class="n">att_animation</span><span class="p">(</span><span class="n">att_maps</span><span class="p">,</span> <span class="s1">'e2d'</span><span class="p">,</span> <span class="n">src_seq</span><span class="p">,</span> <span class="n">tgt_seq</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<p><img alt="image5" src="https://s1.ax1x.com/2018/12/06/F126xI.gif"/> from the figure you see the decoder nodes gradually learns to
attend to corresponding nodes in input sequence, which is the expected
behavior.</p>
<section id="multi-head-attention">
<h3>Multi-head attention<a class="headerlink" href="#multi-head-attention" title="Link to this heading">ÔÉÅ</a></h3>
<p>Besides the attention of a one-head attention trained on toy task. We
also visualize the attention scores of Encoder‚Äôs Self Attention,
Decoder‚Äôs Self Attention and the Encoder-Decoder attention of an
one-Layer Transformer network trained on multi-30k dataset.</p>
<p>From the visualization you see the diversity of different heads, which is what you would
expect. Different heads learn different relations between word pairs.</p>
<ul class="simple">
<li><p><strong>Encoder Self-Attention</strong> <img alt="image6" src="https://i.imgur.com/HjYb7F2.png"/></p></li>
<li><p><strong>Encoder-Decoder Attention</strong> Most words in target sequence attend on
their related words in source sequence, for example: when generating
‚ÄúSee‚Äù (in De), several heads attend on ‚Äúlake‚Äù; when generating
‚ÄúEisfischerh√ºtte‚Äù, several heads attend on ‚Äúice‚Äù. <img alt="image7" src="https://i.imgur.com/383J5O5.png"/></p></li>
<li><p><strong>Decoder Self-Attention</strong> Most words attend on their previous few
words. <img alt="image8" src="https://i.imgur.com/c0UWB1V.png"/></p></li>
</ul>
</section>
</section>
<section id="adaptive-universal-transformer">
<h2>Adaptive Universal Transformer<a class="headerlink" href="#adaptive-universal-transformer" title="Link to this heading">ÔÉÅ</a></h2>
<p>A recent research paper by Google, <a class="reference external" href="https://arxiv.org/pdf/1807.03819.pdf">Universal
Transformer</a>, is an example to
show how <code class="docutils literal notranslate"><span class="pre">update_graph</span></code> adapts to more complex updating rules.</p>
<p>The Universal Transformer was proposed to address the problem that
vanilla Transformer is not computationally universal by introducing
recurrence in Transformer:</p>
<ul class="simple">
<li><p>The basic idea of Universal Transformer is to repeatedly revise its
representations of all symbols in the sequence with each recurrent
step by applying a Transformer layer on the representations.</p></li>
<li><p>Compared to vanilla Transformer, Universal Transformer shares weights
among its layers, and it does not fix the recurrence time (which
means the number of layers in Transformer).</p></li>
</ul>
<p>A further optimization employs an <a class="reference external" href="https://arxiv.org/pdf/1603.08983.pdf">adaptive computation time
(ACT)</a> mechanism to allow the
model to dynamically adjust the number of times the representation of
each position in a sequence is revised (refereed to as <strong>step</strong>
hereafter). This model is also known as the Adaptive Universal
Transformer (AUT).</p>
<p>In AUT, you maintain an active nodes list. In each step <span class="math notranslate nohighlight">\(t\)</span>, we
compute a halting probability: <span class="math notranslate nohighlight">\(h (0&lt;h&lt;1)\)</span> for all nodes in this
list by:</p>
<div class="math notranslate nohighlight">
\[h^t_i = \sigma(W_h x^t_i + b_h)\]</div>
<p>then dynamically decide which nodes are still active. A node is halted
at time <span class="math notranslate nohighlight">\(T\)</span> if and only if
<span class="math notranslate nohighlight">\(\sum_{t=1}^{T-1} h_t &lt; 1 - \varepsilon \leq \sum_{t=1}^{T}h_t\)</span>.
Halted nodes are removed from the list. The procedure proceeds until the
list is empty or a pre-defined maximum step is reached. From DGL‚Äôs
perspective, this means that the ‚Äúactive‚Äù graph becomes sparser over
time.</p>
<p>The final state of a node <span class="math notranslate nohighlight">\(s_i\)</span> is a weighted average of
<span class="math notranslate nohighlight">\(x_i^t\)</span> by <span class="math notranslate nohighlight">\(h_i^t\)</span>:</p>
<div class="math notranslate nohighlight">
\[s_i = \sum_{t=1}^{T} h_i^t\cdot x_i^t\]</div>
<p>In DGL, implement an algorithm by calling
<code class="docutils literal notranslate"><span class="pre">update_graph</span></code> on nodes that are still active and edges associated
with this nodes. The following code shows the Universal Transformer
class in DGL:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">UTransformer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="s2">"Universal Transformer(https://arxiv.org/pdf/1807.03819.pdf) with ACT(https://arxiv.org/pdf/1603.08983.pdf)."</span>
    <span class="n">MAX_DEPTH</span> <span class="o">=</span> <span class="mi">8</span>
    <span class="n">thres</span> <span class="o">=</span> <span class="mf">0.99</span>
    <span class="n">act_loss_weight</span> <span class="o">=</span> <span class="mf">0.01</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">src_embed</span><span class="p">,</span> <span class="n">tgt_embed</span><span class="p">,</span> <span class="n">pos_enc</span><span class="p">,</span> <span class="n">time_enc</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">d_k</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">UTransformer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">,</span>  <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">src_embed</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tgt_embed</span> <span class="o">=</span> <span class="n">src_embed</span><span class="p">,</span> <span class="n">tgt_embed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pos_enc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">time_enc</span> <span class="o">=</span> <span class="n">pos_enc</span><span class="p">,</span> <span class="n">time_enc</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">halt_enc</span> <span class="o">=</span> <span class="n">HaltingUnit</span><span class="p">(</span><span class="n">h</span> <span class="o">*</span> <span class="n">d_k</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">halt_dec</span> <span class="o">=</span> <span class="n">HaltingUnit</span><span class="p">(</span><span class="n">h</span> <span class="o">*</span> <span class="n">d_k</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span> <span class="o">=</span> <span class="n">generator</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_k</span> <span class="o">=</span> <span class="n">h</span><span class="p">,</span> <span class="n">d_k</span>

    <span class="k">def</span> <span class="nf">step_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nodes</span><span class="p">):</span>
        <span class="c1"># add positional encoding and time encoding, increment step by one</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">'x'</span><span class="p">]</span>
        <span class="n">step</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">'step'</span><span class="p">]</span>
        <span class="n">pos</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">'pos'</span><span class="p">]</span>
        <span class="k">return</span> <span class="p">{</span><span class="s1">'x'</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_enc</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_enc</span><span class="p">(</span><span class="n">pos</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">time_enc</span><span class="p">(</span><span class="n">step</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))),</span>
                <span class="s1">'step'</span><span class="p">:</span> <span class="n">step</span> <span class="o">+</span> <span class="mi">1</span><span class="p">}</span>

    <span class="k">def</span> <span class="nf">halt_and_accum</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="s2">"field: 'enc' or 'dec'"</span>
        <span class="n">halt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">halt_enc</span> <span class="k">if</span> <span class="n">name</span> <span class="o">==</span> <span class="s1">'enc'</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">halt_dec</span>
        <span class="n">thres</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">thres</span>
        <span class="k">def</span> <span class="nf">func</span><span class="p">(</span><span class="n">nodes</span><span class="p">):</span>
            <span class="n">p</span> <span class="o">=</span> <span class="n">halt</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">'x'</span><span class="p">])</span>
            <span class="n">sum_p</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">'sum_p'</span><span class="p">]</span> <span class="o">+</span> <span class="n">p</span>
            <span class="n">active</span> <span class="o">=</span> <span class="p">(</span><span class="n">sum_p</span> <span class="o">&lt;</span> <span class="n">thres</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">end</span><span class="p">)</span>
            <span class="n">_continue</span> <span class="o">=</span> <span class="n">active</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
            <span class="n">r</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">'r'</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">_continue</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">sum_p</span><span class="p">)</span> <span class="o">*</span> <span class="n">_continue</span>
            <span class="n">s</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">'s'</span><span class="p">]</span> <span class="o">+</span> <span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">_continue</span><span class="p">)</span> <span class="o">*</span> <span class="n">r</span> <span class="o">+</span> <span class="n">_continue</span> <span class="o">*</span> <span class="n">p</span><span class="p">)</span> <span class="o">*</span> <span class="n">nodes</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">'x'</span><span class="p">]</span>
            <span class="k">return</span> <span class="p">{</span><span class="s1">'p'</span><span class="p">:</span> <span class="n">p</span><span class="p">,</span> <span class="s1">'sum_p'</span><span class="p">:</span> <span class="n">sum_p</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">:</span> <span class="n">r</span><span class="p">,</span> <span class="s1">'s'</span><span class="p">:</span> <span class="n">s</span><span class="p">,</span> <span class="s1">'active'</span><span class="p">:</span> <span class="n">active</span><span class="p">}</span>
        <span class="k">return</span> <span class="n">func</span>

    <span class="k">def</span> <span class="nf">propagate_attention</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">eids</span><span class="p">):</span>
        <span class="c1"># Compute attention score</span>
        <span class="n">g</span><span class="o">.</span><span class="n">apply_edges</span><span class="p">(</span><span class="n">src_dot_dst</span><span class="p">(</span><span class="s1">'k'</span><span class="p">,</span> <span class="s1">'q'</span><span class="p">,</span> <span class="s1">'score'</span><span class="p">),</span> <span class="n">eids</span><span class="p">)</span>
        <span class="n">g</span><span class="o">.</span><span class="n">apply_edges</span><span class="p">(</span><span class="n">scaled_exp</span><span class="p">(</span><span class="s1">'score'</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">d_k</span><span class="p">)),</span> <span class="n">eids</span><span class="p">)</span>
        <span class="c1"># Send weighted values to target nodes</span>
        <span class="n">g</span><span class="o">.</span><span class="n">send_and_recv</span><span class="p">(</span><span class="n">eids</span><span class="p">,</span>
                        <span class="p">[</span><span class="n">fn</span><span class="o">.</span><span class="n">u_mul_e</span><span class="p">(</span><span class="s1">'v'</span><span class="p">,</span> <span class="s1">'score'</span><span class="p">,</span> <span class="s1">'v'</span><span class="p">),</span> <span class="n">fn</span><span class="o">.</span><span class="n">copy_e</span><span class="p">(</span><span class="s1">'score'</span><span class="p">,</span> <span class="s1">'score'</span><span class="p">)],</span>
                        <span class="p">[</span><span class="n">fn</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="s1">'v'</span><span class="p">,</span> <span class="s1">'wv'</span><span class="p">),</span> <span class="n">fn</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="s1">'score'</span><span class="p">,</span> <span class="s1">'z'</span><span class="p">)])</span>

    <span class="k">def</span> <span class="nf">update_graph</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">eids</span><span class="p">,</span> <span class="n">pre_pairs</span><span class="p">,</span> <span class="n">post_pairs</span><span class="p">):</span>
        <span class="s2">"Update the node states and edge states of the graph."</span>
        <span class="c1"># Pre-compute queries and key-value pairs.</span>
        <span class="k">for</span> <span class="n">pre_func</span><span class="p">,</span> <span class="n">nids</span> <span class="ow">in</span> <span class="n">pre_pairs</span><span class="p">:</span>
            <span class="n">g</span><span class="o">.</span><span class="n">apply_nodes</span><span class="p">(</span><span class="n">pre_func</span><span class="p">,</span> <span class="n">nids</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">propagate_attention</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">eids</span><span class="p">)</span>
        <span class="c1"># Further calculation after attention mechanism</span>
        <span class="k">for</span> <span class="n">post_func</span><span class="p">,</span> <span class="n">nids</span> <span class="ow">in</span> <span class="n">post_pairs</span><span class="p">:</span>
            <span class="n">g</span><span class="o">.</span><span class="n">apply_nodes</span><span class="p">(</span><span class="n">post_func</span><span class="p">,</span> <span class="n">nids</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">graph</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">g</span>
        <span class="n">N</span><span class="p">,</span> <span class="n">E</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">n_nodes</span><span class="p">,</span> <span class="n">graph</span><span class="o">.</span><span class="n">n_edges</span>
        <span class="n">nids</span><span class="p">,</span> <span class="n">eids</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">nids</span><span class="p">,</span> <span class="n">graph</span><span class="o">.</span><span class="n">eids</span>

        <span class="c1"># embed &amp; pos</span>
        <span class="n">g</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">nids</span><span class="p">[</span><span class="s1">'enc'</span><span class="p">]]</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">'x'</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">src_embed</span><span class="p">(</span><span class="n">graph</span><span class="o">.</span><span class="n">src</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">g</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">nids</span><span class="p">[</span><span class="s1">'dec'</span><span class="p">]]</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">'x'</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tgt_embed</span><span class="p">(</span><span class="n">graph</span><span class="o">.</span><span class="n">tgt</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">g</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">nids</span><span class="p">[</span><span class="s1">'enc'</span><span class="p">]]</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">'pos'</span><span class="p">]</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">src</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">g</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">nids</span><span class="p">[</span><span class="s1">'dec'</span><span class="p">]]</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">'pos'</span><span class="p">]</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">tgt</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="c1"># init step</span>
        <span class="n">device</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span>
        <span class="n">g</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="s1">'s'</span><span class="p">]</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">h</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_k</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">th</span><span class="o">.</span><span class="n">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>    <span class="c1"># accumulated state</span>
        <span class="n">g</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="s1">'p'</span><span class="p">]</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">th</span><span class="o">.</span><span class="n">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>                    <span class="c1"># halting prob</span>
        <span class="n">g</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="s1">'r'</span><span class="p">]</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">th</span><span class="o">.</span><span class="n">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>                     <span class="c1"># remainder</span>
        <span class="n">g</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="s1">'sum_p'</span><span class="p">]</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">th</span><span class="o">.</span><span class="n">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>                <span class="c1"># sum of pondering values</span>
        <span class="n">g</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="s1">'step'</span><span class="p">]</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">th</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>                  <span class="c1"># step</span>
        <span class="n">g</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="s1">'active'</span><span class="p">]</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">th</span><span class="o">.</span><span class="n">uint8</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>                <span class="c1"># active</span>

        <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">MAX_DEPTH</span><span class="p">):</span>
            <span class="n">pre_func</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">pre_func</span><span class="p">(</span><span class="s1">'qkv'</span><span class="p">)</span>
            <span class="n">post_func</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">post_func</span><span class="p">()</span>
            <span class="n">nodes</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">filter_nodes</span><span class="p">(</span><span class="k">lambda</span> <span class="n">v</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">'active'</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">nids</span><span class="p">[</span><span class="s1">'enc'</span><span class="p">])</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">nodes</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="k">break</span>
            <span class="n">edges</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">filter_edges</span><span class="p">(</span><span class="k">lambda</span> <span class="n">e</span><span class="p">:</span> <span class="n">e</span><span class="o">.</span><span class="n">dst</span><span class="p">[</span><span class="s1">'active'</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">eids</span><span class="p">[</span><span class="s1">'ee'</span><span class="p">])</span>
            <span class="n">end</span> <span class="o">=</span> <span class="n">step</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">MAX_DEPTH</span> <span class="o">-</span> <span class="mi">1</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">update_graph</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">edges</span><span class="p">,</span>
                              <span class="p">[(</span><span class="bp">self</span><span class="o">.</span><span class="n">step_forward</span><span class="p">,</span> <span class="n">nodes</span><span class="p">),</span> <span class="p">(</span><span class="n">pre_func</span><span class="p">,</span> <span class="n">nodes</span><span class="p">)],</span>
                              <span class="p">[(</span><span class="n">post_func</span><span class="p">,</span> <span class="n">nodes</span><span class="p">),</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">halt_and_accum</span><span class="p">(</span><span class="s1">'enc'</span><span class="p">,</span> <span class="n">end</span><span class="p">),</span> <span class="n">nodes</span><span class="p">)])</span>

        <span class="n">g</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">nids</span><span class="p">[</span><span class="s1">'enc'</span><span class="p">]]</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">'x'</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">nids</span><span class="p">[</span><span class="s1">'enc'</span><span class="p">]]</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">'s'</span><span class="p">])</span>

        <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">MAX_DEPTH</span><span class="p">):</span>
            <span class="n">pre_func</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">pre_func</span><span class="p">(</span><span class="s1">'qkv'</span><span class="p">)</span>
            <span class="n">post_func</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">post_func</span><span class="p">()</span>
            <span class="n">nodes</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">filter_nodes</span><span class="p">(</span><span class="k">lambda</span> <span class="n">v</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">'active'</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">nids</span><span class="p">[</span><span class="s1">'dec'</span><span class="p">])</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">nodes</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="k">break</span>
            <span class="n">edges</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">filter_edges</span><span class="p">(</span><span class="k">lambda</span> <span class="n">e</span><span class="p">:</span> <span class="n">e</span><span class="o">.</span><span class="n">dst</span><span class="p">[</span><span class="s1">'active'</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">eids</span><span class="p">[</span><span class="s1">'dd'</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">update_graph</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">edges</span><span class="p">,</span>
                              <span class="p">[(</span><span class="bp">self</span><span class="o">.</span><span class="n">step_forward</span><span class="p">,</span> <span class="n">nodes</span><span class="p">),</span> <span class="p">(</span><span class="n">pre_func</span><span class="p">,</span> <span class="n">nodes</span><span class="p">)],</span>
                              <span class="p">[(</span><span class="n">post_func</span><span class="p">,</span> <span class="n">nodes</span><span class="p">)])</span>

            <span class="n">pre_q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">pre_func</span><span class="p">(</span><span class="s1">'q'</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">pre_kv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">pre_func</span><span class="p">(</span><span class="s1">'kv'</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">post_func</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">post_func</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">nodes_e</span> <span class="o">=</span> <span class="n">nids</span><span class="p">[</span><span class="s1">'enc'</span><span class="p">]</span>
            <span class="n">edges</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">filter_edges</span><span class="p">(</span><span class="k">lambda</span> <span class="n">e</span><span class="p">:</span> <span class="n">e</span><span class="o">.</span><span class="n">dst</span><span class="p">[</span><span class="s1">'active'</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">eids</span><span class="p">[</span><span class="s1">'ed'</span><span class="p">])</span>
            <span class="n">end</span> <span class="o">=</span> <span class="n">step</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">MAX_DEPTH</span> <span class="o">-</span> <span class="mi">1</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">update_graph</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">edges</span><span class="p">,</span>
                              <span class="p">[(</span><span class="n">pre_q</span><span class="p">,</span> <span class="n">nodes</span><span class="p">),</span> <span class="p">(</span><span class="n">pre_kv</span><span class="p">,</span> <span class="n">nodes_e</span><span class="p">)],</span>
                              <span class="p">[(</span><span class="n">post_func</span><span class="p">,</span> <span class="n">nodes</span><span class="p">),</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">halt_and_accum</span><span class="p">(</span><span class="s1">'dec'</span><span class="p">,</span> <span class="n">end</span><span class="p">),</span> <span class="n">nodes</span><span class="p">)])</span>

        <span class="n">g</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">nids</span><span class="p">[</span><span class="s1">'dec'</span><span class="p">]]</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">'x'</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">nids</span><span class="p">[</span><span class="s1">'dec'</span><span class="p">]]</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">'s'</span><span class="p">])</span>
        <span class="n">act_loss</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="s1">'r'</span><span class="p">])</span> <span class="c1"># ACT loss</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="s1">'x'</span><span class="p">][</span><span class="n">nids</span><span class="p">[</span><span class="s1">'dec'</span><span class="p">]]),</span> <span class="n">act_loss</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">act_loss_weight</span>
</pre></div>
</div>
<p>Call <code class="docutils literal notranslate"><span class="pre">filter_nodes</span></code> and <code class="docutils literal notranslate"><span class="pre">filter_edge</span></code> to find nodes/edges
that are still active:</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p><a class="reference internal" href="../../../generated/dgl.DGLGraph.filter_nodes.html#dgl.DGLGraph.filter_nodes" title="dgl.DGLGraph.filter_nodes"><code class="xref py py-func docutils literal notranslate"><span class="pre">filter_nodes()</span></code></a> takes a predicate and a node
ID list/tensor as input, then returns a tensor of node IDs that satisfy
the given predicate.</p></li>
<li><p><a class="reference internal" href="../../../generated/dgl.DGLGraph.filter_edges.html#dgl.DGLGraph.filter_edges" title="dgl.DGLGraph.filter_edges"><code class="xref py py-func docutils literal notranslate"><span class="pre">filter_edges()</span></code></a> takes a predicate
and an edge ID list/tensor as input, then returns a tensor of edge IDs
that satisfy the given predicate.</p></li>
</ul>
</div>
<p>For the full implementation, see the <a class="reference external" href="https://github.com/dmlc/dgl/tree/master/examples/pytorch/transformer/modules/act.py">GitHub
repo</a>.</p>
<p>The figure below shows the effect of Adaptive Computational
Time. Different positions of a sentence were revised different times.</p>
<p><img alt="image9" src="https://s1.ax1x.com/2018/12/06/F1sGod.png"/></p>
<p>You can also visualize the dynamics of step distribution on nodes during the
training of AUT on sort task(reach 99.7% accuracy), which demonstrates
how AUT learns to reduce recurrence steps during training. <img alt="image10" src="https://s1.ax1x.com/2018/12/06/F1r8Cq.gif"/></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The notebook itself is not executable due to many dependencies.
Download <a class="reference external" href="https://data.dgl.ai/tutorial/7_transformer.py">7_transformer.py</a>,
and copy the python script to directory <code class="docutils literal notranslate"><span class="pre">examples/pytorch/transformer</span></code>
then run <code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">7_transformer.py</span></code> to see how it works.</p>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (0 minutes 0.000 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-tutorials-models-4-old-wines-7-transformer-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../../_downloads/42cf0d440f6b51705d7278393a5a17dc/7_transformer.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">7_transformer.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../../_downloads/4b738f924b641d9fd10a3e5454302fa5/7_transformer.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">7_transformer.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../../../_downloads/99b4e83db6fff7f810348a10ace8cb1a/7_transformer.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">7_transformer.zip</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>
</div>
</div>
<footer><div aria-label="Footer" class="rst-footer-buttons" role="navigation">
<a accesskey="p" class="btn btn-neutral float-left" href="2_capsule.html" rel="prev" title="Capsule Network"><span aria-hidden="true" class="fa fa-arrow-circle-left"></span> Previous</a>
<a accesskey="n" class="btn btn-neutral float-right" href="../../../api/python/dgl.html" rel="next" title="dgl">Next <span aria-hidden="true" class="fa fa-arrow-circle-right"></span></a>
</div>
<hr/>
<div role="contentinfo">
<p>¬© Copyright 2018, DGL Team.</p>
</div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
</div>
</div>
</section>
</div>
<div aria-label="Versions" class="rst-versions" data-toggle="rst-versions" role="note">
<span class="rst-current-version" data-toggle="rst-current-version">
<span class="fa fa-book"> Read the Docs</span>
<span id="version-placeholder">v: latest</span>
<span class="fa fa-caret-down"></span>
</span>
<div class="rst-other-versions">
<dl>
<dt>Versions</dt>
<div id="version-list">
<!-- Âä®ÊÄÅÊèíÂÖ•ÁöÑÁâàÊú¨ÂàóË°®Â∞ÜÂá∫Áé∞Âú®ËøôÈáå -->
</div>
</dl>
<dl>
<dt>Downloads</dt>
<!-- ‰∏ãËΩΩÂÜÖÂÆπ -->
</dl>
<dl>
<dt>On Read the Docs</dt>
<dd><a href="//doc-build.dgl.ai/projects/dgl/?fromdocs=dgl">Project Home</a></dd>
<dd><a href="//doc-build.dgl.ai/builds/dgl/?fromdocs=dgl">Builds</a></dd>
</dl>
</div>
</div>
<script>
        document.addEventListener("DOMContentLoaded", function() {
            fetch('/dgl_docs/branches.json')
                .then(response => response.json())
                .then(data => {
                    var versionListDiv = document.getElementById('version-list');
                    data.branches.forEach(function(branch) {
                        var dd = document.createElement('dd');
                        var a = document.createElement('a');
                        a.href = branch.url;
                        a.textContent = branch.name;
                        dd.appendChild(a);
                        versionListDiv.appendChild(dd);
                    });
                })
                .catch(error => console.error('Error loading branches:', error));
        });
        document.addEventListener("DOMContentLoaded", function() {
            // Ëé∑ÂèñÂΩìÂâçË∑ØÂæÑ
            var path = window.location.pathname;
            var versionPlaceholder = document.getElementById('version-placeholder');

            // Ê£ÄÊü•Ë∑ØÂæÑ‰∏≠ÊòØÂê¶ÂåÖÂê´ 'en'
            if (path.includes('/en/')) {
                // ÊèêÂèñ 'en' ÂêéÁöÑÊñá‰ª∂Â§π‰Ωú‰∏∫ÁâàÊú¨Âè∑
                var parts = path.split('/en/');
                if (parts[1]) {
                    var folders = parts[1].split('/');
                    if (folders.length > 0 && folders[0]) {
                        versionPlaceholder.textContent = 'v: ' + folders[0];
                    } else {
                        versionPlaceholder.textContent = 'v: latest';
                    }
                } else {
                    versionPlaceholder.textContent = 'v: latest';
                }
            } else {
                versionPlaceholder.textContent = 'v: latest';
            }
        });
    </script>

<script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
</body>
</html>