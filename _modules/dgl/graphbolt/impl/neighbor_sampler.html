
<!DOCTYPE html>

<html class="writer-html5" data-content_root="../../../../" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>dgl.graphbolt.impl.neighbor_sampler — DGL 2.5 documentation</title>
<link href="../../../../_static/pygments.css?v=80d5e7a1" rel="stylesheet" type="text/css"/>
<link href="../../../../_static/css/theme.css?v=7ab3649f" rel="stylesheet" type="text/css"/>
<link href="../../../../_static/graphviz.css?v=fd3f3429" rel="stylesheet" type="text/css"/>
<link href="../../../../_static/copybutton.css?v=76b2166b" rel="stylesheet" type="text/css"/>
<link href="../../../../_static/sg_gallery.css?v=d2d258e8" rel="stylesheet" type="text/css"/>
<link href="../../../../_static/sg_gallery-binder.css?v=f4aeca0c" rel="stylesheet" type="text/css"/>
<link href="../../../../_static/sg_gallery-dataframe.css?v=2082cf3c" rel="stylesheet" type="text/css"/>
<link href="../../../../_static/sg_gallery-rendered-html.css?v=1277b6f3" rel="stylesheet" type="text/css"/>
<link href="../../../../_static/css/custom.css?v=0bf289b5" rel="stylesheet" type="text/css"/>
<script src="../../../../_static/jquery.js?v=5d32c60e"></script>
<script src="../../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
<script src="../../../../_static/documentation_options.js?v=38d273f4"></script>
<script src="../../../../_static/doctools.js?v=9a2dae69"></script>
<script src="../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
<script src="../../../../_static/clipboard.min.js?v=a7894cd8"></script>
<script src="../../../../_static/copybutton.js?v=ccdb6887"></script>
<script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
<script src="../../../../_static/js/theme.js"></script>
<link href="../../../../genindex.html" rel="index" title="Index"/>
<link href="../../../../search.html" rel="search" title="Search"/>
</head>
<body class="wy-body-for-nav">
<div class="wy-grid-for-nav">
<nav class="wy-nav-side" data-toggle="wy-nav-shift">
<div class="wy-side-scroll">
<div class="wy-side-nav-search">
<a class="icon icon-home" href="../../../../index.html">
            DGL
          </a>
<div role="search">
<form action="../../../../search.html" class="wy-form" id="rtd-search-form" method="get">
<input aria-label="Search docs" name="q" placeholder="Search docs" type="text"/>
<input name="check_keywords" type="hidden" value="yes"/>
<input name="area" type="hidden" value="default"/>
</form>
</div>
</div><div aria-label="Navigation menu" class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation">
<p class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../install/index.html">Install and Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/blitz/index.html">A Blitz Introduction to DGL</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Materials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../stochastic_training/index.html">🆕 Stochastic Training of GNNs with GraphBolt</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../guide/index.html">User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../guide_cn/index.html">用户指南【包含过时信息】</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../guide_ko/index.html">사용자 가이드[시대에 뒤쳐진]</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../graphtransformer/index.html">🆕 Tutorial: Graph Transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebooks/sparse/index.html">Tutorials: dgl.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/cpu/index.html">Training on CPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/multi/index.html">Training on Multiple GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/dist/index.html">Distributed training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials/models/index.html">Paper Study with DGL</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../api/python/dgl.html">dgl</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api/python/dgl.data.html">dgl.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api/python/dgl.dataloading.html">dgl.dataloading</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api/python/dgl.DGLGraph.html">dgl.DGLGraph</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api/python/dgl.distributed.html">dgl.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api/python/dgl.function.html">dgl.function</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api/python/dgl.geometry.html">dgl.geometry</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api/python/dgl.graphbolt.html">🆕 dgl.graphbolt</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api/python/nn-pytorch.html">dgl.nn (PyTorch)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api/python/nn.functional.html">dgl.nn.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api/python/dgl.ops.html">dgl.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api/python/dgl.optim.html">dgl.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api/python/dgl.sampling.html">dgl.sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api/python/dgl.sparse_v0.html">dgl.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api/python/dgl.multiprocessing.html">dgl.multiprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api/python/transforms.html">dgl.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api/python/udf.html">User-defined Functions</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../contribute.html">Contribute to DGL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../developer/ffi.html">DGL Foreign Function Interface (FFI)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../performance.html">Performance Benchmarks</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Misc</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq.html">Frequently Asked Questions (FAQ)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../env_var.html">Environment Variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../resources.html">Resources</a></li>
</ul>
</div>
</div>
</nav>
<section class="wy-nav-content-wrap" data-toggle="wy-nav-shift"><nav aria-label="Mobile navigation menu" class="wy-nav-top">
<i class="fa fa-bars" data-toggle="wy-nav-top"></i>
<a href="../../../../index.html">DGL</a>
</nav>
<div class="wy-nav-content">
<div class="rst-content">
<div aria-label="Page navigation" role="navigation">
<ul class="wy-breadcrumbs">
<li><a aria-label="Home" class="icon icon-home" href="../../../../index.html"></a></li>
<li class="breadcrumb-item"><a href="../../../index.html">Module code</a></li>
<li class="breadcrumb-item active">dgl.graphbolt.impl.neighbor_sampler</li>
<li class="wy-breadcrumbs-aside">
</li>
</ul>
<hr/>
</div>
<div class="document" itemscope="itemscope" itemtype="http://schema.org/Article" role="main">
<div itemprop="articleBody">
<h1>Source code for dgl.graphbolt.impl.neighbor_sampler</h1><div class="highlight"><pre>
<span></span><span class="sd">"""Neighbor subgraph samplers for GraphBolt."""</span>

<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.distributed</span> <span class="k">as</span> <span class="nn">thd</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">functional_datapipe</span>
<span class="kn">from</span> <span class="nn">torch.utils.data.datapipes.iter</span> <span class="kn">import</span> <span class="n">Mapper</span>

<span class="kn">from</span> <span class="nn">..base</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">etype_str_to_tuple</span><span class="p">,</span>
    <span class="n">get_host_to_device_uva_stream</span><span class="p">,</span>
    <span class="n">index_select</span><span class="p">,</span>
    <span class="n">ORIGINAL_EDGE_ID</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">..internal</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">compact_csc_format</span><span class="p">,</span>
    <span class="n">unique_and_compact</span><span class="p">,</span>
    <span class="n">unique_and_compact_csc_formats</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">..minibatch_transformer</span> <span class="kn">import</span> <span class="n">MiniBatchTransformer</span>

<span class="kn">from</span> <span class="nn">..subgraph_sampler</span> <span class="kn">import</span> <span class="n">all_to_all</span><span class="p">,</span> <span class="n">revert_to_homo</span><span class="p">,</span> <span class="n">SubgraphSampler</span>
<span class="kn">from</span> <span class="nn">.fused_csc_sampling_graph</span> <span class="kn">import</span> <span class="n">fused_csc_sampling_graph</span>
<span class="kn">from</span> <span class="nn">.sampled_subgraph_impl</span> <span class="kn">import</span> <span class="n">SampledSubgraphImpl</span>


<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">"NeighborSampler"</span><span class="p">,</span>
    <span class="s2">"LayerNeighborSampler"</span><span class="p">,</span>
    <span class="s2">"SamplePerLayer"</span><span class="p">,</span>
    <span class="s2">"FetchInsubgraphData"</span><span class="p">,</span>
    <span class="s2">"CombineCachedAndFetchedInSubgraph"</span><span class="p">,</span>
<span class="p">]</span>


<span class="nd">@functional_datapipe</span><span class="p">(</span><span class="s2">"fetch_cached_insubgraph_data"</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">FetchCachedInsubgraphData</span><span class="p">(</span><span class="n">Mapper</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Queries the GPUGraphCache and returns the missing seeds and a generator</span>
<span class="sd">    handle that can be called with the fetched graph structure.</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">datapipe</span><span class="p">,</span> <span class="n">gpu_graph_cache</span><span class="p">):</span>
        <span class="n">datapipe</span> <span class="o">=</span> <span class="n">datapipe</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_fetch_per_layer</span><span class="p">)</span><span class="o">.</span><span class="n">buffer</span><span class="p">()</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">datapipe</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_wait_query_future</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cache</span> <span class="o">=</span> <span class="n">gpu_graph_cache</span>

    <span class="k">def</span> <span class="nf">_fetch_per_layer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">minibatch</span><span class="p">):</span>
        <span class="n">minibatch</span><span class="o">.</span><span class="n">_async_handle</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="o">.</span><span class="n">query_async</span><span class="p">(</span><span class="n">minibatch</span><span class="o">.</span><span class="n">_seeds</span><span class="p">)</span>
        <span class="c1"># Start first stage</span>
        <span class="nb">next</span><span class="p">(</span><span class="n">minibatch</span><span class="o">.</span><span class="n">_async_handle</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">minibatch</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_wait_query_future</span><span class="p">(</span><span class="n">minibatch</span><span class="p">):</span>
        <span class="n">minibatch</span><span class="o">.</span><span class="n">_seeds</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">minibatch</span><span class="o">.</span><span class="n">_async_handle</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">minibatch</span>


<span class="nd">@functional_datapipe</span><span class="p">(</span><span class="s2">"combine_cached_and_fetched_insubgraph"</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">CombineCachedAndFetchedInSubgraph</span><span class="p">(</span><span class="n">Mapper</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Combined the fetched graph structure with the graph structure already</span>
<span class="sd">    found inside the GPUGraphCache.</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">datapipe</span><span class="p">,</span> <span class="n">prob_name</span><span class="p">):</span>
        <span class="n">datapipe</span> <span class="o">=</span> <span class="n">datapipe</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_combine_per_layer</span><span class="p">)</span><span class="o">.</span><span class="n">buffer</span><span class="p">()</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">datapipe</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_wait_replace_future</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prob_name</span> <span class="o">=</span> <span class="n">prob_name</span>

    <span class="k">def</span> <span class="nf">_combine_per_layer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">minibatch</span><span class="p">):</span>
        <span class="n">subgraph</span> <span class="o">=</span> <span class="n">minibatch</span><span class="o">.</span><span class="n">_sliced_sampling_graph</span>

        <span class="n">edge_tensors</span> <span class="o">=</span> <span class="p">[</span><span class="n">subgraph</span><span class="o">.</span><span class="n">indices</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">subgraph</span><span class="o">.</span><span class="n">type_per_edge</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">edge_tensors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">subgraph</span><span class="o">.</span><span class="n">type_per_edge</span><span class="p">)</span>
        <span class="n">probs_or_mask</span> <span class="o">=</span> <span class="n">subgraph</span><span class="o">.</span><span class="n">edge_attribute</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prob_name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">probs_or_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">edge_tensors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">probs_or_mask</span><span class="p">)</span>
        <span class="n">edge_tensors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">subgraph</span><span class="o">.</span><span class="n">edge_attribute</span><span class="p">(</span><span class="n">ORIGINAL_EDGE_ID</span><span class="p">))</span>

        <span class="n">minibatch</span><span class="o">.</span><span class="n">_future</span> <span class="o">=</span> <span class="n">minibatch</span><span class="o">.</span><span class="n">_async_handle</span><span class="o">.</span><span class="n">send</span><span class="p">(</span>
            <span class="p">(</span><span class="n">subgraph</span><span class="o">.</span><span class="n">csc_indptr</span><span class="p">,</span> <span class="n">edge_tensors</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="nb">delattr</span><span class="p">(</span><span class="n">minibatch</span><span class="p">,</span> <span class="s2">"_async_handle"</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">minibatch</span>

    <span class="k">def</span> <span class="nf">_wait_replace_future</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">minibatch</span><span class="p">):</span>
        <span class="n">subgraph</span> <span class="o">=</span> <span class="n">minibatch</span><span class="o">.</span><span class="n">_sliced_sampling_graph</span>
        <span class="n">subgraph</span><span class="o">.</span><span class="n">csc_indptr</span><span class="p">,</span> <span class="n">edge_tensors</span> <span class="o">=</span> <span class="n">minibatch</span><span class="o">.</span><span class="n">_future</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>
        <span class="nb">delattr</span><span class="p">(</span><span class="n">minibatch</span><span class="p">,</span> <span class="s2">"_future"</span><span class="p">)</span>

        <span class="n">subgraph</span><span class="o">.</span><span class="n">indices</span> <span class="o">=</span> <span class="n">edge_tensors</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">edge_tensors</span> <span class="o">=</span> <span class="n">edge_tensors</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
        <span class="k">if</span> <span class="n">subgraph</span><span class="o">.</span><span class="n">type_per_edge</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">subgraph</span><span class="o">.</span><span class="n">type_per_edge</span> <span class="o">=</span> <span class="n">edge_tensors</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">edge_tensors</span> <span class="o">=</span> <span class="n">edge_tensors</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
        <span class="n">probs_or_mask</span> <span class="o">=</span> <span class="n">subgraph</span><span class="o">.</span><span class="n">edge_attribute</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prob_name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">probs_or_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">subgraph</span><span class="o">.</span><span class="n">add_edge_attribute</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prob_name</span><span class="p">,</span> <span class="n">edge_tensors</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">edge_tensors</span> <span class="o">=</span> <span class="n">edge_tensors</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
        <span class="n">subgraph</span><span class="o">.</span><span class="n">add_edge_attribute</span><span class="p">(</span><span class="n">ORIGINAL_EDGE_ID</span><span class="p">,</span> <span class="n">edge_tensors</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">edge_tensors</span> <span class="o">=</span> <span class="n">edge_tensors</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">edge_tensors</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span>

        <span class="k">return</span> <span class="n">minibatch</span>


<span class="nd">@functional_datapipe</span><span class="p">(</span><span class="s2">"fetch_insubgraph_data"</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">FetchInsubgraphData</span><span class="p">(</span><span class="n">MiniBatchTransformer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Fetches the insubgraph and wraps it in a FusedCSCSamplingGraph object. If</span>
<span class="sd">    the provided sample_per_layer_obj has a valid prob_name, then it reads the</span>
<span class="sd">    probabilies of all the fetched edges. Furthermore, if type_per_array tensor</span>
<span class="sd">    exists in the underlying graph, then the types of all the fetched edges are</span>
<span class="sd">    read as well."""</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">datapipe</span><span class="p">,</span>
        <span class="n">graph</span><span class="p">,</span>
        <span class="n">prob_name</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="n">datapipe</span> <span class="o">=</span> <span class="n">datapipe</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_concat_hetero_seeds</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">graph</span><span class="o">.</span><span class="n">_gpu_graph_cache</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">datapipe</span> <span class="o">=</span> <span class="n">datapipe</span><span class="o">.</span><span class="n">fetch_cached_insubgraph_data</span><span class="p">(</span>
                <span class="n">graph</span><span class="o">.</span><span class="n">_gpu_graph_cache</span>
            <span class="p">)</span>
        <span class="n">datapipe</span> <span class="o">=</span> <span class="n">datapipe</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_fetch_per_layer_stage_1</span><span class="p">)</span>
        <span class="n">datapipe</span> <span class="o">=</span> <span class="n">datapipe</span><span class="o">.</span><span class="n">buffer</span><span class="p">()</span>
        <span class="n">datapipe</span> <span class="o">=</span> <span class="n">datapipe</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_fetch_per_layer_stage_2</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">graph</span><span class="o">.</span><span class="n">_gpu_graph_cache</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">datapipe</span> <span class="o">=</span> <span class="n">datapipe</span><span class="o">.</span><span class="n">combine_cached_and_fetched_insubgraph</span><span class="p">(</span><span class="n">prob_name</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">datapipe</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">graph</span> <span class="o">=</span> <span class="n">graph</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prob_name</span> <span class="o">=</span> <span class="n">prob_name</span>

    <span class="k">def</span> <span class="nf">_concat_hetero_seeds</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">minibatch</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""Concatenates the seeds into a single tensor in the hetero case."""</span>
        <span class="n">seeds</span> <span class="o">=</span> <span class="n">minibatch</span><span class="o">.</span><span class="n">_seed_nodes</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">seeds</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="p">(</span>
                <span class="n">seeds</span><span class="p">,</span>
                <span class="n">seed_offsets</span><span class="p">,</span>
            <span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">_convert_to_homogeneous_nodes</span><span class="p">(</span><span class="n">seeds</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">seed_offsets</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">minibatch</span><span class="o">.</span><span class="n">_seeds</span> <span class="o">=</span> <span class="n">seeds</span>
        <span class="n">minibatch</span><span class="o">.</span><span class="n">_seed_offsets</span> <span class="o">=</span> <span class="n">seed_offsets</span>

        <span class="k">return</span> <span class="n">minibatch</span>

    <span class="k">def</span> <span class="nf">_fetch_per_layer_stage_1</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">minibatch</span><span class="p">):</span>
        <span class="n">minibatch</span><span class="o">.</span><span class="n">_async_handle_fetch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fetch_per_layer_async</span><span class="p">(</span><span class="n">minibatch</span><span class="p">)</span>
        <span class="nb">next</span><span class="p">(</span><span class="n">minibatch</span><span class="o">.</span><span class="n">_async_handle_fetch</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">minibatch</span>

    <span class="k">def</span> <span class="nf">_fetch_per_layer_stage_2</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">minibatch</span><span class="p">):</span>
        <span class="n">minibatch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">minibatch</span><span class="o">.</span><span class="n">_async_handle_fetch</span><span class="p">)</span>
        <span class="nb">delattr</span><span class="p">(</span><span class="n">minibatch</span><span class="p">,</span> <span class="s2">"_async_handle_fetch"</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">minibatch</span>

    <span class="k">def</span> <span class="nf">_fetch_per_layer_async</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">minibatch</span><span class="p">):</span>
        <span class="n">stream</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_stream</span><span class="p">()</span>
        <span class="n">uva_stream</span> <span class="o">=</span> <span class="n">get_host_to_device_uva_stream</span><span class="p">()</span>
        <span class="n">uva_stream</span><span class="o">.</span><span class="n">wait_stream</span><span class="p">(</span><span class="n">stream</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">stream</span><span class="p">(</span><span class="n">uva_stream</span><span class="p">):</span>
            <span class="n">seeds</span> <span class="o">=</span> <span class="n">minibatch</span><span class="o">.</span><span class="n">_seeds</span>
            <span class="n">seed_offsets</span> <span class="o">=</span> <span class="n">minibatch</span><span class="o">.</span><span class="n">_seed_offsets</span>
            <span class="nb">delattr</span><span class="p">(</span><span class="n">minibatch</span><span class="p">,</span> <span class="s2">"_seeds"</span><span class="p">)</span>
            <span class="nb">delattr</span><span class="p">(</span><span class="n">minibatch</span><span class="p">,</span> <span class="s2">"_seed_offsets"</span><span class="p">)</span>

            <span class="n">seeds</span><span class="o">.</span><span class="n">record_stream</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_stream</span><span class="p">())</span>

            <span class="c1"># Packs tensors for batch slicing.</span>
            <span class="n">tensors_to_be_sliced</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">indices</span><span class="p">]</span>

            <span class="n">has_type_per_edge</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">type_per_edge</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">tensors_to_be_sliced</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">type_per_edge</span><span class="p">)</span>
                <span class="n">has_type_per_edge</span> <span class="o">=</span> <span class="kc">True</span>

            <span class="n">has_probs_or_mask</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">has_original_edge_ids</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">edge_attributes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">probs_or_mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">edge_attributes</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">prob_name</span><span class="p">,</span> <span class="kc">None</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="n">probs_or_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">tensors_to_be_sliced</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">probs_or_mask</span><span class="p">)</span>
                    <span class="n">has_probs_or_mask</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="n">original_edge_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">edge_attributes</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                    <span class="n">ORIGINAL_EDGE_ID</span><span class="p">,</span> <span class="kc">None</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="n">original_edge_ids</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">tensors_to_be_sliced</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">original_edge_ids</span><span class="p">)</span>
                    <span class="n">has_original_edge_ids</span> <span class="o">=</span> <span class="kc">True</span>

            <span class="c1"># Slices the batched tensors.</span>
            <span class="n">future</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">graphbolt</span><span class="o">.</span><span class="n">index_select_csc_batched_async</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">csc_indptr</span><span class="p">,</span>
                <span class="n">tensors_to_be_sliced</span><span class="p">,</span>
                <span class="n">seeds</span><span class="p">,</span>
                <span class="c1"># When there are no edge ids, we assume it is arange(num_edges).</span>
                <span class="ow">not</span> <span class="n">has_original_edge_ids</span><span class="p">,</span>
                <span class="kc">None</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">yield</span>

        <span class="c1"># graphbolt::async has already recorded a CUDAEvent for us and</span>
        <span class="c1"># called CUDAStreamWaitEvent for us on the current stream.</span>
        <span class="n">indptr</span><span class="p">,</span> <span class="n">sliced_tensors</span> <span class="o">=</span> <span class="n">future</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="p">[</span><span class="n">indptr</span><span class="p">]</span> <span class="o">+</span> <span class="n">sliced_tensors</span><span class="p">:</span>
            <span class="n">tensor</span><span class="o">.</span><span class="n">record_stream</span><span class="p">(</span><span class="n">stream</span><span class="p">)</span>

        <span class="c1"># Unpacks the sliced tensors.</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">sliced_tensors</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">sliced_tensors</span> <span class="o">=</span> <span class="n">sliced_tensors</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>

        <span class="n">type_per_edge</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">has_type_per_edge</span><span class="p">:</span>
            <span class="n">type_per_edge</span> <span class="o">=</span> <span class="n">sliced_tensors</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">sliced_tensors</span> <span class="o">=</span> <span class="n">sliced_tensors</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>

        <span class="n">probs_or_mask</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">has_probs_or_mask</span><span class="p">:</span>
            <span class="n">probs_or_mask</span> <span class="o">=</span> <span class="n">sliced_tensors</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">sliced_tensors</span> <span class="o">=</span> <span class="n">sliced_tensors</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>

        <span class="n">edge_ids</span> <span class="o">=</span> <span class="n">sliced_tensors</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">sliced_tensors</span> <span class="o">=</span> <span class="n">sliced_tensors</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">sliced_tensors</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span>

        <span class="n">subgraph</span> <span class="o">=</span> <span class="n">fused_csc_sampling_graph</span><span class="p">(</span>
            <span class="n">indptr</span><span class="p">,</span>
            <span class="n">indices</span><span class="p">,</span>
            <span class="n">node_type_offset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">node_type_offset</span><span class="p">,</span>
            <span class="n">type_per_edge</span><span class="o">=</span><span class="n">type_per_edge</span><span class="p">,</span>
            <span class="n">node_type_to_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">node_type_to_id</span><span class="p">,</span>
            <span class="n">edge_type_to_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">edge_type_to_id</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">prob_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">probs_or_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">subgraph</span><span class="o">.</span><span class="n">add_edge_attribute</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prob_name</span><span class="p">,</span> <span class="n">probs_or_mask</span><span class="p">)</span>
        <span class="n">subgraph</span><span class="o">.</span><span class="n">add_edge_attribute</span><span class="p">(</span><span class="n">ORIGINAL_EDGE_ID</span><span class="p">,</span> <span class="n">edge_ids</span><span class="p">)</span>

        <span class="n">subgraph</span><span class="o">.</span><span class="n">_indptr_node_type_offset_list</span> <span class="o">=</span> <span class="n">seed_offsets</span>
        <span class="n">minibatch</span><span class="o">.</span><span class="n">_sliced_sampling_graph</span> <span class="o">=</span> <span class="n">subgraph</span>

        <span class="k">yield</span> <span class="n">minibatch</span>


<span class="nd">@functional_datapipe</span><span class="p">(</span><span class="s2">"sample_per_layer"</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">SamplePerLayer</span><span class="p">(</span><span class="n">MiniBatchTransformer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Sample neighbor edges from a graph for a single layer."""</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">datapipe</span><span class="p">,</span>
        <span class="n">sampler</span><span class="p">,</span>
        <span class="n">fanout</span><span class="p">,</span>
        <span class="n">replace</span><span class="p">,</span>
        <span class="n">prob_name</span><span class="p">,</span>
        <span class="n">overlap_fetch</span><span class="p">,</span>
        <span class="n">asynchronous</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="n">graph</span> <span class="o">=</span> <span class="n">sampler</span><span class="o">.</span><span class="vm">__self__</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">returning_indices_and_original_edge_ids_are_optional</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">original_edge_ids</span> <span class="o">=</span> <span class="p">(</span>
            <span class="kc">None</span>
            <span class="k">if</span> <span class="n">graph</span><span class="o">.</span><span class="n">edge_attributes</span> <span class="ow">is</span> <span class="kc">None</span>
            <span class="k">else</span> <span class="n">graph</span><span class="o">.</span><span class="n">edge_attributes</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">ORIGINAL_EDGE_ID</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="n">overlap_fetch</span>
            <span class="ow">and</span> <span class="n">sampler</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">==</span> <span class="s2">"sample_neighbors"</span>
            <span class="ow">and</span> <span class="p">(</span>
                <span class="n">graph</span><span class="o">.</span><span class="n">indices</span><span class="o">.</span><span class="n">is_pinned</span><span class="p">()</span>
                <span class="ow">or</span> <span class="p">(</span>
                    <span class="n">original_edge_ids</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                    <span class="ow">and</span> <span class="n">original_edge_ids</span><span class="o">.</span><span class="n">is_pinned</span><span class="p">()</span>
                <span class="p">)</span>
            <span class="p">)</span>
            <span class="ow">and</span> <span class="n">graph</span><span class="o">.</span><span class="n">_gpu_graph_cache</span> <span class="ow">is</span> <span class="kc">None</span>
        <span class="p">):</span>
            <span class="n">datapipe</span> <span class="o">=</span> <span class="n">datapipe</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_sample_per_layer</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">asynchronous</span><span class="p">:</span>
                <span class="n">datapipe</span> <span class="o">=</span> <span class="n">datapipe</span><span class="o">.</span><span class="n">buffer</span><span class="p">()</span>
                <span class="n">datapipe</span> <span class="o">=</span> <span class="n">datapipe</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_wait_subgraph_future</span><span class="p">)</span>
            <span class="n">fetch_indices_and_original_edge_ids_fn</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_fetch_indices_and_original_edge_ids</span><span class="p">,</span>
                <span class="n">graph</span><span class="o">.</span><span class="n">indices</span><span class="p">,</span>
                <span class="n">original_edge_ids</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">datapipe</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">datapipe</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">fetch_indices_and_original_edge_ids_fn</span><span class="p">)</span>
                <span class="o">.</span><span class="n">buffer</span><span class="p">()</span>
                <span class="o">.</span><span class="n">wait</span><span class="p">()</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">graph</span><span class="o">.</span><span class="n">type_per_edge</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># Hetero case.</span>
                <span class="n">datapipe</span> <span class="o">=</span> <span class="n">datapipe</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span>
                    <span class="n">partial</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_subtract_hetero_indices_offset</span><span class="p">,</span>
                        <span class="n">graph</span><span class="o">.</span><span class="n">_node_type_offset_list</span><span class="p">,</span>
                        <span class="n">graph</span><span class="o">.</span><span class="n">node_type_to_id</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">returning_indices_and_original_edge_ids_are_optional</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">elif</span> <span class="n">overlap_fetch</span><span class="p">:</span>
            <span class="n">datapipe</span> <span class="o">=</span> <span class="n">datapipe</span><span class="o">.</span><span class="n">fetch_insubgraph_data</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="n">prob_name</span><span class="p">)</span>
            <span class="n">datapipe</span> <span class="o">=</span> <span class="n">datapipe</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_sample_per_layer_from_fetched_subgraph</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">asynchronous</span><span class="p">:</span>
                <span class="n">datapipe</span> <span class="o">=</span> <span class="n">datapipe</span><span class="o">.</span><span class="n">buffer</span><span class="p">()</span>
                <span class="n">datapipe</span> <span class="o">=</span> <span class="n">datapipe</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_wait_subgraph_future</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">datapipe</span> <span class="o">=</span> <span class="n">datapipe</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_sample_per_layer</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">asynchronous</span><span class="p">:</span>
                <span class="n">datapipe</span> <span class="o">=</span> <span class="n">datapipe</span><span class="o">.</span><span class="n">buffer</span><span class="p">()</span>
                <span class="n">datapipe</span> <span class="o">=</span> <span class="n">datapipe</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_wait_subgraph_future</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">datapipe</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sampler</span> <span class="o">=</span> <span class="n">sampler</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fanout</span> <span class="o">=</span> <span class="n">fanout</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">replace</span> <span class="o">=</span> <span class="n">replace</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prob_name</span> <span class="o">=</span> <span class="n">prob_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">overlap_fetch</span> <span class="o">=</span> <span class="n">overlap_fetch</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">asynchronous</span> <span class="o">=</span> <span class="n">asynchronous</span>

    <span class="k">def</span> <span class="nf">_sample_per_layer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">minibatch</span><span class="p">):</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">key</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">minibatch</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">"_random_seed"</span><span class="p">,</span> <span class="s2">"_seed2_contribution"</span><span class="p">]</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">minibatch</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span>
        <span class="p">}</span>
        <span class="n">subgraph</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sampler</span><span class="p">(</span>
            <span class="n">minibatch</span><span class="o">.</span><span class="n">_seed_nodes</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fanout</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">replace</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">prob_name</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">returning_indices_and_original_edge_ids_are_optional</span><span class="p">,</span>
            <span class="n">async_op</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">asynchronous</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">minibatch</span><span class="o">.</span><span class="n">sampled_subgraphs</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">subgraph</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">minibatch</span>

    <span class="k">def</span> <span class="nf">_sample_per_layer_from_fetched_subgraph</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">minibatch</span><span class="p">):</span>
        <span class="n">subgraph</span> <span class="o">=</span> <span class="n">minibatch</span><span class="o">.</span><span class="n">_sliced_sampling_graph</span>
        <span class="nb">delattr</span><span class="p">(</span><span class="n">minibatch</span><span class="p">,</span> <span class="s2">"_sliced_sampling_graph"</span><span class="p">)</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">key</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">minibatch</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">"_random_seed"</span><span class="p">,</span> <span class="s2">"_seed2_contribution"</span><span class="p">]</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">minibatch</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span>
        <span class="p">}</span>
        <span class="n">sampled_subgraph</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">subgraph</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">sampler</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)(</span>
            <span class="kc">None</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fanout</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">replace</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">prob_name</span><span class="p">,</span>
            <span class="n">async_op</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">asynchronous</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">minibatch</span><span class="o">.</span><span class="n">sampled_subgraphs</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">sampled_subgraph</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">minibatch</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_wait_subgraph_future</span><span class="p">(</span><span class="n">minibatch</span><span class="p">):</span>
        <span class="n">minibatch</span><span class="o">.</span><span class="n">sampled_subgraphs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">minibatch</span><span class="o">.</span><span class="n">sampled_subgraphs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">minibatch</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_fetch_indices_and_original_edge_ids</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">orig_edge_ids</span><span class="p">,</span> <span class="n">minibatch</span><span class="p">):</span>
        <span class="n">stream</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_stream</span><span class="p">()</span>
        <span class="n">host_to_device_stream</span> <span class="o">=</span> <span class="n">get_host_to_device_uva_stream</span><span class="p">()</span>
        <span class="n">host_to_device_stream</span><span class="o">.</span><span class="n">wait_stream</span><span class="p">(</span><span class="n">stream</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">record_stream</span><span class="p">(</span><span class="n">tensor</span><span class="p">):</span>
            <span class="n">tensor</span><span class="o">.</span><span class="n">record_stream</span><span class="p">(</span><span class="n">stream</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">tensor</span>

        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">stream</span><span class="p">(</span><span class="n">host_to_device_stream</span><span class="p">):</span>
            <span class="n">minibatch</span><span class="o">.</span><span class="n">_indices_needs_offset_subtraction</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">subgraph</span> <span class="o">=</span> <span class="n">minibatch</span><span class="o">.</span><span class="n">sampled_subgraphs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">subgraph</span><span class="o">.</span><span class="n">sampled_csc</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">etype</span><span class="p">,</span> <span class="n">pair</span> <span class="ow">in</span> <span class="n">subgraph</span><span class="o">.</span><span class="n">sampled_csc</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="k">if</span> <span class="n">pair</span><span class="o">.</span><span class="n">indices</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">edge_ids</span> <span class="o">=</span> <span class="p">(</span>
                            <span class="n">subgraph</span><span class="o">.</span><span class="n">_edge_ids_in_fused_csc_sampling_graph</span><span class="p">[</span>
                                <span class="n">etype</span>
                            <span class="p">]</span>
                        <span class="p">)</span>
                        <span class="n">edge_ids</span><span class="o">.</span><span class="n">record_stream</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_stream</span><span class="p">())</span>
                        <span class="n">pair</span><span class="o">.</span><span class="n">indices</span> <span class="o">=</span> <span class="n">record_stream</span><span class="p">(</span>
                            <span class="n">index_select</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">edge_ids</span><span class="p">)</span>
                        <span class="p">)</span>
                        <span class="n">minibatch</span><span class="o">.</span><span class="n">_indices_needs_offset_subtraction</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="k">if</span> <span class="p">(</span>
                        <span class="n">orig_edge_ids</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                        <span class="ow">and</span> <span class="n">subgraph</span><span class="o">.</span><span class="n">original_edge_ids</span><span class="p">[</span><span class="n">etype</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span>
                    <span class="p">):</span>
                        <span class="n">edge_ids</span> <span class="o">=</span> <span class="p">(</span>
                            <span class="n">subgraph</span><span class="o">.</span><span class="n">_edge_ids_in_fused_csc_sampling_graph</span><span class="p">[</span>
                                <span class="n">etype</span>
                            <span class="p">]</span>
                        <span class="p">)</span>
                        <span class="n">edge_ids</span><span class="o">.</span><span class="n">record_stream</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_stream</span><span class="p">())</span>
                        <span class="n">subgraph</span><span class="o">.</span><span class="n">original_edge_ids</span><span class="p">[</span><span class="n">etype</span><span class="p">]</span> <span class="o">=</span> <span class="n">record_stream</span><span class="p">(</span>
                            <span class="n">index_select</span><span class="p">(</span><span class="n">orig_edge_ids</span><span class="p">,</span> <span class="n">edge_ids</span><span class="p">)</span>
                        <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">subgraph</span><span class="o">.</span><span class="n">sampled_csc</span><span class="o">.</span><span class="n">indices</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">subgraph</span><span class="o">.</span><span class="n">_edge_ids_in_fused_csc_sampling_graph</span><span class="o">.</span><span class="n">record_stream</span><span class="p">(</span>
                        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_stream</span><span class="p">()</span>
                    <span class="p">)</span>
                    <span class="n">subgraph</span><span class="o">.</span><span class="n">sampled_csc</span><span class="o">.</span><span class="n">indices</span> <span class="o">=</span> <span class="n">record_stream</span><span class="p">(</span>
                        <span class="n">index_select</span><span class="p">(</span>
                            <span class="n">indices</span><span class="p">,</span>
                            <span class="n">subgraph</span><span class="o">.</span><span class="n">_edge_ids_in_fused_csc_sampling_graph</span><span class="p">,</span>
                        <span class="p">)</span>
                    <span class="p">)</span>
                <span class="k">if</span> <span class="p">(</span>
                    <span class="n">orig_edge_ids</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                    <span class="ow">and</span> <span class="n">subgraph</span><span class="o">.</span><span class="n">original_edge_ids</span> <span class="ow">is</span> <span class="kc">None</span>
                <span class="p">):</span>
                    <span class="n">subgraph</span><span class="o">.</span><span class="n">_edge_ids_in_fused_csc_sampling_graph</span><span class="o">.</span><span class="n">record_stream</span><span class="p">(</span>
                        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_stream</span><span class="p">()</span>
                    <span class="p">)</span>
                    <span class="n">subgraph</span><span class="o">.</span><span class="n">original_edge_ids</span> <span class="o">=</span> <span class="n">record_stream</span><span class="p">(</span>
                        <span class="n">index_select</span><span class="p">(</span>
                            <span class="n">orig_edge_ids</span><span class="p">,</span>
                            <span class="n">subgraph</span><span class="o">.</span><span class="n">_edge_ids_in_fused_csc_sampling_graph</span><span class="p">,</span>
                        <span class="p">)</span>
                    <span class="p">)</span>
            <span class="n">subgraph</span><span class="o">.</span><span class="n">_edge_ids_in_fused_csc_sampling_graph</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">minibatch</span><span class="o">.</span><span class="n">wait</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_stream</span><span class="p">()</span><span class="o">.</span><span class="n">record_event</span><span class="p">()</span><span class="o">.</span><span class="n">wait</span>

        <span class="k">return</span> <span class="n">minibatch</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_subtract_hetero_indices_offset</span><span class="p">(</span>
        <span class="n">node_type_offset</span><span class="p">,</span> <span class="n">node_type_to_id</span><span class="p">,</span> <span class="n">minibatch</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">minibatch</span><span class="o">.</span><span class="n">_indices_needs_offset_subtraction</span><span class="p">:</span>
            <span class="n">subgraph</span> <span class="o">=</span> <span class="n">minibatch</span><span class="o">.</span><span class="n">sampled_subgraphs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">etype</span><span class="p">,</span> <span class="n">pair</span> <span class="ow">in</span> <span class="n">subgraph</span><span class="o">.</span><span class="n">sampled_csc</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">src_ntype</span> <span class="o">=</span> <span class="n">etype_str_to_tuple</span><span class="p">(</span><span class="n">etype</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">src_ntype_id</span> <span class="o">=</span> <span class="n">node_type_to_id</span><span class="p">[</span><span class="n">src_ntype</span><span class="p">]</span>
                <span class="n">pair</span><span class="o">.</span><span class="n">indices</span> <span class="o">-=</span> <span class="n">node_type_offset</span><span class="p">[</span><span class="n">src_ntype_id</span><span class="p">]</span>
        <span class="nb">delattr</span><span class="p">(</span><span class="n">minibatch</span><span class="p">,</span> <span class="s2">"_indices_needs_offset_subtraction"</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">minibatch</span>


<span class="nd">@functional_datapipe</span><span class="p">(</span><span class="s2">"compact_per_layer"</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">CompactPerLayer</span><span class="p">(</span><span class="n">MiniBatchTransformer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Compact the sampled edges for a single layer."""</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">datapipe</span><span class="p">,</span> <span class="n">deduplicate</span><span class="p">,</span> <span class="n">cooperative</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">asynchronous</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">deduplicate</span> <span class="o">=</span> <span class="n">deduplicate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cooperative</span> <span class="o">=</span> <span class="n">cooperative</span>
        <span class="k">if</span> <span class="n">asynchronous</span> <span class="ow">and</span> <span class="n">deduplicate</span><span class="p">:</span>
            <span class="n">datapipe</span> <span class="o">=</span> <span class="n">datapipe</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_compact_per_layer_async</span><span class="p">)</span>
            <span class="n">datapipe</span> <span class="o">=</span> <span class="n">datapipe</span><span class="o">.</span><span class="n">buffer</span><span class="p">()</span>
            <span class="n">datapipe</span> <span class="o">=</span> <span class="n">datapipe</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_compact_per_layer_wait_future</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">cooperative</span><span class="p">:</span>
                <span class="n">datapipe</span> <span class="o">=</span> <span class="n">datapipe</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_seeds_cooperative_exchange_1</span>
                <span class="p">)</span>
                <span class="n">datapipe</span> <span class="o">=</span> <span class="n">datapipe</span><span class="o">.</span><span class="n">buffer</span><span class="p">()</span>
                <span class="n">datapipe</span> <span class="o">=</span> <span class="n">datapipe</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_seeds_cooperative_exchange_2</span>
                <span class="p">)</span>
                <span class="n">datapipe</span> <span class="o">=</span> <span class="n">datapipe</span><span class="o">.</span><span class="n">buffer</span><span class="p">()</span>
                <span class="n">datapipe</span> <span class="o">=</span> <span class="n">datapipe</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_seeds_cooperative_exchange_3</span>
                <span class="p">)</span>
                <span class="n">datapipe</span> <span class="o">=</span> <span class="n">datapipe</span><span class="o">.</span><span class="n">buffer</span><span class="p">()</span>
                <span class="n">datapipe</span> <span class="o">=</span> <span class="n">datapipe</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_seeds_cooperative_exchange_4</span>
                <span class="p">)</span>
            <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">datapipe</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">datapipe</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compact_per_layer</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_compact_per_layer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">minibatch</span><span class="p">):</span>
        <span class="n">subgraph</span> <span class="o">=</span> <span class="n">minibatch</span><span class="o">.</span><span class="n">sampled_subgraphs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">seeds</span> <span class="o">=</span> <span class="n">minibatch</span><span class="o">.</span><span class="n">_seed_nodes</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">deduplicate</span><span class="p">:</span>
            <span class="p">(</span>
                <span class="n">original_row_node_ids</span><span class="p">,</span>
                <span class="n">compacted_csc_format</span><span class="p">,</span>
                <span class="n">_</span><span class="p">,</span>
            <span class="p">)</span> <span class="o">=</span> <span class="n">unique_and_compact_csc_formats</span><span class="p">(</span><span class="n">subgraph</span><span class="o">.</span><span class="n">sampled_csc</span><span class="p">,</span> <span class="n">seeds</span><span class="p">)</span>
            <span class="n">subgraph</span> <span class="o">=</span> <span class="n">SampledSubgraphImpl</span><span class="p">(</span>
                <span class="n">sampled_csc</span><span class="o">=</span><span class="n">compacted_csc_format</span><span class="p">,</span>
                <span class="n">original_column_node_ids</span><span class="o">=</span><span class="n">seeds</span><span class="p">,</span>
                <span class="n">original_row_node_ids</span><span class="o">=</span><span class="n">original_row_node_ids</span><span class="p">,</span>
                <span class="n">original_edge_ids</span><span class="o">=</span><span class="n">subgraph</span><span class="o">.</span><span class="n">original_edge_ids</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="p">(</span>
                <span class="n">original_row_node_ids</span><span class="p">,</span>
                <span class="n">compacted_csc_format</span><span class="p">,</span>
            <span class="p">)</span> <span class="o">=</span> <span class="n">compact_csc_format</span><span class="p">(</span><span class="n">subgraph</span><span class="o">.</span><span class="n">sampled_csc</span><span class="p">,</span> <span class="n">seeds</span><span class="p">)</span>
            <span class="n">subgraph</span> <span class="o">=</span> <span class="n">SampledSubgraphImpl</span><span class="p">(</span>
                <span class="n">sampled_csc</span><span class="o">=</span><span class="n">compacted_csc_format</span><span class="p">,</span>
                <span class="n">original_column_node_ids</span><span class="o">=</span><span class="n">seeds</span><span class="p">,</span>
                <span class="n">original_row_node_ids</span><span class="o">=</span><span class="n">original_row_node_ids</span><span class="p">,</span>
                <span class="n">original_edge_ids</span><span class="o">=</span><span class="n">subgraph</span><span class="o">.</span><span class="n">original_edge_ids</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="n">minibatch</span><span class="o">.</span><span class="n">_seed_nodes</span> <span class="o">=</span> <span class="n">original_row_node_ids</span>
        <span class="n">minibatch</span><span class="o">.</span><span class="n">sampled_subgraphs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">subgraph</span>
        <span class="k">return</span> <span class="n">minibatch</span>

    <span class="k">def</span> <span class="nf">_compact_per_layer_async</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">minibatch</span><span class="p">):</span>
        <span class="n">subgraph</span> <span class="o">=</span> <span class="n">minibatch</span><span class="o">.</span><span class="n">sampled_subgraphs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">seeds</span> <span class="o">=</span> <span class="n">minibatch</span><span class="o">.</span><span class="n">_seed_nodes</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">deduplicate</span>
        <span class="n">rank</span> <span class="o">=</span> <span class="n">thd</span><span class="o">.</span><span class="n">get_rank</span><span class="p">()</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cooperative</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="n">world_size</span> <span class="o">=</span> <span class="n">thd</span><span class="o">.</span><span class="n">get_world_size</span><span class="p">()</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cooperative</span> <span class="k">else</span> <span class="mi">1</span>
        <span class="n">minibatch</span><span class="o">.</span><span class="n">_future</span> <span class="o">=</span> <span class="n">unique_and_compact_csc_formats</span><span class="p">(</span>
            <span class="n">subgraph</span><span class="o">.</span><span class="n">sampled_csc</span><span class="p">,</span> <span class="n">seeds</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="n">world_size</span><span class="p">,</span> <span class="n">async_op</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">minibatch</span>

    <span class="k">def</span> <span class="nf">_compact_per_layer_wait_future</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">minibatch</span><span class="p">):</span>
        <span class="n">subgraph</span> <span class="o">=</span> <span class="n">minibatch</span><span class="o">.</span><span class="n">sampled_subgraphs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">seeds</span> <span class="o">=</span> <span class="n">minibatch</span><span class="o">.</span><span class="n">_seed_nodes</span>
        <span class="p">(</span>
            <span class="n">original_row_node_ids</span><span class="p">,</span>
            <span class="n">compacted_csc_format</span><span class="p">,</span>
            <span class="n">seeds_offsets</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="n">minibatch</span><span class="o">.</span><span class="n">_future</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>
        <span class="nb">delattr</span><span class="p">(</span><span class="n">minibatch</span><span class="p">,</span> <span class="s2">"_future"</span><span class="p">)</span>
        <span class="n">subgraph</span> <span class="o">=</span> <span class="n">SampledSubgraphImpl</span><span class="p">(</span>
            <span class="n">sampled_csc</span><span class="o">=</span><span class="n">compacted_csc_format</span><span class="p">,</span>
            <span class="n">original_column_node_ids</span><span class="o">=</span><span class="n">seeds</span><span class="p">,</span>
            <span class="n">original_row_node_ids</span><span class="o">=</span><span class="n">original_row_node_ids</span><span class="p">,</span>
            <span class="n">original_edge_ids</span><span class="o">=</span><span class="n">subgraph</span><span class="o">.</span><span class="n">original_edge_ids</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">minibatch</span><span class="o">.</span><span class="n">_seed_nodes</span> <span class="o">=</span> <span class="n">original_row_node_ids</span>
        <span class="n">minibatch</span><span class="o">.</span><span class="n">sampled_subgraphs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">subgraph</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cooperative</span><span class="p">:</span>
            <span class="n">subgraph</span><span class="o">.</span><span class="n">_seeds_offsets</span> <span class="o">=</span> <span class="n">seeds_offsets</span>
        <span class="k">return</span> <span class="n">minibatch</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_seeds_cooperative_exchange_1</span><span class="p">(</span><span class="n">minibatch</span><span class="p">):</span>
        <span class="n">world_size</span> <span class="o">=</span> <span class="n">thd</span><span class="o">.</span><span class="n">get_world_size</span><span class="p">()</span>
        <span class="n">subgraph</span> <span class="o">=</span> <span class="n">minibatch</span><span class="o">.</span><span class="n">sampled_subgraphs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">seeds_offsets</span> <span class="o">=</span> <span class="n">subgraph</span><span class="o">.</span><span class="n">_seeds_offsets</span>
        <span class="n">is_homogeneous</span> <span class="o">=</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">seeds_offsets</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">is_homogeneous</span><span class="p">:</span>
            <span class="n">seeds_offsets</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"_N"</span><span class="p">:</span> <span class="n">seeds_offsets</span><span class="p">}</span>
        <span class="n">num_ntypes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">seeds_offsets</span><span class="p">)</span>
        <span class="n">counts_sent</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">world_size</span> <span class="o">*</span> <span class="n">num_ntypes</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">offsets</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">seeds_offsets</span><span class="o">.</span><span class="n">values</span><span class="p">()):</span>
            <span class="n">counts_sent</span><span class="p">[</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">world_size</span> <span class="o">*</span> <span class="n">num_ntypes</span><span class="p">,</span> <span class="n">num_ntypes</span><span class="p">)</span>
            <span class="p">]</span> <span class="o">=</span> <span class="n">offsets</span><span class="o">.</span><span class="n">diff</span><span class="p">()</span>
        <span class="n">counts_received</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">counts_sent</span><span class="p">)</span>
        <span class="n">subgraph</span><span class="o">.</span><span class="n">_counts_future</span> <span class="o">=</span> <span class="n">all_to_all</span><span class="p">(</span>
            <span class="n">counts_received</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">num_ntypes</span><span class="p">),</span>
            <span class="n">counts_sent</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">num_ntypes</span><span class="p">),</span>
            <span class="n">async_op</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">subgraph</span><span class="o">.</span><span class="n">_counts_sent</span> <span class="o">=</span> <span class="n">counts_sent</span>
        <span class="n">subgraph</span><span class="o">.</span><span class="n">_counts_received</span> <span class="o">=</span> <span class="n">counts_received</span>
        <span class="k">return</span> <span class="n">minibatch</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_seeds_cooperative_exchange_2</span><span class="p">(</span><span class="n">minibatch</span><span class="p">):</span>
        <span class="n">world_size</span> <span class="o">=</span> <span class="n">thd</span><span class="o">.</span><span class="n">get_world_size</span><span class="p">()</span>
        <span class="n">seeds</span> <span class="o">=</span> <span class="n">minibatch</span><span class="o">.</span><span class="n">_seed_nodes</span>
        <span class="n">is_homogenous</span> <span class="o">=</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">seeds</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">is_homogenous</span><span class="p">:</span>
            <span class="n">seeds</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"_N"</span><span class="p">:</span> <span class="n">seeds</span><span class="p">}</span>
        <span class="n">subgraph</span> <span class="o">=</span> <span class="n">minibatch</span><span class="o">.</span><span class="n">sampled_subgraphs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">subgraph</span><span class="o">.</span><span class="n">_counts_future</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>
        <span class="nb">delattr</span><span class="p">(</span><span class="n">subgraph</span><span class="p">,</span> <span class="s2">"_counts_future"</span><span class="p">)</span>
        <span class="n">num_ntypes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">seeds</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="n">seeds_received</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">counts_sent</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">counts_received</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">ntype</span><span class="p">,</span> <span class="n">typed_seeds</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">seeds</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">world_size</span> <span class="o">*</span> <span class="n">num_ntypes</span><span class="p">,</span> <span class="n">num_ntypes</span><span class="p">)</span>
            <span class="n">typed_counts_sent</span> <span class="o">=</span> <span class="n">subgraph</span><span class="o">.</span><span class="n">_counts_sent</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
            <span class="n">typed_counts_received</span> <span class="o">=</span> <span class="n">subgraph</span><span class="o">.</span><span class="n">_counts_received</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
            <span class="n">typed_seeds_received</span> <span class="o">=</span> <span class="n">typed_seeds</span><span class="o">.</span><span class="n">new_empty</span><span class="p">(</span>
                <span class="nb">sum</span><span class="p">(</span><span class="n">typed_counts_received</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">all_to_all</span><span class="p">(</span>
                <span class="n">typed_seeds_received</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">typed_counts_received</span><span class="p">),</span>
                <span class="n">typed_seeds</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">typed_counts_sent</span><span class="p">),</span>
            <span class="p">)</span>
            <span class="n">seeds_received</span><span class="p">[</span><span class="n">ntype</span><span class="p">]</span> <span class="o">=</span> <span class="n">typed_seeds_received</span>
            <span class="n">counts_sent</span><span class="p">[</span><span class="n">ntype</span><span class="p">]</span> <span class="o">=</span> <span class="n">typed_counts_sent</span>
            <span class="n">counts_received</span><span class="p">[</span><span class="n">ntype</span><span class="p">]</span> <span class="o">=</span> <span class="n">typed_counts_received</span>
        <span class="n">minibatch</span><span class="o">.</span><span class="n">_seed_nodes</span> <span class="o">=</span> <span class="n">seeds_received</span>
        <span class="n">subgraph</span><span class="o">.</span><span class="n">_counts_sent</span> <span class="o">=</span> <span class="n">revert_to_homo</span><span class="p">(</span><span class="n">counts_sent</span><span class="p">)</span>
        <span class="n">subgraph</span><span class="o">.</span><span class="n">_counts_received</span> <span class="o">=</span> <span class="n">revert_to_homo</span><span class="p">(</span><span class="n">counts_received</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">minibatch</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_seeds_cooperative_exchange_3</span><span class="p">(</span><span class="n">minibatch</span><span class="p">):</span>
        <span class="n">nodes</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">ntype</span><span class="p">:</span> <span class="p">[</span><span class="n">typed_seeds</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">ntype</span><span class="p">,</span> <span class="n">typed_seeds</span> <span class="ow">in</span> <span class="n">minibatch</span><span class="o">.</span><span class="n">_seed_nodes</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
        <span class="p">}</span>
        <span class="n">minibatch</span><span class="o">.</span><span class="n">_unique_future</span> <span class="o">=</span> <span class="n">unique_and_compact</span><span class="p">(</span>
            <span class="n">nodes</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">async_op</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">minibatch</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_seeds_cooperative_exchange_4</span><span class="p">(</span><span class="n">minibatch</span><span class="p">):</span>
        <span class="n">unique_seeds</span><span class="p">,</span> <span class="n">inverse_seeds</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">minibatch</span><span class="o">.</span><span class="n">_unique_future</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>
        <span class="nb">delattr</span><span class="p">(</span><span class="n">minibatch</span><span class="p">,</span> <span class="s2">"_unique_future"</span><span class="p">)</span>
        <span class="n">inverse_seeds</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">ntype</span><span class="p">:</span> <span class="n">typed_inv</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">ntype</span><span class="p">,</span> <span class="n">typed_inv</span> <span class="ow">in</span> <span class="n">inverse_seeds</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
        <span class="p">}</span>
        <span class="n">minibatch</span><span class="o">.</span><span class="n">_seed_nodes</span> <span class="o">=</span> <span class="n">revert_to_homo</span><span class="p">(</span><span class="n">unique_seeds</span><span class="p">)</span>
        <span class="n">subgraph</span> <span class="o">=</span> <span class="n">minibatch</span><span class="o">.</span><span class="n">sampled_subgraphs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">sizes</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">ntype</span><span class="p">:</span> <span class="n">typed_seeds</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">ntype</span><span class="p">,</span> <span class="n">typed_seeds</span> <span class="ow">in</span> <span class="n">unique_seeds</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
        <span class="p">}</span>
        <span class="n">subgraph</span><span class="o">.</span><span class="n">_seed_sizes</span> <span class="o">=</span> <span class="n">revert_to_homo</span><span class="p">(</span><span class="n">sizes</span><span class="p">)</span>
        <span class="n">subgraph</span><span class="o">.</span><span class="n">_seed_inverse_ids</span> <span class="o">=</span> <span class="n">revert_to_homo</span><span class="p">(</span><span class="n">inverse_seeds</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">minibatch</span>


<span class="k">class</span> <span class="nc">NeighborSamplerImpl</span><span class="p">(</span><span class="n">SubgraphSampler</span><span class="p">):</span>
    <span class="c1"># pylint: disable=abstract-method</span>
<span class="w">    </span><span class="sd">"""Base class for NeighborSamplers."""</span>

    <span class="c1"># pylint: disable=useless-super-delegation</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">datapipe</span><span class="p">,</span>
        <span class="n">graph</span><span class="p">,</span>
        <span class="n">fanouts</span><span class="p">,</span>
        <span class="n">replace</span><span class="p">,</span>
        <span class="n">prob_name</span><span class="p">,</span>
        <span class="n">deduplicate</span><span class="p">,</span>
        <span class="n">sampler</span><span class="p">,</span>
        <span class="n">overlap_fetch</span><span class="p">,</span>
        <span class="n">num_gpu_cached_edges</span><span class="p">,</span>
        <span class="n">gpu_cache_threshold</span><span class="p">,</span>
        <span class="n">cooperative</span><span class="p">,</span>
        <span class="n">asynchronous</span><span class="p">,</span>
        <span class="n">layer_dependency</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">batch_dependency</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">overlap_fetch</span> <span class="ow">and</span> <span class="n">num_gpu_cached_edges</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">graph</span><span class="o">.</span><span class="n">_gpu_graph_cache</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">graph</span><span class="o">.</span><span class="n">_initialize_gpu_graph_cache</span><span class="p">(</span>
                    <span class="n">num_gpu_cached_edges</span><span class="p">,</span> <span class="n">gpu_cache_threshold</span><span class="p">,</span> <span class="n">prob_name</span>
                <span class="p">)</span>
        <span class="k">if</span> <span class="n">sampler</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">==</span> <span class="s2">"sample_layer_neighbors"</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_init_seed</span><span class="p">(</span><span class="n">batch_dependency</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">datapipe</span><span class="p">,</span>
            <span class="n">graph</span><span class="p">,</span>
            <span class="n">fanouts</span><span class="p">,</span>
            <span class="n">replace</span><span class="p">,</span>
            <span class="n">prob_name</span><span class="p">,</span>
            <span class="n">deduplicate</span><span class="p">,</span>
            <span class="n">sampler</span><span class="p">,</span>
            <span class="n">overlap_fetch</span><span class="p">,</span>
            <span class="n">cooperative</span><span class="o">=</span><span class="n">cooperative</span><span class="p">,</span>
            <span class="n">asynchronous</span><span class="o">=</span><span class="n">asynchronous</span><span class="p">,</span>
            <span class="n">layer_dependency</span><span class="o">=</span><span class="n">layer_dependency</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_init_seed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_dependency</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rng</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="mf">1e18</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="nb">tuple</span><span class="p">())</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cnt</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">batch_dependency</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_seed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
            <span class="mi">2</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cnt</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_seed</span><span class="o">.</span><span class="n">random_</span><span class="p">(</span><span class="n">generator</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">rng</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_set_seed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">minibatch</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cnt</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cnt</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">cnt</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">cnt</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">random_seed</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">random_seed</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">random_seed</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">random_</span><span class="p">(</span><span class="n">generator</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">rng</span><span class="p">)</span>
        <span class="n">minibatch</span><span class="o">.</span><span class="n">_random_seed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">random_seed</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="n">minibatch</span><span class="o">.</span><span class="n">_seed2_contribution</span> <span class="o">=</span> <span class="p">(</span>
            <span class="mf">0.0</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cnt</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">1</span>
            <span class="k">else</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cnt</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">cnt</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">cnt</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="n">minibatch</span><span class="o">.</span><span class="n">_iter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cnt</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">minibatch</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_increment_seed</span><span class="p">(</span><span class="n">minibatch</span><span class="p">):</span>
        <span class="n">minibatch</span><span class="o">.</span><span class="n">_random_seed</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">minibatch</span><span class="o">.</span><span class="n">_random_seed</span>
        <span class="k">return</span> <span class="n">minibatch</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_delattr_dependency</span><span class="p">(</span><span class="n">minibatch</span><span class="p">):</span>
        <span class="nb">delattr</span><span class="p">(</span><span class="n">minibatch</span><span class="p">,</span> <span class="s2">"_random_seed"</span><span class="p">)</span>
        <span class="nb">delattr</span><span class="p">(</span><span class="n">minibatch</span><span class="p">,</span> <span class="s2">"_seed2_contribution"</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">minibatch</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_prepare</span><span class="p">(</span><span class="n">node_type_to_id</span><span class="p">,</span> <span class="n">minibatch</span><span class="p">):</span>
        <span class="n">seeds</span> <span class="o">=</span> <span class="n">minibatch</span><span class="o">.</span><span class="n">_seed_nodes</span>
        <span class="c1"># Enrich seeds with all node types.</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">seeds</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">ntypes</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">node_type_to_id</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
            <span class="c1"># Loop over different seeds to extract the device they are on.</span>
            <span class="n">device</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">dtype</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">seed</span> <span class="ow">in</span> <span class="n">seeds</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">device</span> <span class="o">=</span> <span class="n">seed</span><span class="o">.</span><span class="n">device</span>
                <span class="n">dtype</span> <span class="o">=</span> <span class="n">seed</span><span class="o">.</span><span class="n">dtype</span>
                <span class="k">break</span>
            <span class="n">default_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
            <span class="n">seeds</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">ntype</span><span class="p">:</span> <span class="n">seeds</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">ntype</span><span class="p">,</span> <span class="n">default_tensor</span><span class="p">)</span> <span class="k">for</span> <span class="n">ntype</span> <span class="ow">in</span> <span class="n">ntypes</span>
            <span class="p">}</span>
        <span class="n">minibatch</span><span class="o">.</span><span class="n">_seed_nodes</span> <span class="o">=</span> <span class="n">seeds</span>
        <span class="n">minibatch</span><span class="o">.</span><span class="n">sampled_subgraphs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">return</span> <span class="n">minibatch</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_set_input_nodes</span><span class="p">(</span><span class="n">minibatch</span><span class="p">):</span>
        <span class="n">minibatch</span><span class="o">.</span><span class="n">input_nodes</span> <span class="o">=</span> <span class="n">minibatch</span><span class="o">.</span><span class="n">_seed_nodes</span>
        <span class="k">return</span> <span class="n">minibatch</span>

    <span class="c1"># pylint: disable=arguments-differ</span>
    <span class="k">def</span> <span class="nf">sampling_stages</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">datapipe</span><span class="p">,</span>
        <span class="n">graph</span><span class="p">,</span>
        <span class="n">fanouts</span><span class="p">,</span>
        <span class="n">replace</span><span class="p">,</span>
        <span class="n">prob_name</span><span class="p">,</span>
        <span class="n">deduplicate</span><span class="p">,</span>
        <span class="n">sampler</span><span class="p">,</span>
        <span class="n">overlap_fetch</span><span class="p">,</span>
        <span class="n">cooperative</span><span class="p">,</span>
        <span class="n">asynchronous</span><span class="p">,</span>
        <span class="n">layer_dependency</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="n">datapipe</span> <span class="o">=</span> <span class="n">datapipe</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span>
            <span class="n">partial</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_prepare</span><span class="p">,</span> <span class="n">graph</span><span class="o">.</span><span class="n">node_type_to_id</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">is_labor</span> <span class="o">=</span> <span class="n">sampler</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">==</span> <span class="s2">"sample_layer_neighbors"</span>
        <span class="k">if</span> <span class="n">is_labor</span><span class="p">:</span>
            <span class="n">datapipe</span> <span class="o">=</span> <span class="n">datapipe</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_set_seed</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">fanout</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="n">fanouts</span><span class="p">):</span>
            <span class="c1"># Convert fanout to tensor.</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">fanout</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                <span class="n">fanout</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="nb">int</span><span class="p">(</span><span class="n">fanout</span><span class="p">)])</span>
            <span class="n">datapipe</span> <span class="o">=</span> <span class="n">datapipe</span><span class="o">.</span><span class="n">sample_per_layer</span><span class="p">(</span>
                <span class="n">sampler</span><span class="p">,</span> <span class="n">fanout</span><span class="p">,</span> <span class="n">replace</span><span class="p">,</span> <span class="n">prob_name</span><span class="p">,</span> <span class="n">overlap_fetch</span><span class="p">,</span> <span class="n">asynchronous</span>
            <span class="p">)</span>
            <span class="n">datapipe</span> <span class="o">=</span> <span class="n">datapipe</span><span class="o">.</span><span class="n">compact_per_layer</span><span class="p">(</span>
                <span class="n">deduplicate</span><span class="p">,</span> <span class="n">cooperative</span><span class="p">,</span> <span class="n">asynchronous</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">is_labor</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">layer_dependency</span><span class="p">:</span>
                <span class="n">datapipe</span> <span class="o">=</span> <span class="n">datapipe</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_increment_seed</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">is_labor</span><span class="p">:</span>
            <span class="n">datapipe</span> <span class="o">=</span> <span class="n">datapipe</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_delattr_dependency</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">datapipe</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_set_input_nodes</span><span class="p">)</span>


<div class="viewcode-block" id="NeighborSampler">
<a class="viewcode-back" href="../../../../generated/dgl.graphbolt.NeighborSampler.html#dgl.graphbolt.NeighborSampler">[docs]</a>
<span class="nd">@functional_datapipe</span><span class="p">(</span><span class="s2">"sample_neighbor"</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">NeighborSampler</span><span class="p">(</span><span class="n">NeighborSamplerImpl</span><span class="p">):</span>
    <span class="c1"># pylint: disable=abstract-method</span>
<span class="w">    </span><span class="sd">"""Sample neighbor edges from a graph and return a subgraph.</span>

<span class="sd">    Functional name: :obj:`sample_neighbor`.</span>

<span class="sd">    Neighbor sampler is responsible for sampling a subgraph from given data. It</span>
<span class="sd">    returns an induced subgraph along with compacted information. In the</span>
<span class="sd">    context of a node classification task, the neighbor sampler directly</span>
<span class="sd">    utilizes the nodes provided as seed nodes. However, in scenarios involving</span>
<span class="sd">    link prediction, the process needs another pre-peocess operation. That is,</span>
<span class="sd">    gathering unique nodes from the given node pairs, encompassing both</span>
<span class="sd">    positive and negative node pairs, and employs these nodes as the seed nodes</span>
<span class="sd">    for subsequent steps. When the graph is hetero, sampled subgraphs in</span>
<span class="sd">    minibatch will contain every edge type even though it is empty after</span>
<span class="sd">    sampling.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    datapipe : DataPipe</span>
<span class="sd">        The datapipe.</span>
<span class="sd">    graph : FusedCSCSamplingGraph</span>
<span class="sd">        The graph on which to perform subgraph sampling.</span>
<span class="sd">    fanouts: list[torch.Tensor] or list[int]</span>
<span class="sd">        The number of edges to be sampled for each node with or without</span>
<span class="sd">        considering edge types. The length of this parameter implicitly</span>
<span class="sd">        signifies the layer of sampling being conducted.</span>
<span class="sd">        Note: The fanout order is from the outermost layer to innermost layer.</span>
<span class="sd">        For example, the fanout '[15, 10, 5]' means that 15 to the outermost</span>
<span class="sd">        layer, 10 to the intermediate layer and 5 corresponds to the innermost</span>
<span class="sd">        layer.</span>
<span class="sd">    replace: bool</span>
<span class="sd">        Boolean indicating whether the sample is preformed with or</span>
<span class="sd">        without replacement. If True, a value can be selected multiple</span>
<span class="sd">        times. Otherwise, each value can be selected only once.</span>
<span class="sd">    prob_name: str, optional</span>
<span class="sd">        The name of an edge attribute used as the weights of sampling for</span>
<span class="sd">        each node. This attribute tensor should contain (unnormalized)</span>
<span class="sd">        probabilities corresponding to each neighboring edge of a node.</span>
<span class="sd">        It must be a 1D floating-point or boolean tensor, with the number</span>
<span class="sd">        of elements equalling the total number of edges.</span>
<span class="sd">    deduplicate: bool</span>
<span class="sd">        Boolean indicating whether seeds between hops will be deduplicated.</span>
<span class="sd">        If True, the same elements in seeds will be deleted to only one.</span>
<span class="sd">        Otherwise, the same elements will be remained.</span>
<span class="sd">    overlap_fetch : bool, optional</span>
<span class="sd">        If True, the data loader will overlap the UVA graph fetching operations</span>
<span class="sd">        with the rest of operations by using an alternative CUDA stream. This</span>
<span class="sd">        option should be enabled if you have moved your graph to the pinned</span>
<span class="sd">        memory for optimal performance. Default is False.</span>
<span class="sd">    num_gpu_cached_edges : int, optional</span>
<span class="sd">        If positive and overlap_graph_fetch is True, then the GPU will cache</span>
<span class="sd">        frequently accessed vertex neighborhoods to reduce the PCI-e bandwidth</span>
<span class="sd">        demand due to pinned graph accesses.</span>
<span class="sd">    gpu_cache_threshold : int, optional</span>
<span class="sd">        Determines how many times a vertex needs to be accessed before its</span>
<span class="sd">        neighborhood ends up being cached on the GPU.</span>
<span class="sd">    cooperative: bool, optional</span>
<span class="sd">        Boolean indicating whether Cooperative Minibatching, which was initially</span>
<span class="sd">        proposed in</span>
<span class="sd">        `Deep Graph Library PR#4337&lt;https://github.com/dmlc/dgl/pull/4337&gt;`__</span>
<span class="sd">        and was later first fully described in</span>
<span class="sd">        `Cooperative Minibatching in Graph Neural Networks</span>
<span class="sd">        &lt;https://arxiv.org/abs/2310.12403&gt;`__. Cooperation between the GPUs</span>
<span class="sd">        eliminates duplicate work performed across the GPUs due to the</span>
<span class="sd">        overlapping sampled k-hop neighborhoods of seed nodes when performing</span>
<span class="sd">        GNN minibatching.</span>
<span class="sd">    asynchronous: bool</span>
<span class="sd">        Boolean indicating whether sampling and compaction stages should run</span>
<span class="sd">        in background threads to hide the latency of CPU GPU synchronization.</span>
<span class="sd">        Should be enabled only when sampling on the GPU.</span>

<span class="sd">    Examples</span>
<span class="sd">    -------</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; import dgl.graphbolt as gb</span>
<span class="sd">    &gt;&gt;&gt; indptr = torch.LongTensor([0, 2, 4, 5, 6, 7 ,8])</span>
<span class="sd">    &gt;&gt;&gt; indices = torch.LongTensor([1, 2, 0, 3, 5, 4, 3, 5])</span>
<span class="sd">    &gt;&gt;&gt; graph = gb.fused_csc_sampling_graph(indptr, indices)</span>
<span class="sd">    &gt;&gt;&gt; seeds = torch.LongTensor([[0, 1], [1, 2]])</span>
<span class="sd">    &gt;&gt;&gt; item_set = gb.ItemSet(seeds, names="seeds")</span>
<span class="sd">    &gt;&gt;&gt; datapipe = gb.ItemSampler(item_set, batch_size=1)</span>
<span class="sd">    &gt;&gt;&gt; datapipe = datapipe.sample_uniform_negative(graph, 2)</span>
<span class="sd">    &gt;&gt;&gt; datapipe = datapipe.sample_neighbor(graph, [5, 10, 15])</span>
<span class="sd">    &gt;&gt;&gt; next(iter(datapipe)).sampled_subgraphs</span>
<span class="sd">    [SampledSubgraphImpl(sampled_csc=CSCFormatBase(</span>
<span class="sd">            indptr=tensor([0, 2, 4, 5, 6, 7, 8]),</span>
<span class="sd">            indices=tensor([1, 4, 0, 5, 5, 3, 3, 2]),</span>
<span class="sd">        ),</span>
<span class="sd">        original_row_node_ids=tensor([0, 1, 4, 5, 2, 3]),</span>
<span class="sd">        original_edge_ids=None,</span>
<span class="sd">        original_column_node_ids=tensor([0, 1, 4, 5, 2, 3]),</span>
<span class="sd">    ),</span>
<span class="sd">    SampledSubgraphImpl(sampled_csc=CSCFormatBase(</span>
<span class="sd">            indptr=tensor([0, 2, 4, 5, 6, 7, 8]),</span>
<span class="sd">            indices=tensor([1, 4, 0, 5, 5, 3, 3, 2]),</span>
<span class="sd">        ),</span>
<span class="sd">        original_row_node_ids=tensor([0, 1, 4, 5, 2, 3]),</span>
<span class="sd">        original_edge_ids=None,</span>
<span class="sd">        original_column_node_ids=tensor([0, 1, 4, 5, 2, 3]),</span>
<span class="sd">    ),</span>
<span class="sd">    SampledSubgraphImpl(sampled_csc=CSCFormatBase(</span>
<span class="sd">            indptr=tensor([0, 2, 4, 5, 6]),</span>
<span class="sd">            indices=tensor([1, 4, 0, 5, 5, 3]),</span>
<span class="sd">        ),</span>
<span class="sd">        original_row_node_ids=tensor([0, 1, 4, 5, 2, 3]),</span>
<span class="sd">        original_edge_ids=None,</span>
<span class="sd">        original_column_node_ids=tensor([0, 1, 4, 5]),</span>
<span class="sd">    )]</span>
<span class="sd">    """</span>

    <span class="c1"># pylint: disable=useless-super-delegation</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">datapipe</span><span class="p">,</span>
        <span class="n">graph</span><span class="p">,</span>
        <span class="n">fanouts</span><span class="p">,</span>
        <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">prob_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">deduplicate</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">overlap_fetch</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">num_gpu_cached_edges</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">gpu_cache_threshold</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">cooperative</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">asynchronous</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">datapipe</span><span class="p">,</span>
            <span class="n">graph</span><span class="p">,</span>
            <span class="n">fanouts</span><span class="p">,</span>
            <span class="n">replace</span><span class="p">,</span>
            <span class="n">prob_name</span><span class="p">,</span>
            <span class="n">deduplicate</span><span class="p">,</span>
            <span class="n">graph</span><span class="o">.</span><span class="n">sample_neighbors</span><span class="p">,</span>
            <span class="n">overlap_fetch</span><span class="p">,</span>
            <span class="n">num_gpu_cached_edges</span><span class="p">,</span>
            <span class="n">gpu_cache_threshold</span><span class="p">,</span>
            <span class="n">cooperative</span><span class="p">,</span>
            <span class="n">asynchronous</span><span class="p">,</span>
        <span class="p">)</span></div>



<div class="viewcode-block" id="LayerNeighborSampler">
<a class="viewcode-back" href="../../../../generated/dgl.graphbolt.LayerNeighborSampler.html#dgl.graphbolt.LayerNeighborSampler">[docs]</a>
<span class="nd">@functional_datapipe</span><span class="p">(</span><span class="s2">"sample_layer_neighbor"</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">LayerNeighborSampler</span><span class="p">(</span><span class="n">NeighborSamplerImpl</span><span class="p">):</span>
    <span class="c1"># pylint: disable=abstract-method</span>
<span class="w">    </span><span class="sd">"""Sample layer neighbor edges from a graph and return a subgraph.</span>

<span class="sd">    Functional name: :obj:`sample_layer_neighbor`.</span>

<span class="sd">    Sampler that builds computational dependency of node representations via</span>
<span class="sd">    labor sampling for multilayer GNN from the NeurIPS 2023 paper</span>
<span class="sd">    `Layer-Neighbor Sampling -- Defusing Neighborhood Explosion in GNNs</span>
<span class="sd">    &lt;https://proceedings.neurips.cc/paper_files/paper/2023/file/51f9036d5e7ae822da8f6d4adda1fb39-Paper-Conference.pdf&gt;`__</span>

<span class="sd">    Layer-Neighbor sampler is responsible for sampling a subgraph from given</span>
<span class="sd">    data. It returns an induced subgraph along with compacted information. In</span>
<span class="sd">    the context of a node classification task, the neighbor sampler directly</span>
<span class="sd">    utilizes the nodes provided as seed nodes. However, in scenarios involving</span>
<span class="sd">    link prediction, the process needs another pre-process operation. That is,</span>
<span class="sd">    gathering unique nodes from the given node pairs, encompassing both</span>
<span class="sd">    positive and negative node pairs, and employs these nodes as the seed nodes</span>
<span class="sd">    for subsequent steps. When the graph is hetero, sampled subgraphs in</span>
<span class="sd">    minibatch will contain every edge type even though it is empty after</span>
<span class="sd">    sampling.</span>

<span class="sd">    Implements the approach described in Appendix A.3 of the paper. Similar to</span>
<span class="sd">    dgl.dataloading.LaborSampler but this uses sequential poisson sampling</span>
<span class="sd">    instead of poisson sampling to keep the count of sampled edges per vertex</span>
<span class="sd">    deterministic like NeighborSampler. Thus, it is a drop-in replacement for</span>
<span class="sd">    NeighborSampler. However, unlike NeighborSampler, it samples fewer vertices</span>
<span class="sd">    and edges for multilayer GNN scenario without harming convergence speed with</span>
<span class="sd">    respect to training iterations.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    datapipe : DataPipe</span>
<span class="sd">        The datapipe.</span>
<span class="sd">    graph : FusedCSCSamplingGraph</span>
<span class="sd">        The graph on which to perform subgraph sampling.</span>
<span class="sd">    fanouts: list[torch.Tensor]</span>
<span class="sd">        The number of edges to be sampled for each node with or without</span>
<span class="sd">        considering edge types. The length of this parameter implicitly</span>
<span class="sd">        signifies the layer of sampling being conducted.</span>
<span class="sd">    replace: bool</span>
<span class="sd">        Boolean indicating whether the sample is preformed with or</span>
<span class="sd">        without replacement. If True, a value can be selected multiple</span>
<span class="sd">        times. Otherwise, each value can be selected only once.</span>
<span class="sd">    prob_name: str, optional</span>
<span class="sd">        The name of an edge attribute used as the weights of sampling for</span>
<span class="sd">        each node. This attribute tensor should contain (unnormalized)</span>
<span class="sd">        probabilities corresponding to each neighboring edge of a node.</span>
<span class="sd">        It must be a 1D floating-point or boolean tensor, with the number</span>
<span class="sd">        of elements equalling the total number of edges.</span>
<span class="sd">    deduplicate: bool</span>
<span class="sd">        Boolean indicating whether seeds between hops will be deduplicated.</span>
<span class="sd">        If True, the same elements in seeds will be deleted to only one.</span>
<span class="sd">        Otherwise, the same elements will be remained.</span>
<span class="sd">    layer_dependency: bool</span>
<span class="sd">        Boolean indicating whether different layers should use the same random</span>
<span class="sd">        variates. Results in a reduction in the number of nodes sampled and</span>
<span class="sd">        turns LayerNeighborSampler into a subgraph sampling method. Later layers</span>
<span class="sd">        will be guaranteed to sample overlapping neighbors as the previous</span>
<span class="sd">        layers.</span>
<span class="sd">    batch_dependency: int</span>
<span class="sd">        Specifies whether consecutive minibatches should use similar random</span>
<span class="sd">        variates. Results in a higher temporal access locality of sampled</span>
<span class="sd">        nodes and edges. Setting it to :math:`\\kappa` slows down the change in</span>
<span class="sd">        the random variates proportional to :math:`\\frac{1}{\\kappa}`. Implements</span>
<span class="sd">        the dependent minibatching approach in `arXiv:2310.12403</span>
<span class="sd">        &lt;https://arxiv.org/abs/2310.12403&gt;`__.</span>
<span class="sd">    overlap_fetch : bool, optional</span>
<span class="sd">        If True, the data loader will overlap the UVA graph fetching operations</span>
<span class="sd">        with the rest of operations by using an alternative CUDA stream. This</span>
<span class="sd">        option should be enabled if you have moved your graph to the pinned</span>
<span class="sd">        memory for optimal performance. Default is False.</span>
<span class="sd">    num_gpu_cached_edges : int, optional</span>
<span class="sd">        If positive and overlap_graph_fetch is True, then the GPU will cache</span>
<span class="sd">        frequently accessed vertex neighborhoods to reduce the PCI-e bandwidth</span>
<span class="sd">        demand due to pinned graph accesses.</span>
<span class="sd">    gpu_cache_threshold : int, optional</span>
<span class="sd">        Determines how many times a vertex needs to be accessed before its</span>
<span class="sd">        neighborhood ends up being cached on the GPU.</span>
<span class="sd">    cooperative: bool, optional</span>
<span class="sd">        Boolean indicating whether Cooperative Minibatching, which was initially</span>
<span class="sd">        proposed in</span>
<span class="sd">        `Deep Graph Library PR#4337&lt;https://github.com/dmlc/dgl/pull/4337&gt;`__</span>
<span class="sd">        and was later first fully described in</span>
<span class="sd">        `Cooperative Minibatching in Graph Neural Networks</span>
<span class="sd">        &lt;https://arxiv.org/abs/2310.12403&gt;`__. Cooperation between the GPUs</span>
<span class="sd">        eliminates duplicate work performed across the GPUs due to the</span>
<span class="sd">        overlapping sampled k-hop neighborhoods of seed nodes when performing</span>
<span class="sd">        GNN minibatching.</span>
<span class="sd">    asynchronous: bool</span>
<span class="sd">        Boolean indicating whether sampling and compaction stages should run</span>
<span class="sd">        in background threads to hide the latency of CPU GPU synchronization.</span>
<span class="sd">        Should be enabled only when sampling on the GPU.</span>

<span class="sd">    Examples</span>
<span class="sd">    -------</span>
<span class="sd">    &gt;&gt;&gt; import dgl.graphbolt as gb</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; indptr = torch.LongTensor([0, 2, 4, 5, 6, 7 ,8])</span>
<span class="sd">    &gt;&gt;&gt; indices = torch.LongTensor([1, 2, 0, 3, 5, 4, 3, 5])</span>
<span class="sd">    &gt;&gt;&gt; graph = gb.fused_csc_sampling_graph(indptr, indices)</span>
<span class="sd">    &gt;&gt;&gt; seeds = torch.LongTensor([[0, 1], [1, 2]])</span>
<span class="sd">    &gt;&gt;&gt; item_set = gb.ItemSet(seeds, names="seeds")</span>
<span class="sd">    &gt;&gt;&gt; item_sampler = gb.ItemSampler(item_set, batch_size=1,)</span>
<span class="sd">    &gt;&gt;&gt; neg_sampler = gb.UniformNegativeSampler(item_sampler, graph, 2)</span>
<span class="sd">    &gt;&gt;&gt; fanouts = [torch.LongTensor([5]),</span>
<span class="sd">    ...     torch.LongTensor([10]),torch.LongTensor([15])]</span>
<span class="sd">    &gt;&gt;&gt; subgraph_sampler = gb.LayerNeighborSampler(neg_sampler, graph, fanouts)</span>
<span class="sd">    &gt;&gt;&gt; next(iter(subgraph_sampler)).sampled_subgraphs</span>
<span class="sd">    [SampledSubgraphImpl(sampled_csc=CSCFormatBase(</span>
<span class="sd">            indptr=tensor([0, 2, 4, 5, 6, 7, 8]),</span>
<span class="sd">            indices=tensor([1, 3, 0, 4, 2, 2, 5, 4]),</span>
<span class="sd">        ),</span>
<span class="sd">        original_row_node_ids=tensor([0, 1, 5, 2, 3, 4]),</span>
<span class="sd">        original_edge_ids=None,</span>
<span class="sd">        original_column_node_ids=tensor([0, 1, 5, 2, 3, 4]),</span>
<span class="sd">    ),</span>
<span class="sd">    SampledSubgraphImpl(sampled_csc=CSCFormatBase(</span>
<span class="sd">            indptr=tensor([0, 2, 4, 5, 6, 7]),</span>
<span class="sd">            indices=tensor([1, 3, 0, 4, 2, 2, 5]),</span>
<span class="sd">        ),</span>
<span class="sd">        original_row_node_ids=tensor([0, 1, 5, 2, 3, 4]),</span>
<span class="sd">        original_edge_ids=None,</span>
<span class="sd">        original_column_node_ids=tensor([0, 1, 5, 2, 3]),</span>
<span class="sd">    ),</span>
<span class="sd">    SampledSubgraphImpl(sampled_csc=CSCFormatBase(</span>
<span class="sd">            indptr=tensor([0, 2, 4, 5, 6]),</span>
<span class="sd">            indices=tensor([1, 3, 0, 4, 2, 2]),</span>
<span class="sd">        ),</span>
<span class="sd">        original_row_node_ids=tensor([0, 1, 5, 2, 3]),</span>
<span class="sd">        original_edge_ids=None,</span>
<span class="sd">        original_column_node_ids=tensor([0, 1, 5, 2]),</span>
<span class="sd">    )]</span>
<span class="sd">    &gt;&gt;&gt; next(iter(subgraph_sampler)).compacted_seeds</span>
<span class="sd">    tensor([[0, 1], [0, 2], [0, 3]])</span>
<span class="sd">    &gt;&gt;&gt; next(iter(subgraph_sampler)).labels</span>
<span class="sd">    tensor([1., 0., 0.])</span>
<span class="sd">    &gt;&gt;&gt; next(iter(subgraph_sampler)).indexes</span>
<span class="sd">    tensor([0, 0, 0])</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">datapipe</span><span class="p">,</span>
        <span class="n">graph</span><span class="p">,</span>
        <span class="n">fanouts</span><span class="p">,</span>
        <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">prob_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">deduplicate</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">layer_dependency</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">batch_dependency</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">overlap_fetch</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">num_gpu_cached_edges</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">gpu_cache_threshold</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">cooperative</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">asynchronous</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">datapipe</span><span class="p">,</span>
            <span class="n">graph</span><span class="p">,</span>
            <span class="n">fanouts</span><span class="p">,</span>
            <span class="n">replace</span><span class="p">,</span>
            <span class="n">prob_name</span><span class="p">,</span>
            <span class="n">deduplicate</span><span class="p">,</span>
            <span class="n">graph</span><span class="o">.</span><span class="n">sample_layer_neighbors</span><span class="p">,</span>
            <span class="n">overlap_fetch</span><span class="p">,</span>
            <span class="n">num_gpu_cached_edges</span><span class="p">,</span>
            <span class="n">gpu_cache_threshold</span><span class="p">,</span>
            <span class="n">cooperative</span><span class="p">,</span>
            <span class="n">asynchronous</span><span class="p">,</span>
            <span class="n">layer_dependency</span><span class="p">,</span>
            <span class="n">batch_dependency</span><span class="p">,</span>
        <span class="p">)</span></div>

</pre></div>
</div>
</div>
<footer>
<hr/>
<div role="contentinfo">
<p>© Copyright 2018, DGL Team.</p>
</div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
</div>
</div>
</section>
</div>
<div aria-label="Versions" class="rst-versions" data-toggle="rst-versions" role="note">
<span class="rst-current-version" data-toggle="rst-current-version">
<span class="fa fa-book"> Read the Docs</span>
<span id="version-placeholder">v: latest</span>
<span class="fa fa-caret-down"></span>
</span>
<div class="rst-other-versions">
<dl>
<dt>Versions</dt>
<div id="version-list">
</div>
</dl>
<dl>
<dt>Downloads</dt>
</dl>
<dl>
<dt>On Read the Docs</dt>
<dd><a href="//doc-build.dgl.ai/projects/dgl/?fromdocs=dgl">Project Home</a></dd>
<dd><a href="//doc-build.dgl.ai/builds/dgl/?fromdocs=dgl">Builds</a></dd>
</dl>
</div>
</div>
<script>
    document.addEventListener("DOMContentLoaded", function() {
        fetch('/dgl_docs/branches.json')
            .then(response => response.json())
            .then(data => {
                var versionListDiv = document.getElementById('version-list');
                data.branches.forEach(function(branch) {
                    var dd = document.createElement('dd');
                    var a = document.createElement('a');
                    a.href = branch.url;
                    a.textContent = branch.name;
                    dd.appendChild(a);
                    versionListDiv.appendChild(dd);
                });
            })
            .catch(error => console.error('Error loading branches:', error));
    });
    document.addEventListener("DOMContentLoaded", function() {
        // 获取当前路径
        var path = window.location.pathname;
        var versionPlaceholder = document.getElementById('version-placeholder');

        
        if (path.includes('/en/')) {
            
            var parts = path.split('/en/');
            if (parts[1]) {
                var folders = parts[1].split('/');
                if (folders.length > 0 && folders[0]) {
                    versionPlaceholder.textContent = 'v: ' + folders[0];
                } else {
                    versionPlaceholder.textContent = 'v: latest';
                }
            } else {
                versionPlaceholder.textContent = 'v: latest';
            }
        } else {
            versionPlaceholder.textContent = 'v: latest';
        }
    });
</script>

<script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
</body>
</html>