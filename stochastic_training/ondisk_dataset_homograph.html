<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>OnDiskDataset for Homogeneous Graph &mdash; DGL 2.4 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../_static/graphviz.css?v=fd3f3429" />
      <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=61a4c737" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
      <link rel="stylesheet" type="text/css" href="../_static/nbsphinx-code-cells.css" />
      <link rel="stylesheet" type="text/css" href="../_static/css/custom.css?v=0bf289b5" />

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../_static/documentation_options.js?v=9caaf7ed"></script>
        <script src="../_static/doctools.js?v=9a2dae69"></script>
        <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
        <script src="../_static/copybutton.js?v=ccdb6887"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="OnDiskDataset for Heterogeneous Graph" href="ondisk_dataset_heterograph.html" />
    <link rel="prev" title="Composing OnDiskDataset from raw data" href="ondisk-dataset.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            DGL
          </a>
              <div class="version">
                2.4
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../install/index.html">Install and Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/blitz/index.html">A Blitz Introduction to DGL</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Materials</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">🆕 Stochastic Training of GNNs with GraphBolt</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="neighbor_sampling_overview.html">Neighbor Sampling Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="node_classification.html">Node Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="link_prediction.html">Link Prediction</a></li>
<li class="toctree-l2"><a class="reference internal" href="multigpu_node_classification.html">Multi-GPU Node Classification</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="ondisk-dataset.html">Composing OnDiskDataset from raw data</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">OnDiskDataset for Homogeneous Graph</a></li>
<li class="toctree-l3"><a class="reference internal" href="ondisk_dataset_heterograph.html">OnDiskDataset for Heterogeneous Graph</a></li>
<li class="toctree-l3"><a class="reference internal" href="ondisk-dataset-specification.html">YAML specification</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../guide/index.html">User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guide_cn/index.html">用户指南【包含过时信息】</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guide_ko/index.html">사용자 가이드[시대에 뒤쳐진]</a></li>
<li class="toctree-l1"><a class="reference internal" href="../graphtransformer/index.html">🆕 Tutorial: Graph Transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebooks/sparse/index.html">Tutorials: dgl.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/cpu/index.html">Training on CPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/multi/index.html">Training on Multiple GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/dist/index.html">Distributed training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/models/index.html">Paper Study with DGL</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.html">dgl</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.data.html">dgl.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.dataloading.html">dgl.dataloading</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.DGLGraph.html">dgl.DGLGraph</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.distributed.html">dgl.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.function.html">dgl.function</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.geometry.html">dgl.geometry</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.graphbolt.html">🆕 dgl.graphbolt</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/nn-pytorch.html">dgl.nn (PyTorch)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/nn.functional.html">dgl.nn.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.ops.html">dgl.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.optim.html">dgl.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.sampling.html">dgl.sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.sparse_v0.html">dgl.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.multiprocessing.html">dgl.multiprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/transforms.html">dgl.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/udf.html">User-defined Functions</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../contribute.html">Contribute to DGL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../developer/ffi.html">DGL Foreign Function Interface (FFI)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../performance.html">Performance Benchmarks</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Misc</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">Frequently Asked Questions (FAQ)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../env_var.html">Environment Variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="../resources.html">Resources</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">DGL</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">🆕 Stochastic Training of GNNs with GraphBolt</a></li>
          <li class="breadcrumb-item"><a href="ondisk-dataset.html">Composing OnDiskDataset from raw data</a></li>
      <li class="breadcrumb-item active">OnDiskDataset for Homogeneous Graph</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/stochastic_training/ondisk_dataset_homograph.nblink.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="OnDiskDataset-for-Homogeneous-Graph">
<h1>OnDiskDataset for Homogeneous Graph<a class="headerlink" href="#OnDiskDataset-for-Homogeneous-Graph" title="Link to this heading"></a></h1>
<p><a class="reference external" href="https://colab.research.google.com/github/dmlc/dgl/blob/master/notebooks/stochastic_training/ondisk_dataset_homograph.ipynb"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a> <a class="reference external" href="https://github.com/dmlc/dgl/blob/master/notebooks/stochastic_training/ondisk_dataset_homograph.ipynb"><img alt="GitHub" src="https://img.shields.io/badge/-View%20on%20GitHub-181717?logo=github&amp;logoColor=ffffff" /></a></p>
<p>This tutorial shows how to create <code class="docutils literal notranslate"><span class="pre">OnDiskDataset</span></code> for homogeneous graph that could be used in <strong>GraphBolt</strong> framework.</p>
<p>By the end of this tutorial, you will be able to</p>
<ul class="simple">
<li><p>organize graph structure data.</p></li>
<li><p>organize feature data.</p></li>
<li><p>organize training/validation/test set for specific tasks.</p></li>
</ul>
<p>To create an <code class="docutils literal notranslate"><span class="pre">OnDiskDataset</span></code> object, you need to organize all the data including graph structure, feature data and tasks into a directory. The directory should contain a <code class="docutils literal notranslate"><span class="pre">metadata.yaml</span></code> file that describes the metadata of the dataset.</p>
<p>Now let’s generate various data step by step and organize them together to instantiate <code class="docutils literal notranslate"><span class="pre">OnDiskDataset</span></code> finally.</p>
<section id="Install-DGL-package">
<h2>Install DGL package<a class="headerlink" href="#Install-DGL-package" title="Link to this heading"></a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Install required packages.</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;TORCH&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">__version__</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;DGLBACKEND&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;pytorch&quot;</span>

<span class="c1"># Install the CPU version.</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>--pre<span class="w"> </span>dgl<span class="w"> </span>-f<span class="w"> </span>https://data.dgl.ai/wheels-test/repo.html

<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">dgl</span>
    <span class="kn">import</span> <span class="nn">dgl.graphbolt</span> <span class="k">as</span> <span class="nn">gb</span>
    <span class="n">installed</span> <span class="o">=</span> <span class="kc">True</span>
<span class="k">except</span> <span class="ne">ImportError</span> <span class="k">as</span> <span class="n">error</span><span class="p">:</span>
    <span class="n">installed</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">error</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;DGL installed!&quot;</span> <span class="k">if</span> <span class="n">installed</span> <span class="k">else</span> <span class="s2">&quot;DGL not found!&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Looking in links: https://data.dgl.ai/wheels-test/repo.html
Requirement already satisfied: dgl in /opt/conda/envs/gpu/lib/python3.10/site-packages (2.2a240410)
Requirement already satisfied: numpy&gt;=1.14.0 in /opt/conda/envs/gpu/lib/python3.10/site-packages (from dgl) (1.26.4)
Requirement already satisfied: scipy&gt;=1.1.0 in /opt/conda/envs/gpu/lib/python3.10/site-packages (from dgl) (1.13.0)
Requirement already satisfied: networkx&gt;=2.1 in /opt/conda/envs/gpu/lib/python3.10/site-packages (from dgl) (3.3)
Requirement already satisfied: requests&gt;=2.19.0 in /opt/conda/envs/gpu/lib/python3.10/site-packages (from dgl) (2.31.0)
Requirement already satisfied: tqdm in /opt/conda/envs/gpu/lib/python3.10/site-packages (from dgl) (4.66.2)
Requirement already satisfied: psutil&gt;=5.8.0 in /opt/conda/envs/gpu/lib/python3.10/site-packages (from dgl) (5.9.8)
Requirement already satisfied: torchdata&gt;=0.5.0 in /opt/conda/envs/gpu/lib/python3.10/site-packages (from dgl) (0.7.1)
Requirement already satisfied: pandas in /opt/conda/envs/gpu/lib/python3.10/site-packages (from dgl) (2.2.2)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Requirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /opt/conda/envs/gpu/lib/python3.10/site-packages (from requests&gt;=2.19.0-&gt;dgl) (3.3.2)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /opt/conda/envs/gpu/lib/python3.10/site-packages (from requests&gt;=2.19.0-&gt;dgl) (3.7)
Requirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /opt/conda/envs/gpu/lib/python3.10/site-packages (from requests&gt;=2.19.0-&gt;dgl) (2.2.1)
Requirement already satisfied: certifi&gt;=2017.4.17 in /opt/conda/envs/gpu/lib/python3.10/site-packages (from requests&gt;=2.19.0-&gt;dgl) (2024.2.2)
Requirement already satisfied: torch&gt;=2 in /opt/conda/envs/gpu/lib/python3.10/site-packages (from torchdata&gt;=0.5.0-&gt;dgl) (2.2.1+cu121)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Requirement already satisfied: python-dateutil&gt;=2.8.2 in /opt/conda/envs/gpu/lib/python3.10/site-packages (from pandas-&gt;dgl) (2.9.0.post0)
Requirement already satisfied: pytz&gt;=2020.1 in /opt/conda/envs/gpu/lib/python3.10/site-packages (from pandas-&gt;dgl) (2024.1)
Requirement already satisfied: tzdata&gt;=2022.7 in /opt/conda/envs/gpu/lib/python3.10/site-packages (from pandas-&gt;dgl) (2024.1)
Requirement already satisfied: six&gt;=1.5 in /opt/conda/envs/gpu/lib/python3.10/site-packages (from python-dateutil&gt;=2.8.2-&gt;pandas-&gt;dgl) (1.16.0)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Requirement already satisfied: filelock in /opt/conda/envs/gpu/lib/python3.10/site-packages (from torch&gt;=2-&gt;torchdata&gt;=0.5.0-&gt;dgl) (3.13.4)
Requirement already satisfied: typing-extensions&gt;=4.8.0 in /opt/conda/envs/gpu/lib/python3.10/site-packages (from torch&gt;=2-&gt;torchdata&gt;=0.5.0-&gt;dgl) (4.11.0)
Requirement already satisfied: sympy in /opt/conda/envs/gpu/lib/python3.10/site-packages (from torch&gt;=2-&gt;torchdata&gt;=0.5.0-&gt;dgl) (1.12)
Requirement already satisfied: jinja2 in /opt/conda/envs/gpu/lib/python3.10/site-packages (from torch&gt;=2-&gt;torchdata&gt;=0.5.0-&gt;dgl) (3.1.3)
Requirement already satisfied: fsspec in /opt/conda/envs/gpu/lib/python3.10/site-packages (from torch&gt;=2-&gt;torchdata&gt;=0.5.0-&gt;dgl) (2024.3.1)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/envs/gpu/lib/python3.10/site-packages (from torch&gt;=2-&gt;torchdata&gt;=0.5.0-&gt;dgl) (12.1.105)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/envs/gpu/lib/python3.10/site-packages (from torch&gt;=2-&gt;torchdata&gt;=0.5.0-&gt;dgl) (12.1.105)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/envs/gpu/lib/python3.10/site-packages (from torch&gt;=2-&gt;torchdata&gt;=0.5.0-&gt;dgl) (12.1.105)
Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/envs/gpu/lib/python3.10/site-packages (from torch&gt;=2-&gt;torchdata&gt;=0.5.0-&gt;dgl) (8.9.2.26)
Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/envs/gpu/lib/python3.10/site-packages (from torch&gt;=2-&gt;torchdata&gt;=0.5.0-&gt;dgl) (12.1.3.1)
Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/envs/gpu/lib/python3.10/site-packages (from torch&gt;=2-&gt;torchdata&gt;=0.5.0-&gt;dgl) (11.0.2.54)
Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/envs/gpu/lib/python3.10/site-packages (from torch&gt;=2-&gt;torchdata&gt;=0.5.0-&gt;dgl) (10.3.2.106)
Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/envs/gpu/lib/python3.10/site-packages (from torch&gt;=2-&gt;torchdata&gt;=0.5.0-&gt;dgl) (11.4.5.107)
Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/envs/gpu/lib/python3.10/site-packages (from torch&gt;=2-&gt;torchdata&gt;=0.5.0-&gt;dgl) (12.1.0.106)
Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /opt/conda/envs/gpu/lib/python3.10/site-packages (from torch&gt;=2-&gt;torchdata&gt;=0.5.0-&gt;dgl) (2.19.3)
Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/envs/gpu/lib/python3.10/site-packages (from torch&gt;=2-&gt;torchdata&gt;=0.5.0-&gt;dgl) (12.1.105)
Requirement already satisfied: triton==2.2.0 in /opt/conda/envs/gpu/lib/python3.10/site-packages (from torch&gt;=2-&gt;torchdata&gt;=0.5.0-&gt;dgl) (2.2.0)
Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/envs/gpu/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107-&gt;torch&gt;=2-&gt;torchdata&gt;=0.5.0-&gt;dgl) (12.4.127)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Requirement already satisfied: MarkupSafe&gt;=2.0 in /opt/conda/envs/gpu/lib/python3.10/site-packages (from jinja2-&gt;torch&gt;=2-&gt;torchdata&gt;=0.5.0-&gt;dgl) (2.1.5)
Requirement already satisfied: mpmath&gt;=0.19 in /opt/conda/envs/gpu/lib/python3.10/site-packages (from sympy-&gt;torch&gt;=2-&gt;torchdata&gt;=0.5.0-&gt;dgl) (1.3.0)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
DGL installed!
</pre></div></div>
</div>
</section>
<section id="Data-preparation">
<h2>Data preparation<a class="headerlink" href="#Data-preparation" title="Link to this heading"></a></h2>
<p>In order to demonstrate how to organize various data, let’s create a base directory first.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">base_dir</span> <span class="o">=</span> <span class="s1">&#39;./ondisk_dataset_homograph&#39;</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Created base directory: </span><span class="si">{</span><span class="n">base_dir</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Created base directory: ./ondisk_dataset_homograph
</pre></div></div>
</div>
<section id="Generate-graph-structure-data">
<h3>Generate graph structure data<a class="headerlink" href="#Generate-graph-structure-data" title="Link to this heading"></a></h3>
<p>For homogeneous graph, we just need to save edges(namely seeds) into <strong>Numpy</strong> or <strong>CSV</strong> file.</p>
<p>Note: - when saving to <strong>Numpy</strong>, the array requires to be in shape of <code class="docutils literal notranslate"><span class="pre">(2,</span> <span class="pre">N)</span></code>. This format is recommended as constructing graph from it is much faster than <strong>CSV</strong> file. - when saving to <strong>CSV</strong> file, do not save index and header.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">num_nodes</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">num_edges</span> <span class="o">=</span> <span class="mi">10</span> <span class="o">*</span> <span class="n">num_nodes</span>
<span class="n">edges_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s2">&quot;edges.csv&quot;</span><span class="p">)</span>
<span class="n">edges</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_nodes</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">num_edges</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Part of edges: </span><span class="si">{</span><span class="n">edges</span><span class="p">[:</span><span class="mi">5</span><span class="p">,</span><span class="w"> </span><span class="p">:]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">edges</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">edges_path</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Edges are saved into </span><span class="si">{</span><span class="n">edges_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Part of edges: [[333  51]
 [627 314]
 [974 960]
 [608 210]
 [947 500]]
Edges are saved into ./ondisk_dataset_homograph/edges.csv
</pre></div></div>
</div>
</section>
<section id="Generate-feature-data-for-graph">
<h3>Generate feature data for graph<a class="headerlink" href="#Generate-feature-data-for-graph" title="Link to this heading"></a></h3>
<p>For feature data, numpy arrays and torch tensors are supported for now.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generate node feature in numpy array.</span>
<span class="n">node_feat_0_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s2">&quot;node-feat-0.npy&quot;</span><span class="p">)</span>
<span class="n">node_feat_0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">num_nodes</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Part of node feature [feat_0]: </span><span class="si">{</span><span class="n">node_feat_0</span><span class="p">[:</span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="p">:]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">node_feat_0_path</span><span class="p">,</span> <span class="n">node_feat_0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Node feature [feat_0] is saved to </span><span class="si">{</span><span class="n">node_feat_0_path</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Generate another node feature in torch tensor</span>
<span class="n">node_feat_1_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s2">&quot;node-feat-1.pt&quot;</span><span class="p">)</span>
<span class="n">node_feat_1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">num_nodes</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Part of node feature [feat_1]: </span><span class="si">{</span><span class="n">node_feat_1</span><span class="p">[:</span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="p">:]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">node_feat_1</span><span class="p">,</span> <span class="n">node_feat_1_path</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Node feature [feat_1] is saved to </span><span class="si">{</span><span class="n">node_feat_1_path</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Generate edge feature in numpy array.</span>
<span class="n">edge_feat_0_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s2">&quot;edge-feat-0.npy&quot;</span><span class="p">)</span>
<span class="n">edge_feat_0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">num_edges</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Part of edge feature [feat_0]: </span><span class="si">{</span><span class="n">edge_feat_0</span><span class="p">[:</span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="p">:]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">edge_feat_0_path</span><span class="p">,</span> <span class="n">edge_feat_0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Edge feature [feat_0] is saved to </span><span class="si">{</span><span class="n">edge_feat_0_path</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Generate another edge feature in torch tensor</span>
<span class="n">edge_feat_1_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s2">&quot;edge-feat-1.pt&quot;</span><span class="p">)</span>
<span class="n">edge_feat_1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">num_edges</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Part of edge feature [feat_1]: </span><span class="si">{</span><span class="n">edge_feat_1</span><span class="p">[:</span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="p">:]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">edge_feat_1</span><span class="p">,</span> <span class="n">edge_feat_1_path</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Edge feature [feat_1] is saved to </span><span class="si">{</span><span class="n">edge_feat_1_path</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<br/></pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Part of node feature [feat_0]: [[0.55638816 0.29640347 0.01168646 0.94500187 0.1200923 ]
 [0.637482   0.68527676 0.91091426 0.93816437 0.57928967]
 [0.22366348 0.74724981 0.9216977  0.92080438 0.42393485]]
Node feature [feat_0] is saved to ./ondisk_dataset_homograph/node-feat-0.npy

Part of node feature [feat_1]: tensor([[0.8693, 0.1440, 0.3363, 0.5206, 0.0912],
        [0.2734, 0.3872, 0.1187, 0.8336, 0.4087],
        [0.1987, 0.6960, 0.9002, 0.5608, 0.2093]])
Node feature [feat_1] is saved to ./ondisk_dataset_homograph/node-feat-1.pt

Part of edge feature [feat_0]: [[0.91149488 0.69920594 0.81593141 0.40117401 0.4010922 ]
 [0.77548271 0.3070736  0.03289692 0.76516515 0.77282356]
 [0.26872647 0.946464   0.72184271 0.17865494 0.37244025]]
Edge feature [feat_0] is saved to ./ondisk_dataset_homograph/edge-feat-0.npy

Part of edge feature [feat_1]: tensor([[0.8857, 0.8096, 0.5453, 0.9915, 0.7684],
        [0.9626, 0.2615, 0.6159, 0.7570, 0.1749],
        [0.4404, 0.3759, 0.3843, 0.5937, 0.6090]])
Edge feature [feat_1] is saved to ./ondisk_dataset_homograph/edge-feat-1.pt

</pre></div></div>
</div>
</section>
<section id="Generate-tasks">
<h3>Generate tasks<a class="headerlink" href="#Generate-tasks" title="Link to this heading"></a></h3>
<p><code class="docutils literal notranslate"><span class="pre">OnDiskDataset</span></code> supports multiple tasks. For each task, we need to prepare training/validation/test sets respectively. Such sets usually vary among different tasks. In this tutorial, let’s create a <strong>Node Classification</strong> task and <strong>Link Prediction</strong> task.</p>
<section id="Node-Classification-Task">
<h4>Node Classification Task<a class="headerlink" href="#Node-Classification-Task" title="Link to this heading"></a></h4>
<p>For node classification task, we need <strong>node IDs</strong> and corresponding <strong>labels</strong> for each training/validation/test set. Like feature data, numpy arrays and torch tensors are supported for these sets.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num_trains</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">num_nodes</span> <span class="o">*</span> <span class="mf">0.6</span><span class="p">)</span>
<span class="n">num_vals</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">num_nodes</span> <span class="o">*</span> <span class="mf">0.2</span><span class="p">)</span>
<span class="n">num_tests</span> <span class="o">=</span> <span class="n">num_nodes</span> <span class="o">-</span> <span class="n">num_trains</span> <span class="o">-</span> <span class="n">num_vals</span>

<span class="n">ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">num_nodes</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">ids</span><span class="p">)</span>

<span class="n">nc_train_ids_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s2">&quot;nc-train-ids.npy&quot;</span><span class="p">)</span>
<span class="n">nc_train_ids</span> <span class="o">=</span> <span class="n">ids</span><span class="p">[:</span><span class="n">num_trains</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Part of train ids for node classification: </span><span class="si">{</span><span class="n">nc_train_ids</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">nc_train_ids_path</span><span class="p">,</span> <span class="n">nc_train_ids</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;NC train ids are saved to </span><span class="si">{</span><span class="n">nc_train_ids_path</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">nc_train_labels_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s2">&quot;nc-train-labels.pt&quot;</span><span class="p">)</span>
<span class="n">nc_train_labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="p">(</span><span class="n">num_trains</span><span class="p">,))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Part of train labels for node classification: </span><span class="si">{</span><span class="n">nc_train_labels</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">nc_train_labels</span><span class="p">,</span> <span class="n">nc_train_labels_path</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;NC train labels are saved to </span><span class="si">{</span><span class="n">nc_train_labels_path</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">nc_val_ids_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s2">&quot;nc-val-ids.npy&quot;</span><span class="p">)</span>
<span class="n">nc_val_ids</span> <span class="o">=</span> <span class="n">ids</span><span class="p">[</span><span class="n">num_trains</span><span class="p">:</span><span class="n">num_trains</span><span class="o">+</span><span class="n">num_vals</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Part of val ids for node classification: </span><span class="si">{</span><span class="n">nc_val_ids</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">nc_val_ids_path</span><span class="p">,</span> <span class="n">nc_val_ids</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;NC val ids are saved to </span><span class="si">{</span><span class="n">nc_val_ids_path</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">nc_val_labels_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s2">&quot;nc-val-labels.pt&quot;</span><span class="p">)</span>
<span class="n">nc_val_labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="p">(</span><span class="n">num_vals</span><span class="p">,))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Part of val labels for node classification: </span><span class="si">{</span><span class="n">nc_val_labels</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">nc_val_labels</span><span class="p">,</span> <span class="n">nc_val_labels_path</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;NC val labels are saved to </span><span class="si">{</span><span class="n">nc_val_labels_path</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">nc_test_ids_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s2">&quot;nc-test-ids.npy&quot;</span><span class="p">)</span>
<span class="n">nc_test_ids</span> <span class="o">=</span> <span class="n">ids</span><span class="p">[</span><span class="o">-</span><span class="n">num_tests</span><span class="p">:]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Part of test ids for node classification: </span><span class="si">{</span><span class="n">nc_test_ids</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">nc_test_ids_path</span><span class="p">,</span> <span class="n">nc_test_ids</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;NC test ids are saved to </span><span class="si">{</span><span class="n">nc_test_ids_path</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">nc_test_labels_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s2">&quot;nc-test-labels.pt&quot;</span><span class="p">)</span>
<span class="n">nc_test_labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="p">(</span><span class="n">num_tests</span><span class="p">,))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Part of test labels for node classification: </span><span class="si">{</span><span class="n">nc_test_labels</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">nc_test_labels</span><span class="p">,</span> <span class="n">nc_test_labels_path</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;NC test labels are saved to </span><span class="si">{</span><span class="n">nc_test_labels_path</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Part of train ids for node classification: [287 336 252]
NC train ids are saved to ./ondisk_dataset_homograph/nc-train-ids.npy

Part of train labels for node classification: tensor([1, 7, 2])
NC train labels are saved to ./ondisk_dataset_homograph/nc-train-labels.pt

Part of val ids for node classification: [ 99 246 400]
NC val ids are saved to ./ondisk_dataset_homograph/nc-val-ids.npy

Part of val labels for node classification: tensor([3, 4, 1])
NC val labels are saved to ./ondisk_dataset_homograph/nc-val-labels.pt

Part of test ids for node classification: [607  96 875]
NC test ids are saved to ./ondisk_dataset_homograph/nc-test-ids.npy

Part of test labels for node classification: tensor([8, 9, 0])
NC test labels are saved to ./ondisk_dataset_homograph/nc-test-labels.pt

</pre></div></div>
</div>
</section>
<section id="Link-Prediction-Task">
<h4>Link Prediction Task<a class="headerlink" href="#Link-Prediction-Task" title="Link to this heading"></a></h4>
<p>For link prediction task, we need <strong>seeds</strong> or <strong>corresponding labels and indexes</strong> which representing the pos/neg property and group of the seeds for each training/validation/test set. Like feature data, numpy arrays and torch tensors are supported for these sets.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num_trains</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">num_edges</span> <span class="o">*</span> <span class="mf">0.6</span><span class="p">)</span>
<span class="n">num_vals</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">num_edges</span> <span class="o">*</span> <span class="mf">0.2</span><span class="p">)</span>
<span class="n">num_tests</span> <span class="o">=</span> <span class="n">num_edges</span> <span class="o">-</span> <span class="n">num_trains</span> <span class="o">-</span> <span class="n">num_vals</span>

<span class="n">lp_train_seeds_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s2">&quot;lp-train-seeds.npy&quot;</span><span class="p">)</span>
<span class="n">lp_train_seeds</span> <span class="o">=</span> <span class="n">edges</span><span class="p">[:</span><span class="n">num_trains</span><span class="p">,</span> <span class="p">:]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Part of train seeds for link prediction: </span><span class="si">{</span><span class="n">lp_train_seeds</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">lp_train_seeds_path</span><span class="p">,</span> <span class="n">lp_train_seeds</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;LP train seeds are saved to </span><span class="si">{</span><span class="n">lp_train_seeds_path</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">lp_val_seeds_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s2">&quot;lp-val-seeds.npy&quot;</span><span class="p">)</span>
<span class="n">lp_val_seeds</span> <span class="o">=</span> <span class="n">edges</span><span class="p">[</span><span class="n">num_trains</span><span class="p">:</span><span class="n">num_trains</span><span class="o">+</span><span class="n">num_vals</span><span class="p">,</span> <span class="p">:]</span>
<span class="n">lp_val_neg_dsts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_nodes</span><span class="p">,</span> <span class="p">(</span><span class="n">num_vals</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">lp_val_neg_srcs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">lp_val_seeds</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">lp_val_neg_seeds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">lp_val_neg_srcs</span><span class="p">,</span> <span class="n">lp_val_neg_dsts</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
<span class="n">lp_val_seeds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">lp_val_seeds</span><span class="p">,</span> <span class="n">lp_val_neg_seeds</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Part of val seeds for link prediction: </span><span class="si">{</span><span class="n">lp_val_seeds</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">lp_val_seeds_path</span><span class="p">,</span> <span class="n">lp_val_seeds</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;LP val seeds are saved to </span><span class="si">{</span><span class="n">lp_val_seeds_path</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">lp_val_labels_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s2">&quot;lp-val-labels.npy&quot;</span><span class="p">)</span>
<span class="n">lp_val_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">num_vals</span> <span class="o">*</span> <span class="p">(</span><span class="mi">10</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">lp_val_labels</span><span class="p">[:</span><span class="n">num_vals</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">lp_val_labels</span><span class="p">[</span><span class="n">num_vals</span><span class="p">:]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Part of val labels for link prediction: </span><span class="si">{</span><span class="n">lp_val_labels</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">lp_val_labels_path</span><span class="p">,</span> <span class="n">lp_val_labels</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;LP val labels are saved to </span><span class="si">{</span><span class="n">lp_val_labels_path</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">lp_val_indexes_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s2">&quot;lp-val-indexes.npy&quot;</span><span class="p">)</span>
<span class="n">lp_val_indexes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_vals</span><span class="p">)</span>
<span class="n">lp_val_neg_indexes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">lp_val_indexes</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">lp_val_indexes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">lp_val_indexes</span><span class="p">,</span> <span class="n">lp_val_neg_indexes</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Part of val indexes for link prediction: </span><span class="si">{</span><span class="n">lp_val_indexes</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">lp_val_indexes_path</span><span class="p">,</span> <span class="n">lp_val_indexes</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;LP val indexes are saved to </span><span class="si">{</span><span class="n">lp_val_indexes_path</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">lp_test_seeds_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s2">&quot;lp-test-seeds.npy&quot;</span><span class="p">)</span>
<span class="n">lp_test_seeds</span> <span class="o">=</span> <span class="n">edges</span><span class="p">[</span><span class="o">-</span><span class="n">num_tests</span><span class="p">:,</span> <span class="p">:]</span>
<span class="n">lp_test_neg_dsts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_nodes</span><span class="p">,</span> <span class="p">(</span><span class="n">num_tests</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">lp_test_neg_srcs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">lp_test_seeds</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">lp_test_neg_seeds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">lp_test_neg_srcs</span><span class="p">,</span> <span class="n">lp_test_neg_dsts</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
<span class="n">lp_test_seeds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">lp_test_seeds</span><span class="p">,</span> <span class="n">lp_test_neg_seeds</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Part of test seeds for link prediction: </span><span class="si">{</span><span class="n">lp_test_seeds</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">lp_test_seeds_path</span><span class="p">,</span> <span class="n">lp_test_seeds</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;LP test seeds are saved to </span><span class="si">{</span><span class="n">lp_test_seeds_path</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">lp_test_labels_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s2">&quot;lp-test-labels.npy&quot;</span><span class="p">)</span>
<span class="n">lp_test_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">num_tests</span> <span class="o">*</span> <span class="p">(</span><span class="mi">10</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">lp_test_labels</span><span class="p">[:</span><span class="n">num_tests</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">lp_test_labels</span><span class="p">[</span><span class="n">num_tests</span><span class="p">:]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Part of val labels for link prediction: </span><span class="si">{</span><span class="n">lp_test_labels</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">lp_test_labels_path</span><span class="p">,</span> <span class="n">lp_test_labels</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;LP test labels are saved to </span><span class="si">{</span><span class="n">lp_test_labels_path</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">lp_test_indexes_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s2">&quot;lp-test-indexes.npy&quot;</span><span class="p">)</span>
<span class="n">lp_test_indexes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_tests</span><span class="p">)</span>
<span class="n">lp_test_neg_indexes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">lp_test_indexes</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">lp_test_indexes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">lp_test_indexes</span><span class="p">,</span> <span class="n">lp_test_neg_indexes</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Part of test indexes for link prediction: </span><span class="si">{</span><span class="n">lp_test_indexes</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">lp_test_indexes_path</span><span class="p">,</span> <span class="n">lp_test_indexes</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;LP test indexes are saved to </span><span class="si">{</span><span class="n">lp_test_indexes_path</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Part of train seeds for link prediction: [[333  51]
 [627 314]
 [974 960]]
LP train seeds are saved to ./ondisk_dataset_homograph/lp-train-seeds.npy

Part of val seeds for link prediction: [[ 50  70]
 [427 959]
 [476 259]]
LP val seeds are saved to ./ondisk_dataset_homograph/lp-val-seeds.npy

Part of val labels for link prediction: [1. 1. 1.]
LP val labels are saved to ./ondisk_dataset_homograph/lp-val-labels.npy

Part of val indexes for link prediction: [0 1 2]
LP val indexes are saved to ./ondisk_dataset_homograph/lp-val-indexes.npy

Part of test seeds for link prediction: [[260 286]
 [971 343]
 [611 926]]
LP test seeds are saved to ./ondisk_dataset_homograph/lp-test-seeds.npy

Part of val labels for link prediction: [1. 1. 1.]
LP test labels are saved to ./ondisk_dataset_homograph/lp-test-labels.npy

Part of test indexes for link prediction: [0 1 2]
LP test indexes are saved to ./ondisk_dataset_homograph/lp-test-indexes.npy

</pre></div></div>
</div>
</section>
</section>
</section>
<section id="Organize-Data-into-YAML-File">
<h2>Organize Data into YAML File<a class="headerlink" href="#Organize-Data-into-YAML-File" title="Link to this heading"></a></h2>
<p>Now we need to create a <code class="docutils literal notranslate"><span class="pre">metadata.yaml</span></code> file which contains the paths, dadta types of graph structure, feature data, training/validation/test sets.</p>
<p>Notes: - all path should be relative to <code class="docutils literal notranslate"><span class="pre">metadata.yaml</span></code>. - Below fields are optional and not specified in below example. - <code class="docutils literal notranslate"><span class="pre">in_memory</span></code>: indicates whether to load dada into memory or <code class="docutils literal notranslate"><span class="pre">mmap</span></code>. Default is <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
<p>Please refer to <a class="reference external" href="https://github.com/dmlc/dgl/blob/master/docs/source/stochastic_training/ondisk-dataset-specification.rst">YAML specification</a> for more details.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">yaml_content</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">    dataset_name: homogeneous_graph_nc_lp</span>
<span class="s2">    graph:</span>
<span class="s2">      nodes:</span>
<span class="s2">        - num: </span><span class="si">{</span><span class="n">num_nodes</span><span class="si">}</span>
<span class="s2">      edges:</span>
<span class="s2">        - format: csv</span>
<span class="s2">          path: </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">edges_path</span><span class="p">)</span><span class="si">}</span>
<span class="s2">    feature_data:</span>
<span class="s2">      - domain: node</span>
<span class="s2">        name: feat_0</span>
<span class="s2">        format: numpy</span>
<span class="s2">        path: </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">node_feat_0_path</span><span class="p">)</span><span class="si">}</span>
<span class="s2">      - domain: node</span>
<span class="s2">        name: feat_1</span>
<span class="s2">        format: torch</span>
<span class="s2">        path: </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">node_feat_1_path</span><span class="p">)</span><span class="si">}</span>
<span class="s2">      - domain: edge</span>
<span class="s2">        name: feat_0</span>
<span class="s2">        format: numpy</span>
<span class="s2">        path: </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">edge_feat_0_path</span><span class="p">)</span><span class="si">}</span>
<span class="s2">      - domain: edge</span>
<span class="s2">        name: feat_1</span>
<span class="s2">        format: torch</span>
<span class="s2">        path: </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">edge_feat_1_path</span><span class="p">)</span><span class="si">}</span>
<span class="s2">    tasks:</span>
<span class="s2">      - name: node_classification</span>
<span class="s2">        num_classes: 10</span>
<span class="s2">        train_set:</span>
<span class="s2">          - data:</span>
<span class="s2">              - name: seeds</span>
<span class="s2">                format: numpy</span>
<span class="s2">                path: </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">nc_train_ids_path</span><span class="p">)</span><span class="si">}</span>
<span class="s2">              - name: labels</span>
<span class="s2">                format: torch</span>
<span class="s2">                path: </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">nc_train_labels_path</span><span class="p">)</span><span class="si">}</span>
<span class="s2">        validation_set:</span>
<span class="s2">          - data:</span>
<span class="s2">              - name: seeds</span>
<span class="s2">                format: numpy</span>
<span class="s2">                path: </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">nc_val_ids_path</span><span class="p">)</span><span class="si">}</span>
<span class="s2">              - name: labels</span>
<span class="s2">                format: torch</span>
<span class="s2">                path: </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">nc_val_labels_path</span><span class="p">)</span><span class="si">}</span>
<span class="s2">        test_set:</span>
<span class="s2">          - data:</span>
<span class="s2">              - name: seeds</span>
<span class="s2">                format: numpy</span>
<span class="s2">                path: </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">nc_test_ids_path</span><span class="p">)</span><span class="si">}</span>
<span class="s2">              - name: labels</span>
<span class="s2">                format: torch</span>
<span class="s2">                path: </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">nc_test_labels_path</span><span class="p">)</span><span class="si">}</span>
<span class="s2">      - name: link_prediction</span>
<span class="s2">        num_classes: 10</span>
<span class="s2">        train_set:</span>
<span class="s2">          - data:</span>
<span class="s2">              - name: seeds</span>
<span class="s2">                format: numpy</span>
<span class="s2">                path: </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">lp_train_seeds_path</span><span class="p">)</span><span class="si">}</span>
<span class="s2">        validation_set:</span>
<span class="s2">          - data:</span>
<span class="s2">              - name: seeds</span>
<span class="s2">                format: numpy</span>
<span class="s2">                path: </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">lp_val_seeds_path</span><span class="p">)</span><span class="si">}</span>
<span class="s2">              - name: labels</span>
<span class="s2">                format: numpy</span>
<span class="s2">                path: </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">lp_val_labels_path</span><span class="p">)</span><span class="si">}</span>
<span class="s2">              - name: indexes</span>
<span class="s2">                format: numpy</span>
<span class="s2">                path: </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">lp_val_indexes_path</span><span class="p">)</span><span class="si">}</span>
<span class="s2">        test_set:</span>
<span class="s2">          - data:</span>
<span class="s2">              - name: seeds</span>
<span class="s2">                format: numpy</span>
<span class="s2">                path: </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">lp_test_seeds_path</span><span class="p">)</span><span class="si">}</span>
<span class="s2">              - name: labels</span>
<span class="s2">                format: numpy</span>
<span class="s2">                path: </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">lp_test_labels_path</span><span class="p">)</span><span class="si">}</span>
<span class="s2">              - name: indexes</span>
<span class="s2">                format: numpy</span>
<span class="s2">                path: </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">lp_test_indexes_path</span><span class="p">)</span><span class="si">}</span>
<span class="s2">&quot;&quot;&quot;</span>
<span class="n">metadata_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s2">&quot;metadata.yaml&quot;</span><span class="p">)</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">metadata_path</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
  <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">yaml_content</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="Instantiate-OnDiskDataset">
<h2>Instantiate <code class="docutils literal notranslate"><span class="pre">OnDiskDataset</span></code><a class="headerlink" href="#Instantiate-OnDiskDataset" title="Link to this heading"></a></h2>
<p>Now we’re ready to load dataset via <code class="docutils literal notranslate"><span class="pre">dgl.graphbolt.OnDiskDataset</span></code>. When instantiating, we just pass in the base directory where <code class="docutils literal notranslate"><span class="pre">metadata.yaml</span></code> file lies.</p>
<p>During first instantiation, GraphBolt preprocesses the raw data such as constructing <code class="docutils literal notranslate"><span class="pre">FusedCSCSamplingGraph</span></code> from edges. All data including graph, feature data, training/validation/test sets are put into <code class="docutils literal notranslate"><span class="pre">preprocessed</span></code> directory after preprocessing. Any following dataset loading will skip the preprocess stage.</p>
<p>After preprocessing, <code class="docutils literal notranslate"><span class="pre">load()</span></code> is required to be called explicitly in order to load graph, feature data and tasks.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">gb</span><span class="o">.</span><span class="n">OnDiskDataset</span><span class="p">(</span><span class="n">base_dir</span><span class="p">)</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
<span class="n">graph</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">graph</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loaded graph: </span><span class="si">{</span><span class="n">graph</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">feature</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">feature</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loaded feature store: </span><span class="si">{</span><span class="n">feature</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">tasks</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">tasks</span>
<span class="n">nc_task</span> <span class="o">=</span> <span class="n">tasks</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loaded node classification task: </span><span class="si">{</span><span class="n">nc_task</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">lp_task</span> <span class="o">=</span> <span class="n">tasks</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loaded link prediction task: </span><span class="si">{</span><span class="n">lp_task</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
The on-disk dataset is re-preprocessing, so the existing preprocessed dataset has been removed.
Start to preprocess the on-disk dataset.
Finish preprocessing the on-disk dataset.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Loaded graph: FusedCSCSamplingGraph(csc_indptr=tensor([    0,    14,    24,  ...,  9982,  9991, 10000], dtype=torch.int32),
                      indices=tensor([997, 611, 809,  ..., 174, 860, 385], dtype=torch.int32),
                      total_num_nodes=1000, num_edges=10000,)

Loaded feature store: TorchBasedFeatureStore(
    {(&lt;OnDiskFeatureDataDomain.NODE: &#39;node&#39;&gt;, None, &#39;feat_0&#39;): TorchBasedFeature(
        feature=tensor([[0.5564, 0.2964, 0.0117, 0.9450, 0.1201],
                        [0.6375, 0.6853, 0.9109, 0.9382, 0.5793],
                        [0.2237, 0.7472, 0.9217, 0.9208, 0.4239],
                        ...,
                        [0.8127, 0.4760, 0.9890, 0.9391, 0.5339],
                        [0.7303, 0.9573, 0.9012, 0.6436, 0.3665],
                        [0.9364, 0.5762, 0.9867, 0.8484, 0.4348]], dtype=torch.float64),
        metadata={},
    ), (&lt;OnDiskFeatureDataDomain.NODE: &#39;node&#39;&gt;, None, &#39;feat_1&#39;): TorchBasedFeature(
        feature=tensor([[0.8693, 0.1440, 0.3363, 0.5206, 0.0912],
                        [0.2734, 0.3872, 0.1187, 0.8336, 0.4087],
                        [0.1987, 0.6960, 0.9002, 0.5608, 0.2093],
                        ...,
                        [0.2666, 0.6680, 0.6319, 0.1799, 0.3811],
                        [0.1433, 0.5420, 0.3064, 0.5488, 0.8442],
                        [0.1601, 0.9098, 0.2455, 0.8474, 0.2141]]),
        metadata={},
    ), (&lt;OnDiskFeatureDataDomain.EDGE: &#39;edge&#39;&gt;, None, &#39;feat_0&#39;): TorchBasedFeature(
        feature=tensor([[0.9115, 0.6992, 0.8159, 0.4012, 0.4011],
                        [0.7755, 0.3071, 0.0329, 0.7652, 0.7728],
                        [0.2687, 0.9465, 0.7218, 0.1787, 0.3724],
                        ...,
                        [0.9900, 0.7889, 0.5332, 0.8527, 0.2973],
                        [0.4448, 0.0112, 0.5608, 0.3832, 0.0311],
                        [0.2558, 0.8800, 0.3945, 0.4548, 0.6796]], dtype=torch.float64),
        metadata={},
    ), (&lt;OnDiskFeatureDataDomain.EDGE: &#39;edge&#39;&gt;, None, &#39;feat_1&#39;): TorchBasedFeature(
        feature=tensor([[0.8857, 0.8096, 0.5453, 0.9915, 0.7684],
                        [0.9626, 0.2615, 0.6159, 0.7570, 0.1749],
                        [0.4404, 0.3759, 0.3843, 0.5937, 0.6090],
                        ...,
                        [0.6330, 0.6756, 0.9294, 0.5533, 0.5155],
                        [0.9011, 0.5170, 0.7739, 0.7246, 0.6908],
                        [0.5548, 0.6727, 0.0887, 0.5525, 0.4919]]),
        metadata={},
    )}
)

Loaded node classification task: OnDiskTask(validation_set=ItemSet(
               items=(tensor([ 99, 246, 400, 186, 892,   9, 184, 182, 577, 635, 422, 913, 795, 322,
                   198, 201, 281, 534, 413, 945, 364, 486, 131, 776, 925, 267, 403, 483,
                   614, 555, 975, 762, 365, 447,  76, 481, 192, 867, 442,  87, 991, 673,
                   819, 446, 368, 605, 240, 582, 691, 985, 343, 970, 493, 404, 298, 989,
                   854, 968, 373, 327, 818, 705, 736, 937, 230, 906,  34, 314,  67, 119,
                   297, 633, 835, 960, 830, 714, 239, 465, 503, 356, 827, 803,  59, 335,
                   809, 408, 153, 147, 136, 744, 731, 986, 420, 520, 151, 524, 601, 478,
                   355, 506, 511, 684, 358, 611, 374, 972, 202, 572, 243, 137, 426, 868,
                   338, 980, 656, 882, 842, 362, 593, 377, 790,   0, 318, 247, 837, 879,
                   957, 676, 348, 855,  28, 402, 430, 456, 431, 708, 784, 395, 265, 878,
                    42, 366, 812, 662, 500, 258, 515,  55, 525, 586, 142, 654, 638, 727,
                   313, 450, 814, 156, 193, 788, 215, 218, 934, 412, 902, 890,  49, 330,
                    72, 514, 739, 331, 428, 307, 417, 309, 836, 710,   7, 389, 497,  45,
                   530, 979, 796, 850, 756, 548, 320, 472, 789, 628,  97, 257, 214, 926,
                   711, 639,  60, 386], dtype=torch.int32), tensor([3, 4, 1, 2, 0, 9, 6, 0, 0, 5, 9, 7, 6, 0, 4, 5, 0, 6, 8, 1, 9, 3, 9, 3,
                   8, 7, 7, 8, 3, 4, 5, 5, 5, 6, 3, 5, 8, 1, 6, 9, 1, 1, 1, 1, 0, 1, 7, 2,
                   3, 1, 8, 3, 3, 6, 2, 5, 7, 8, 2, 7, 3, 1, 5, 5, 2, 8, 8, 5, 5, 8, 2, 1,
                   1, 0, 9, 2, 0, 0, 7, 8, 1, 5, 7, 3, 7, 8, 8, 9, 1, 0, 2, 3, 6, 4, 3, 7,
                   3, 5, 1, 2, 3, 9, 5, 6, 1, 4, 7, 5, 9, 6, 5, 5, 9, 7, 1, 7, 3, 8, 2, 9,
                   5, 7, 7, 7, 8, 9, 3, 6, 7, 5, 7, 1, 4, 3, 4, 8, 4, 8, 6, 4, 8, 1, 8, 8,
                   0, 3, 2, 9, 7, 6, 7, 6, 9, 4, 5, 8, 9, 7, 3, 9, 3, 7, 8, 7, 3, 4, 8, 6,
                   3, 6, 3, 7, 1, 6, 1, 6, 9, 7, 4, 3, 3, 8, 8, 1, 0, 9, 9, 6, 3, 9, 9, 6,
                   0, 2, 6, 2, 8, 9, 5, 5])),
               names=(&#39;seeds&#39;, &#39;labels&#39;),
           ),
           train_set=ItemSet(
               items=(tensor([287, 336, 252, 228, 522, 578, 259, 144,  86,  51,  56, 518, 379,  79,
                   234, 984, 473, 954, 881, 441, 308, 874, 394, 445, 563, 460, 385,  38,
                   130,  44, 179, 539, 779, 436, 659, 885, 269,  29,  43, 716, 547, 328,
                   801, 981, 226,  39, 955, 165, 391, 185, 236,  35, 492, 977, 825, 160,
                   270, 359, 726, 870, 808, 738, 471,  18, 213, 603, 703, 507, 932, 177,
                   971, 266, 127, 112, 845, 427, 491, 494, 849, 334,  73, 363, 333, 997,
                   811, 893,  32,  71, 390, 299, 899,  23,  63, 421, 690, 598,  12, 208,
                   261, 587, 567, 205, 916, 339, 203, 489, 770, 116, 927, 821, 415, 544,
                   305, 207, 757, 992,  84, 371, 995, 753, 416, 170, 891,  61, 121, 864,
                   134, 718, 861, 688, 124, 285, 496, 680,  74, 816, 178, 728, 150, 974,
                   466, 274, 162, 876, 860, 380, 576,  70, 590, 528, 157, 448, 939, 301,
                   485, 114, 930, 848,  83, 557,   1, 381, 774, 723,  24, 653, 615, 866,
                     2, 947, 749, 344, 406, 990, 220, 629, 176, 961, 272, 254, 931, 479,
                   833, 174, 204, 817, 453, 903,  91, 253, 641, 597, 713, 681, 235, 115,
                   108, 793, 689, 857,  66, 909, 508, 551, 111, 321, 512, 965,  88, 217,
                   393, 953,  40, 552, 369, 758,  93, 949, 694, 487, 915, 414, 617, 532,
                   824, 693, 171, 372, 610, 921, 897, 917, 794, 173, 644, 346, 303, 457,
                   101,  14, 911,  33, 565, 353, 685, 765, 360, 575,  37,  94, 677, 263,
                   772,  21, 858, 883,  16, 846, 104, 432, 787, 804, 242, 667, 646, 983,
                   797, 894,  81, 264, 958, 545, 627, 197, 159, 609, 241, 872, 918, 987,
                   154, 139, 291, 209, 742, 312, 792, 658, 383, 541, 529, 467, 799, 107,
                   920, 554, 962, 735, 245, 164, 630, 440, 695, 352, 282, 468, 976,  15,
                   546, 661, 341, 608, 810, 912, 279,   5, 946, 332, 233, 398, 623, 452,
                   901, 660, 780, 856, 898, 523, 238, 966, 354, 865, 807,  80, 155, 570,
                   568, 564, 250, 923, 904, 692, 125, 843, 255, 596, 907, 969, 863, 148,
                   437, 284, 212, 167, 562, 877, 561, 625, 655, 294, 649, 908, 292, 454,
                   141, 831, 889, 293, 724, 310, 745, 306, 449, 401, 199, 800, 463, 251,
                   720, 761, 110, 329, 350, 424, 319, 700, 580, 910, 791, 952, 461, 746,
                   533, 701, 527, 781, 994,   6, 583, 571, 143, 521, 324, 581, 771,  31,
                    69, 871, 229, 304, 715,  20, 828, 505, 526, 996, 579, 712, 126, 502,
                   616,  53, 602, 604, 775, 433, 418, 829, 407, 621, 922, 636, 900, 409,
                   768, 914, 645,  77, 669, 120, 631, 704, 480, 964, 733, 540, 438, 880,
                   584, 425, 419, 410, 288, 933, 618, 277,  92, 175, 928, 743, 687, 826,
                   451, 382, 221,   3, 672, 219, 158, 852, 763,  52,  64, 152, 950, 924,
                   549, 286,  26, 612, 351,  48,  11, 606, 999, 223, 295, 666, 289, 558,
                   388, 190, 118, 822, 839, 357, 675, 862, 600, 873, 370,  98,  82, 823,
                   637, 709,  22, 122, 161, 783, 323, 585, 725, 531, 361, 195, 387, 766,
                   853, 624,   4, 271, 978, 905, 943, 841, 488,  50, 315, 896, 643, 778,
                   501, 802, 751, 378,  10, 464, 678, 543, 180, 651, 940, 189, 786, 470,
                   888, 936, 760, 337, 702, 560, 832, 260, 717,  36, 109, 838, 998, 455,
                   750, 200, 187, 105,  68, 517, 538,  78, 535, 166,  27, 886, 657, 752,
                   244, 663, 938, 674, 634, 719, 194, 138, 135,  46, 679, 133, 256, 516,
                   847, 887, 591, 944, 181, 411, 249,  47, 100, 773, 683, 951],
                  dtype=torch.int32), tensor([1, 7, 2, 3, 3, 1, 7, 0, 2, 9, 5, 0, 5, 3, 6, 7, 2, 1, 7, 5, 7, 7, 5, 5,
                   5, 6, 1, 7, 0, 9, 3, 3, 5, 3, 6, 2, 1, 6, 7, 1, 9, 9, 5, 5, 6, 0, 9, 3,
                   0, 6, 9, 0, 9, 9, 5, 8, 9, 2, 9, 5, 9, 1, 1, 0, 9, 5, 0, 1, 8, 7, 9, 3,
                   3, 8, 9, 7, 0, 5, 8, 7, 6, 0, 4, 3, 8, 3, 5, 0, 4, 0, 8, 3, 5, 5, 5, 9,
                   0, 5, 8, 7, 6, 1, 9, 2, 7, 9, 2, 4, 9, 3, 9, 9, 6, 5, 3, 3, 4, 3, 3, 1,
                   0, 9, 1, 7, 6, 7, 9, 7, 5, 2, 9, 7, 1, 2, 4, 6, 1, 8, 6, 9, 4, 3, 4, 6,
                   1, 6, 7, 4, 9, 5, 0, 3, 0, 1, 8, 1, 1, 5, 9, 4, 5, 2, 9, 7, 0, 5, 5, 1,
                   3, 8, 4, 0, 7, 6, 5, 1, 2, 9, 8, 7, 9, 7, 5, 7, 1, 7, 1, 4, 8, 2, 1, 8,
                   7, 7, 2, 6, 4, 5, 3, 3, 8, 6, 7, 4, 0, 0, 1, 2, 3, 8, 1, 8, 7, 2, 1, 8,
                   3, 6, 5, 8, 8, 0, 7, 3, 7, 4, 9, 4, 9, 8, 6, 7, 6, 1, 3, 6, 3, 4, 5, 1,
                   2, 4, 5, 3, 4, 7, 3, 1, 1, 8, 6, 6, 4, 6, 9, 4, 6, 4, 6, 8, 3, 0, 8, 6,
                   7, 7, 1, 2, 8, 4, 8, 7, 2, 6, 7, 9, 2, 5, 5, 1, 6, 6, 3, 6, 6, 4, 6, 1,
                   8, 7, 0, 3, 3, 0, 1, 1, 5, 0, 6, 4, 8, 6, 3, 2, 1, 4, 1, 1, 6, 3, 8, 4,
                   0, 1, 4, 4, 3, 7, 4, 5, 5, 7, 7, 9, 6, 0, 9, 7, 1, 0, 1, 5, 4, 4, 4, 2,
                   1, 3, 2, 1, 8, 7, 6, 0, 9, 8, 2, 3, 0, 9, 0, 6, 7, 3, 9, 6, 4, 9, 2, 7,
                   9, 6, 4, 7, 4, 5, 0, 5, 1, 9, 5, 6, 6, 8, 7, 8, 1, 4, 9, 2, 0, 6, 5, 5,
                   7, 1, 9, 2, 5, 6, 8, 0, 9, 8, 5, 9, 3, 9, 0, 5, 0, 0, 9, 5, 7, 3, 6, 8,
                   4, 6, 0, 3, 4, 4, 4, 9, 3, 1, 4, 2, 7, 6, 9, 0, 8, 6, 3, 7, 1, 0, 4, 2,
                   4, 9, 5, 5, 6, 6, 6, 3, 9, 3, 0, 6, 7, 2, 8, 3, 3, 4, 2, 7, 6, 2, 4, 5,
                   9, 1, 7, 7, 5, 5, 4, 7, 4, 9, 0, 9, 0, 2, 8, 1, 9, 8, 9, 4, 8, 6, 8, 4,
                   6, 7, 8, 8, 5, 0, 9, 2, 0, 8, 6, 6, 4, 0, 2, 1, 5, 0, 0, 3, 8, 2, 5, 5,
                   7, 8, 1, 6, 9, 3, 1, 0, 5, 7, 5, 1, 5, 6, 7, 4, 8, 4, 4, 4, 2, 8, 0, 8,
                   6, 6, 0, 9, 7, 6, 9, 2, 5, 2, 5, 9, 7, 0, 5, 3, 0, 9, 6, 0, 1, 4, 1, 5,
                   6, 8, 3, 1, 2, 6, 3, 5, 9, 2, 7, 6, 1, 0, 0, 4, 9, 7, 1, 5, 6, 8, 9, 6,
                   9, 2, 7, 0, 6, 5, 3, 4, 4, 9, 8, 8, 9, 0, 9, 8, 1, 5, 7, 2, 6, 4, 1, 5])),
               names=(&#39;seeds&#39;, &#39;labels&#39;),
           ),
           test_set=ItemSet(
               items=(tensor([607,  96, 875, 537,  65, 574, 296, 224, 113, 191, 982, 550, 973,  19,
                   993, 509, 188, 490, 747, 569, 553, 482, 146, 172, 740, 210, 730,  17,
                   844, 495, 588, 367, 225, 754, 613, 283,  62, 640, 149, 764, 206, 273,
                   132, 967, 840,  30, 632, 536, 128, 469, 559, 435,  54, 737, 805, 806,
                   884, 759,  90, 475, 956, 459, 769, 851, 300, 290, 697, 231,  58, 106,
                   405, 935, 439, 699, 592, 869, 895, 668, 169, 941, 423, 103, 477, 227,
                   820, 216, 376, 785, 741, 919, 620, 458,  95, 589, 392, 462, 498, 434,
                   682, 397, 573, 948, 499, 513, 196, 326, 664, 696, 399, 648, 834, 652,
                   384, 102, 647, 595, 626, 317, 686, 599, 504, 556, 755, 429, 342, 734,
                   248, 698, 268, 484,  75, 474, 280, 665, 129, 767, 316, 302, 721, 670,
                   168, 815, 183, 510, 444, 729, 594, 671, 443, 622, 163, 262,  57, 117,
                   123, 566, 859, 276, 929,  85, 211, 375, 325, 311, 222,   8, 942, 619,
                   963,  41, 732, 345,  89, 519, 232, 813,  25, 707, 642, 798, 748, 782,
                   722, 650, 340, 542, 145, 349, 959, 140, 396, 777,  13, 278, 706, 476,
                   988, 237, 275, 347], dtype=torch.int32), tensor([8, 9, 0, 9, 4, 6, 4, 9, 9, 3, 6, 2, 2, 7, 4, 7, 1, 4, 4, 0, 6, 0, 4, 6,
                   6, 9, 5, 5, 3, 7, 3, 8, 1, 4, 0, 9, 3, 3, 7, 4, 8, 8, 0, 2, 6, 0, 6, 1,
                   3, 3, 5, 3, 3, 1, 7, 2, 2, 6, 0, 0, 4, 2, 1, 6, 3, 1, 7, 3, 8, 0, 6, 1,
                   2, 5, 3, 9, 8, 6, 3, 7, 6, 5, 5, 7, 0, 5, 7, 2, 4, 0, 4, 8, 1, 3, 3, 1,
                   0, 0, 4, 9, 7, 0, 2, 1, 3, 3, 6, 8, 8, 6, 3, 0, 5, 3, 3, 6, 4, 2, 9, 8,
                   1, 7, 3, 7, 4, 1, 1, 7, 1, 1, 1, 5, 2, 0, 1, 5, 2, 1, 0, 7, 2, 5, 7, 4,
                   9, 5, 1, 4, 0, 3, 3, 0, 0, 4, 1, 0, 5, 5, 8, 2, 0, 1, 3, 6, 1, 7, 1, 1,
                   0, 7, 6, 4, 3, 6, 8, 1, 8, 1, 9, 3, 6, 5, 4, 2, 7, 2, 1, 0, 9, 2, 4, 5,
                   6, 4, 3, 7, 6, 7, 5, 2])),
               names=(&#39;seeds&#39;, &#39;labels&#39;),
           ),
           metadata={&#39;name&#39;: &#39;node_classification&#39;, &#39;num_classes&#39;: 10},)

Loaded link prediction task: OnDiskTask(validation_set=ItemSet(
               items=(tensor([[ 50,  70],
                   [427, 959],
                   [476, 259],
                   ...,
                   [537, 449],
                   [537, 757],
                   [537, 274]], dtype=torch.int32), tensor([1., 1., 1.,  ..., 0., 0., 0.], dtype=torch.float64), tensor([   0,    1,    2,  ..., 1999, 1999, 1999])),
               names=(&#39;seeds&#39;, &#39;labels&#39;, &#39;indexes&#39;),
           ),
           train_set=ItemSet(
               items=(tensor([[333,  51],
                   [627, 314],
                   [974, 960],
                   ...,
                   [481, 294],
                   [902,  55],
                   [716,  34]], dtype=torch.int32),),
               names=(&#39;seeds&#39;,),
           ),
           test_set=ItemSet(
               items=(tensor([[260, 286],
                   [971, 343],
                   [611, 926],
                   ...,
                   [501, 839],
                   [501, 629],
                   [501, 720]], dtype=torch.int32), tensor([1., 1., 1.,  ..., 0., 0., 0.], dtype=torch.float64), tensor([   0,    1,    2,  ..., 1999, 1999, 1999])),
               names=(&#39;seeds&#39;, &#39;labels&#39;, &#39;indexes&#39;),
           ),
           metadata={&#39;name&#39;: &#39;link_prediction&#39;, &#39;num_classes&#39;: 10},)

</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/home/ubuntu/dgl_doc_dev/dgl/python/dgl/graphbolt/impl/ondisk_dataset.py:463: GBWarning: Edge feature is stored, but edge IDs are not saved.
  gb_warning(&#34;Edge feature is stored, but edge IDs are not saved.&#34;)
</pre></div></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="ondisk-dataset.html" class="btn btn-neutral float-left" title="Composing OnDiskDataset from raw data" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="ondisk_dataset_heterograph.html" class="btn btn-neutral float-right" title="OnDiskDataset for Heterogeneous Graph" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2018, DGL Team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>